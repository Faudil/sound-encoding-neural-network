{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import phase if every import is here it is to allow you to run this cell and know if you have any issue and not after a few hours of training\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, Activation, Flatten, MaxPooling1D, BatchNormalization, LSTM, GaussianNoise\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "from src.VoiceModule import VoiceModule\n",
    "from src.classifiers.KerasClassifier import KerasClassifier\n",
    "from prepare_data_utils import load_wav, preprare_wav, split_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n",
      "tree\n",
      "_background_noise_\n",
      "go\n",
      "house\n",
      "validation_list.txt\n",
      "eight\n",
      "up\n",
      "bed\n",
      "two\n",
      "dog\n",
      "no\n",
      "bird\n",
      "five\n",
      "marvin\n",
      "seven\n",
      "four\n",
      "visual\n",
      "happy\n",
      "nine\n",
      "data_speech_commands_v0.02.tar.gz\n",
      "off\n",
      "yes\n",
      "forward\n",
      "follow\n",
      "README.md\n",
      "cat\n",
      "three\n",
      "on\n",
      "right\n",
      "backward\n",
      "testing_list.txt\n",
      "sheila\n",
      "wow\n",
      ".DS_Store\n",
      "stop\n",
      "one\n",
      "zero\n",
      "six\n",
      "learn\n",
      "LICENSE\n",
      "left\n"
     ]
    }
   ],
   "source": [
    "# print environment\n",
    "folder_path = \"../../data/keywords\"\n",
    "for l in os.listdir(folder_path):\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data method\n",
    "\n",
    "def mfcc(buffer, samplerate, dim):\n",
    "    a = librosa.feature.mfcc(y=buffer, sr=samplerate, n_mfcc=dim)\n",
    "    a = np.transpose(a)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback to later draw some graphs\n",
    "\n",
    "class PerformanceLogger(Callback):\n",
    "    def __init__(self):\n",
    "        # List of tuple (loss, accuracy)\n",
    "        self.training = []\n",
    "        self.testing = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.training.append((logs[\"loss\"], logs[\"acc\"]))\n",
    "        self.testing.append((logs[\"val_loss\"], logs[\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class\n",
    "class EmotionClassifierCnn(KerasClassifier):\n",
    "    def __init__(self, file_path=None):\n",
    "        super().__init__(file_path)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.expand_dims(np.array([x]), axis=2)\n",
    "        return self._model.predict(x)\n",
    "\n",
    "    def build(self):\n",
    "        model = Sequential()\n",
    "        # Adding noise to the training data\n",
    "        model.add(GaussianNoise(0.2))\n",
    "        \n",
    "        # feature Extraction layers\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv1D(256, 3, input_shape=(50, 13), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(128, 3, input_shape=(50, 13), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(64, 3, input_shape=(50, 13), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(64, 3, input_shape=(50, 13), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        \n",
    "        # End of the neuron and classification part\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Flatten())\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Dense(35))\n",
    "        model.add(Activation('softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self._model = model\n",
    "        \n",
    "    def train(self, X, Y, batch_size=32, epoch=720, validation_data=None, callbacks=[]):\n",
    "        self._model.fit(X, Y, batch_size=batch_size, epochs=epoch, validation_data=validation_data, callbacks=callbacks)\n",
    "\n",
    "    def transform(self, x, samplerate):\n",
    "        to_process = mfcc(x, samplerate, 13)\n",
    "        to_process = pad_sequences([to_process], maxlen=50, padding='post')[0]\n",
    "        return to_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "WARNING:tensorflow:From /home/arc/fdp5/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#Instanciate model\n",
    "digit_list = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
    "keyword_list = [\"backward\", \"bed\", \"bird\", \"cat\", \"dog\", \"down\", \"follow\", \"forward\",\n",
    "               \"go\", \"happy\", \"house\", \"learn\", \"left\", \"marvin\", \"no\", \"off\", \"on\",\n",
    "               \"right\", \"sheila\", \"stop\", \"tree\", \"up\", \"visual\", \"wow\", \"yes\"] + digit_list\n",
    "print(len(keyword_list))\n",
    "dimension_mfcc = 13\n",
    "samplerate = 16000\n",
    "nb_break=None\n",
    "sample_duration=1\n",
    "step=1\n",
    "\n",
    "logger = PerformanceLogger()\n",
    "\n",
    "cls = EmotionClassifierCnn()\n",
    "vm = VoiceModule(\"digit\", keyword_list, cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing backward\n",
      "Doing bed\n",
      "Doing bird\n",
      "Doing cat\n",
      "Doing dog\n",
      "Doing down\n",
      "Doing follow\n",
      "Doing forward\n",
      "Doing go\n",
      "Doing happy\n",
      "Doing house\n",
      "Doing learn\n",
      "Doing left\n",
      "Doing marvin\n",
      "Doing no\n",
      "Doing off\n",
      "Doing on\n",
      "Doing right\n",
      "Doing sheila\n",
      "Doing stop\n",
      "Doing tree\n",
      "Doing up\n",
      "Doing visual\n",
      "Doing wow\n",
      "Doing yes\n",
      "Doing zero\n",
      "Doing one\n",
      "Doing two\n",
      "Doing three\n",
      "Doing four\n",
      "Doing five\n",
      "Doing six\n",
      "Doing seven\n",
      "Doing eight\n",
      "Doing nine\n",
      "Done (95394, 50, 13)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in keyword_list}\n",
    "X, Y = preprare_wav(data, vm, sample_duration, step)\n",
    "print(\"Done\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_file = f\"x_{'_'.join(keyword_list)}-{vm._name}.npy\"\n",
    "Y_file = f\"y_{'_'.join(keyword_list)}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the prepared input data \n",
    "np.save(X_file, X)\n",
    "np.save(Y_file, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for training\n",
    "X, Y = np.load(X_file), np.load(Y_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95394, 50, 13)\n",
      "76315 19079\n",
      "(50, 13)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "\"\"\"train_size = 80 * len(X) // 100\n",
    "test_size = 20 * len(X) // 100\n",
    "#X = np.expand_dims(X, axis=3)\n",
    "X_train, X_test, = X[:train_size], X[train_size:]\n",
    "Y_train, Y_test = Y[:train_size], Y[train_size:]\"\"\"\n",
    "X = X.astype('float32')\n",
    "print(X.shape)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(len(X_train), len(X_test))\n",
    "\n",
    "print(X[0].shape)\n",
    "print( X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76315 samples, validate on 19079 samples\n",
      "Epoch 1/100\n",
      "76315/76315 [==============================] - 20s 261us/sample - loss: 2.0254 - acc: 0.4267 - val_loss: 1.3400 - val_acc: 0.6894\n",
      "Epoch 2/100\n",
      "76315/76315 [==============================] - 17s 220us/sample - loss: 0.8849 - acc: 0.7377 - val_loss: 0.7107 - val_acc: 0.8096\n",
      "Epoch 3/100\n",
      "76315/76315 [==============================] - 17s 218us/sample - loss: 0.6254 - acc: 0.8148 - val_loss: 0.5215 - val_acc: 0.8514\n",
      "Epoch 4/100\n",
      "76315/76315 [==============================] - 17s 218us/sample - loss: 0.5139 - acc: 0.8477 - val_loss: 0.4936 - val_acc: 0.8511\n",
      "Epoch 5/100\n",
      "76315/76315 [==============================] - 17s 226us/sample - loss: 0.4485 - acc: 0.8664 - val_loss: 0.3600 - val_acc: 0.8922\n",
      "Epoch 6/100\n",
      "76315/76315 [==============================] - 16s 216us/sample - loss: 0.3894 - acc: 0.8850 - val_loss: 0.3392 - val_acc: 0.9003\n",
      "Epoch 7/100\n",
      "76315/76315 [==============================] - 17s 216us/sample - loss: 0.3516 - acc: 0.8954 - val_loss: 0.3234 - val_acc: 0.9039\n",
      "Epoch 8/100\n",
      "76315/76315 [==============================] - 16s 207us/sample - loss: 0.3180 - acc: 0.9059 - val_loss: 0.2881 - val_acc: 0.9143\n",
      "Epoch 9/100\n",
      "76315/76315 [==============================] - 17s 224us/sample - loss: 0.2807 - acc: 0.9158 - val_loss: 0.2744 - val_acc: 0.9220\n",
      "Epoch 10/100\n",
      "76315/76315 [==============================] - 17s 228us/sample - loss: 0.2855 - acc: 0.9137 - val_loss: 0.2791 - val_acc: 0.9196\n",
      "Epoch 11/100\n",
      "76315/76315 [==============================] - 18s 235us/sample - loss: 0.2454 - acc: 0.9255 - val_loss: 0.2733 - val_acc: 0.9194\n",
      "Epoch 12/100\n",
      "76315/76315 [==============================] - 18s 237us/sample - loss: 0.2538 - acc: 0.9231 - val_loss: 0.2760 - val_acc: 0.9194\n",
      "Epoch 13/100\n",
      "76315/76315 [==============================] - 18s 232us/sample - loss: 0.2332 - acc: 0.9304 - val_loss: 0.2584 - val_acc: 0.9247\n",
      "Epoch 14/100\n",
      "76315/76315 [==============================] - 18s 238us/sample - loss: 0.1988 - acc: 0.9389 - val_loss: 0.2495 - val_acc: 0.9293\n",
      "Epoch 15/100\n",
      "76315/76315 [==============================] - 17s 229us/sample - loss: 0.1873 - acc: 0.9425 - val_loss: 0.2515 - val_acc: 0.9285\n",
      "Epoch 16/100\n",
      "76315/76315 [==============================] - 18s 238us/sample - loss: 0.1910 - acc: 0.9416 - val_loss: 0.2670 - val_acc: 0.9253\n",
      "Epoch 17/100\n",
      "76315/76315 [==============================] - 18s 230us/sample - loss: 0.1677 - acc: 0.9481 - val_loss: 0.2572 - val_acc: 0.9291\n",
      "Epoch 18/100\n",
      "76315/76315 [==============================] - 18s 239us/sample - loss: 0.1523 - acc: 0.9533 - val_loss: 0.2497 - val_acc: 0.9330\n",
      "Epoch 19/100\n",
      "76315/76315 [==============================] - 18s 237us/sample - loss: 0.1749 - acc: 0.9461 - val_loss: 0.2637 - val_acc: 0.9315\n",
      "Epoch 20/100\n",
      "76315/76315 [==============================] - 17s 226us/sample - loss: 0.1411 - acc: 0.9567 - val_loss: 0.2490 - val_acc: 0.9319\n",
      "Epoch 21/100\n",
      "76315/76315 [==============================] - 17s 222us/sample - loss: 0.1962 - acc: 0.9397 - val_loss: 0.2534 - val_acc: 0.9336\n",
      "Epoch 22/100\n",
      "76315/76315 [==============================] - 17s 224us/sample - loss: 0.1619 - acc: 0.9503 - val_loss: 0.2468 - val_acc: 0.9361\n",
      "Epoch 23/100\n",
      "76315/76315 [==============================] - 17s 216us/sample - loss: 0.1257 - acc: 0.9612 - val_loss: 0.2394 - val_acc: 0.9377\n",
      "Epoch 24/100\n",
      "76315/76315 [==============================] - 17s 217us/sample - loss: 0.1195 - acc: 0.9631 - val_loss: 0.2782 - val_acc: 0.9302\n",
      "Epoch 25/100\n",
      "76315/76315 [==============================] - 17s 221us/sample - loss: 0.1484 - acc: 0.9541 - val_loss: 0.2571 - val_acc: 0.9348\n",
      "Epoch 26/100\n",
      "76315/76315 [==============================] - 17s 223us/sample - loss: 0.1096 - acc: 0.9659 - val_loss: 0.2588 - val_acc: 0.9363\n",
      "Epoch 27/100\n",
      "76315/76315 [==============================] - 18s 236us/sample - loss: 0.0990 - acc: 0.9692 - val_loss: 0.2739 - val_acc: 0.9324\n",
      "Epoch 28/100\n",
      "76315/76315 [==============================] - 19s 251us/sample - loss: 0.1051 - acc: 0.9664 - val_loss: 0.2774 - val_acc: 0.9330\n",
      "Epoch 29/100\n",
      "76315/76315 [==============================] - 19s 245us/sample - loss: 0.1147 - acc: 0.9641 - val_loss: 0.2681 - val_acc: 0.9341\n",
      "Epoch 30/100\n",
      "76315/76315 [==============================] - 19s 253us/sample - loss: 0.1542 - acc: 0.9535 - val_loss: 0.2796 - val_acc: 0.9321\n",
      "Epoch 31/100\n",
      "76315/76315 [==============================] - 20s 256us/sample - loss: 0.1211 - acc: 0.9620 - val_loss: 0.2486 - val_acc: 0.9355\n",
      "Epoch 32/100\n",
      "76315/76315 [==============================] - 19s 250us/sample - loss: 0.0989 - acc: 0.9689 - val_loss: 0.2503 - val_acc: 0.9382\n",
      "Epoch 33/100\n",
      "76315/76315 [==============================] - 19s 252us/sample - loss: 0.0905 - acc: 0.9713 - val_loss: 0.2511 - val_acc: 0.9404\n",
      "Epoch 34/100\n",
      "76315/76315 [==============================] - 19s 245us/sample - loss: 0.0792 - acc: 0.9748 - val_loss: 0.2597 - val_acc: 0.9376\n",
      "Epoch 35/100\n",
      "76315/76315 [==============================] - 19s 249us/sample - loss: 0.0834 - acc: 0.9742 - val_loss: 0.2611 - val_acc: 0.9401\n",
      "Epoch 36/100\n",
      "76315/76315 [==============================] - 19s 253us/sample - loss: 0.0880 - acc: 0.9722 - val_loss: 0.2700 - val_acc: 0.9383\n",
      "Epoch 37/100\n",
      "76315/76315 [==============================] - 19s 250us/sample - loss: 0.0827 - acc: 0.9737 - val_loss: 0.2743 - val_acc: 0.9379\n",
      "Epoch 38/100\n",
      "76315/76315 [==============================] - 19s 243us/sample - loss: 0.0870 - acc: 0.9720 - val_loss: 0.2785 - val_acc: 0.9365\n",
      "Epoch 39/100\n",
      "76315/76315 [==============================] - 18s 237us/sample - loss: 0.1063 - acc: 0.9669 - val_loss: 0.2927 - val_acc: 0.9352\n",
      "Epoch 40/100\n",
      "76315/76315 [==============================] - 18s 234us/sample - loss: 0.0921 - acc: 0.9705 - val_loss: 0.2757 - val_acc: 0.9365\n",
      "Epoch 41/100\n",
      "76315/76315 [==============================] - 18s 231us/sample - loss: 0.0860 - acc: 0.9727 - val_loss: 0.2736 - val_acc: 0.9399\n",
      "Epoch 42/100\n",
      "76315/76315 [==============================] - 17s 224us/sample - loss: 0.0779 - acc: 0.9748 - val_loss: 0.2977 - val_acc: 0.9352\n",
      "Epoch 43/100\n",
      "76315/76315 [==============================] - 17s 221us/sample - loss: 0.0927 - acc: 0.9721 - val_loss: 0.3010 - val_acc: 0.9333\n",
      "Epoch 44/100\n",
      "76315/76315 [==============================] - 17s 228us/sample - loss: 0.0951 - acc: 0.9702 - val_loss: 0.2904 - val_acc: 0.9347\n",
      "Epoch 45/100\n",
      "76315/76315 [==============================] - 17s 229us/sample - loss: 0.1044 - acc: 0.9674 - val_loss: 0.2797 - val_acc: 0.9363\n",
      "Epoch 46/100\n",
      "76315/76315 [==============================] - 18s 233us/sample - loss: 0.0806 - acc: 0.9748 - val_loss: 0.2809 - val_acc: 0.9391\n",
      "Epoch 47/100\n",
      "76315/76315 [==============================] - 18s 233us/sample - loss: 0.0958 - acc: 0.9706 - val_loss: 0.2587 - val_acc: 0.9411\n",
      "Epoch 48/100\n",
      "76315/76315 [==============================] - 18s 233us/sample - loss: 0.0599 - acc: 0.9811 - val_loss: 0.2705 - val_acc: 0.9380\n",
      "Epoch 49/100\n",
      "76315/76315 [==============================] - 17s 229us/sample - loss: 0.0639 - acc: 0.9796 - val_loss: 0.2757 - val_acc: 0.9399\n",
      "Epoch 50/100\n",
      "76315/76315 [==============================] - 18s 231us/sample - loss: 0.0717 - acc: 0.9775 - val_loss: 0.2893 - val_acc: 0.9379\n",
      "Epoch 51/100\n",
      "76315/76315 [==============================] - 17s 222us/sample - loss: 0.0746 - acc: 0.9766 - val_loss: 0.2870 - val_acc: 0.9390\n",
      "Epoch 52/100\n",
      "76315/76315 [==============================] - 18s 236us/sample - loss: 0.0491 - acc: 0.9842 - val_loss: 0.2859 - val_acc: 0.9395\n",
      "Epoch 53/100\n",
      "76315/76315 [==============================] - 18s 237us/sample - loss: 0.0779 - acc: 0.9751 - val_loss: 0.2885 - val_acc: 0.9397\n",
      "Epoch 54/100\n",
      "76315/76315 [==============================] - 18s 235us/sample - loss: 0.0511 - acc: 0.9836 - val_loss: 0.2818 - val_acc: 0.9416\n",
      "Epoch 55/100\n",
      "76315/76315 [==============================] - 18s 241us/sample - loss: 0.0454 - acc: 0.9859 - val_loss: 0.2882 - val_acc: 0.9400\n",
      "Epoch 56/100\n",
      "76315/76315 [==============================] - 19s 243us/sample - loss: 0.0530 - acc: 0.9831 - val_loss: 0.3070 - val_acc: 0.9374\n",
      "Epoch 57/100\n",
      "76315/76315 [==============================] - 19s 255us/sample - loss: 0.0534 - acc: 0.9832 - val_loss: 0.3115 - val_acc: 0.9367\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76315/76315 [==============================] - 19s 251us/sample - loss: 0.0576 - acc: 0.9816 - val_loss: 0.2989 - val_acc: 0.9406\n",
      "Epoch 59/100\n",
      "76315/76315 [==============================] - 19s 246us/sample - loss: 0.0660 - acc: 0.9798 - val_loss: 0.3089 - val_acc: 0.9399\n",
      "Epoch 60/100\n",
      "76315/76315 [==============================] - 19s 243us/sample - loss: 0.0468 - acc: 0.9855 - val_loss: 0.3117 - val_acc: 0.9390\n",
      "Epoch 61/100\n",
      "76315/76315 [==============================] - 18s 232us/sample - loss: 0.0569 - acc: 0.9818 - val_loss: 0.3293 - val_acc: 0.9365\n",
      "Epoch 62/100\n",
      "76315/76315 [==============================] - 17s 225us/sample - loss: 0.1299 - acc: 0.9621 - val_loss: 0.3174 - val_acc: 0.9345\n",
      "Epoch 63/100\n",
      "76315/76315 [==============================] - 17s 218us/sample - loss: 0.0566 - acc: 0.9817 - val_loss: 0.2843 - val_acc: 0.9393\n",
      "Epoch 64/100\n",
      "76315/76315 [==============================] - 17s 217us/sample - loss: 0.0443 - acc: 0.9860 - val_loss: 0.2878 - val_acc: 0.9408\n",
      "Epoch 65/100\n",
      "76315/76315 [==============================] - 17s 226us/sample - loss: 0.0376 - acc: 0.9887 - val_loss: 0.3112 - val_acc: 0.9416\n",
      "Epoch 66/100\n",
      "76315/76315 [==============================] - 17s 224us/sample - loss: 0.0638 - acc: 0.9807 - val_loss: 0.3012 - val_acc: 0.9395\n",
      "Epoch 67/100\n",
      "76315/76315 [==============================] - 17s 224us/sample - loss: 0.0531 - acc: 0.9838 - val_loss: 0.3204 - val_acc: 0.9377\n",
      "Epoch 68/100\n",
      "76315/76315 [==============================] - 17s 217us/sample - loss: 0.0606 - acc: 0.9811 - val_loss: 0.3088 - val_acc: 0.9406\n",
      "Epoch 69/100\n",
      "76315/76315 [==============================] - 17s 224us/sample - loss: 0.0459 - acc: 0.9857 - val_loss: 0.3173 - val_acc: 0.9402\n",
      "Epoch 70/100\n",
      "76315/76315 [==============================] - 18s 235us/sample - loss: 0.0623 - acc: 0.9811 - val_loss: 0.3485 - val_acc: 0.9353\n",
      "Epoch 71/100\n",
      "76315/76315 [==============================] - 18s 240us/sample - loss: 0.0511 - acc: 0.9841 - val_loss: 0.3178 - val_acc: 0.9404\n",
      "Epoch 72/100\n",
      "76315/76315 [==============================] - 17s 226us/sample - loss: 0.0363 - acc: 0.9886 - val_loss: 0.3151 - val_acc: 0.9420\n",
      "Epoch 73/100\n",
      "76315/76315 [==============================] - 17s 228us/sample - loss: 0.0320 - acc: 0.9901 - val_loss: 0.3169 - val_acc: 0.9424\n",
      "Epoch 74/100\n",
      "76315/76315 [==============================] - 18s 233us/sample - loss: 0.0343 - acc: 0.9897 - val_loss: 0.3515 - val_acc: 0.9374\n",
      "Epoch 75/100\n",
      "76315/76315 [==============================] - 18s 232us/sample - loss: 0.0566 - acc: 0.9826 - val_loss: 0.3332 - val_acc: 0.9404\n",
      "Epoch 76/100\n",
      "76315/76315 [==============================] - 18s 233us/sample - loss: 0.0388 - acc: 0.9878 - val_loss: 0.3308 - val_acc: 0.9400\n",
      "Epoch 77/100\n",
      "76315/76315 [==============================] - 19s 245us/sample - loss: 0.0484 - acc: 0.9847 - val_loss: 0.3174 - val_acc: 0.9415\n",
      "Epoch 78/100\n",
      "76315/76315 [==============================] - 19s 246us/sample - loss: 0.0427 - acc: 0.9860 - val_loss: 0.3289 - val_acc: 0.9402\n",
      "Epoch 79/100\n",
      "76315/76315 [==============================] - 19s 246us/sample - loss: 0.0346 - acc: 0.9892 - val_loss: 0.3622 - val_acc: 0.9366\n",
      "Epoch 80/100\n",
      "76315/76315 [==============================] - 19s 244us/sample - loss: 0.0647 - acc: 0.9813 - val_loss: 0.3358 - val_acc: 0.9388\n",
      "Epoch 81/100\n",
      "76315/76315 [==============================] - 19s 255us/sample - loss: 0.0346 - acc: 0.9893 - val_loss: 0.3333 - val_acc: 0.9407\n",
      "Epoch 82/100\n",
      "76315/76315 [==============================] - 19s 249us/sample - loss: 0.0582 - acc: 0.9823 - val_loss: 0.3379 - val_acc: 0.9367\n",
      "Epoch 83/100\n",
      "76315/76315 [==============================] - 19s 253us/sample - loss: 0.0828 - acc: 0.9765 - val_loss: 0.3279 - val_acc: 0.9388\n",
      "Epoch 84/100\n",
      "76315/76315 [==============================] - 20s 257us/sample - loss: 0.0463 - acc: 0.9853 - val_loss: 0.3429 - val_acc: 0.9393\n",
      "Epoch 85/100\n",
      "76315/76315 [==============================] - 20s 260us/sample - loss: 0.0294 - acc: 0.9908 - val_loss: 0.3482 - val_acc: 0.9382\n",
      "Epoch 86/100\n",
      "76315/76315 [==============================] - 20s 259us/sample - loss: 0.0544 - acc: 0.9833 - val_loss: 0.3323 - val_acc: 0.9416\n",
      "Epoch 87/100\n",
      "76315/76315 [==============================] - 20s 259us/sample - loss: 0.0350 - acc: 0.9889 - val_loss: 0.3486 - val_acc: 0.9385\n",
      "Epoch 88/100\n",
      "76315/76315 [==============================] - 19s 248us/sample - loss: 0.0373 - acc: 0.9886 - val_loss: 0.3363 - val_acc: 0.9417\n",
      "Epoch 89/100\n",
      "76315/76315 [==============================] - 19s 246us/sample - loss: 0.0382 - acc: 0.9883 - val_loss: 0.3371 - val_acc: 0.9389\n",
      "Epoch 90/100\n",
      "76315/76315 [==============================] - 18s 242us/sample - loss: 0.0262 - acc: 0.9917 - val_loss: 0.3448 - val_acc: 0.9389\n",
      "Epoch 91/100\n",
      "76315/76315 [==============================] - 17s 228us/sample - loss: 0.0452 - acc: 0.9857 - val_loss: 0.3400 - val_acc: 0.9411\n",
      "Epoch 92/100\n",
      "76315/76315 [==============================] - 17s 218us/sample - loss: 0.0299 - acc: 0.9906 - val_loss: 0.3443 - val_acc: 0.9409\n",
      "Epoch 93/100\n",
      "76315/76315 [==============================] - 17s 220us/sample - loss: 0.0267 - acc: 0.9918 - val_loss: 0.3859 - val_acc: 0.9371\n",
      "Epoch 94/100\n",
      "76315/76315 [==============================] - 16s 212us/sample - loss: 0.0759 - acc: 0.9775 - val_loss: 0.3412 - val_acc: 0.9391\n",
      "Epoch 95/100\n",
      "76315/76315 [==============================] - 17s 221us/sample - loss: 0.0483 - acc: 0.9853 - val_loss: 0.3544 - val_acc: 0.9400\n",
      "Epoch 96/100\n",
      "76315/76315 [==============================] - 17s 217us/sample - loss: 0.0377 - acc: 0.9883 - val_loss: 0.3499 - val_acc: 0.9400\n",
      "Epoch 97/100\n",
      "76315/76315 [==============================] - 17s 223us/sample - loss: 0.0556 - acc: 0.9827 - val_loss: 0.3345 - val_acc: 0.9416\n",
      "Epoch 98/100\n",
      "76315/76315 [==============================] - 17s 219us/sample - loss: 0.0275 - acc: 0.9912 - val_loss: 0.3246 - val_acc: 0.9434\n",
      "Epoch 99/100\n",
      "76315/76315 [==============================] - 17s 225us/sample - loss: 0.0260 - acc: 0.9917 - val_loss: 0.3524 - val_acc: 0.9411\n",
      "Epoch 100/100\n",
      "76315/76315 [==============================] - 17s 227us/sample - loss: 0.0227 - acc: 0.9927 - val_loss: 0.3485 - val_acc: 0.9422\n"
     ]
    }
   ],
   "source": [
    "vm.model.train(X_train, Y_train, batch_size=512, epoch=100, validation_data=(X_test, Y_test), callbacks=[logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f94297cc4a8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(list(range(0, len(logger.training))), list(map(lambda x:x[1], logger.training)), label=\"training data\")\n",
    "plt.plot(list(range(0, len(logger.testing))), list(map(lambda x:x[1], logger.testing)), label=\"testing data\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.model.save(\"keyword-cnn.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'calm' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c563932882c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Now we load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{folder_path}/{f}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_break\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memotion_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_savee\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_savee\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprare_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_duration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/research/notebook/soundlib/prepare_data_utils.py\u001b[0m in \u001b[0;36mpreprare_wav\u001b[0;34m(data, vm, sample_duration, step)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mkey_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Doing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/notebook/soundlib/src/VoiceModule.py\u001b[0m in \u001b[0;36mlabel_vector\u001b[0;34m(self, label_name)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlabel_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert_prediction_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'calm' is not in list"
     ]
    }
   ],
   "source": [
    "# Now we load the new dataset (savee)\n",
    "emotion_list = [\"calm\", \"happy\", \"angry\", \"fearful\", \"surprised\", \"sad\"]\n",
    "# First we change the folder path\n",
    "# folder_path += \"/savee\"\n",
    "\n",
    "# Now we load the data\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in emotion_list}\n",
    "X_savee, Y_savee = preprare_wav(data, vm, sample_duration, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.model._model.evaluate(X_savee, Y_savee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we freeze every layer used for extracting features from data\n",
    "fine_tuned_model = Sequential(vm.model._model.layers[:-6])\n",
    "fine_tuned_model.add(Dense(128))\n",
    "fine_tuned_model.add(Dense(35))\n",
    "fine_tuned_model.add(Activation('softmax'))\n",
    "fine_tuned_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for layer in fine_tuned_model.layers[:-3]:\n",
    "    print(layer.name)\n",
    "    layer.trainable = False\n",
    "vm.model._model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
