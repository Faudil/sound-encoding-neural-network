{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import phase if every import is here it is to allow you to run this cell and know if you have any issue and not after a few hours of training\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, Activation, Flatten, MaxPooling1D, BatchNormalization, LSTM, GaussianNoise\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "from src.VoiceModule import VoiceModule\n",
    "from src.classifiers.KerasClassifier import KerasClassifier\n",
    "from prepare_data_utils import load_wav, preprare_wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bdes.zip\n",
      "fearful\n",
      "savee\n",
      "calm\n",
      "happy\n",
      "surprised\n",
      "angry\n",
      "sad\n",
      "keywords\n"
     ]
    }
   ],
   "source": [
    "# print environment\n",
    "folder_path = \"../../data\"\n",
    "for l in os.listdir(folder_path):\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data method\n",
    "\n",
    "def mfcc(buffer, samplerate, dim):\n",
    "    a = librosa.feature.mfcc(y=buffer, sr=samplerate, n_mfcc=dim)\n",
    "    a = np.transpose(a)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback to later draw some graphs\n",
    "\n",
    "class PerformanceLogger(Callback):\n",
    "    def __init__(self):\n",
    "        # List of tuple (loss, accuracy)\n",
    "        self.training = []\n",
    "        self.testing = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.training.append((logs[\"loss\"], logs[\"acc\"]))\n",
    "        self.testing.append((logs[\"val_loss\"], logs[\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prints metrics about a model\n",
    "def print_metrics(X, Y, label_name_list):\n",
    "    Y_pred = vm.model._model.predict(X)\n",
    "    Y_pred = np.argmax(Y_pred, axis=1)\n",
    "    Y_max = np.argmax(Y, axis=1)\n",
    "    print(confusion_matrix(Y_max, Y_pred))\n",
    "    print(classification_report(Y_max, Y_pred, target_names=label_name_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class\n",
    "class EmotionClassifierCnn(KerasClassifier):\n",
    "    def __init__(self, file_path=None):\n",
    "        super().__init__(file_path)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.expand_dims(np.array([x]), axis=2)\n",
    "        return self._model.predict(x)\n",
    "\n",
    "    def build(self):\n",
    "        model = Sequential()\n",
    "        model.add(GaussianNoise(0.4))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv1D(64, 3, input_shape=(35, 13), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(GaussianNoise(0.4))\n",
    "        model.add(Dense(64))\n",
    "        model.add(Dense(6))\n",
    "        model.add(Activation('softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self._model = model\n",
    "        \n",
    "    def train(self, X, Y, batch_size=32, epoch=720, validation_data=None, callbacks=[]):\n",
    "        self._model.fit(X, Y, batch_size=batch_size, epochs=epoch, validation_data=validation_data, callbacks=callbacks)\n",
    "\n",
    "    def transform(self, x, samplerate):\n",
    "        to_process = mfcc(x, samplerate, 13)\n",
    "        to_process = pad_sequences([to_process], maxlen=35, padding='post')[0]\n",
    "        return to_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciate model\n",
    "emotion_list = [\"calm\", \"happy\", \"angry\", \"fearful\", \"surprised\", \"sad\"]\n",
    "dimension_mfcc = 13\n",
    "samplerate = 16000\n",
    "nb_break=None\n",
    "sample_duration=1\n",
    "step=0.5\n",
    "\n",
    "logger = PerformanceLogger()\n",
    "\n",
    "cls = EmotionClassifierCnn()\n",
    "vm = VoiceModule(\"emotion-1s\", emotion_list, cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing calm\n",
      "Doing happy\n",
      "Doing angry\n",
      "Doing fearful\n",
      "Doing surprised\n",
      "Doing sad\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in emotion_list}\n",
    "X, Y = preprare_wav(data, vm, sample_duration, step)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_file = f\"x_{'_'.join(emotion_list)}-{vm._name}.npy\"\n",
    "Y_file = f\"y_{'_'.join(emotion_list)}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the prepared input data \n",
    "np.save(X_file, X)\n",
    "np.save(Y_file, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for training\n",
    "X, Y = np.load(X_file), np.load(Y_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5435 1359\n",
      "(35, 13)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "\"\"\"train_size = 80 * len(X) // 100\n",
    "test_size = 20 * len(X) // 100\n",
    "#X = np.expand_dims(X, axis=3)\n",
    "X_train, X_test, = X[:train_size], X[train_size:]\n",
    "Y_train, Y_test = Y[:train_size], Y[train_size:]\"\"\"\n",
    "X = X.astype('float32')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(len(X_train), len(X_test))\n",
    "\n",
    "print(X[0].shape)\n",
    "print( X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5435 samples, validate on 1359 samples\n",
      "Epoch 1/100\n",
      "5435/5435 [==============================] - 2s 396us/sample - loss: 2.3959 - acc: 0.2826 - val_loss: 2.1112 - val_acc: 0.2995\n",
      "Epoch 2/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 1.7286 - acc: 0.3776 - val_loss: 1.7016 - val_acc: 0.3223\n",
      "Epoch 3/100\n",
      "5435/5435 [==============================] - 2s 310us/sample - loss: 1.5915 - acc: 0.3989 - val_loss: 1.4749 - val_acc: 0.3996\n",
      "Epoch 4/100\n",
      "5435/5435 [==============================] - 2s 311us/sample - loss: 1.4934 - acc: 0.4250 - val_loss: 1.4324 - val_acc: 0.4165\n",
      "Epoch 5/100\n",
      "5435/5435 [==============================] - 2s 308us/sample - loss: 1.4295 - acc: 0.4456 - val_loss: 1.3950 - val_acc: 0.4371\n",
      "Epoch 6/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 1.3706 - acc: 0.4666 - val_loss: 1.3640 - val_acc: 0.4393\n",
      "Epoch 7/100\n",
      "5435/5435 [==============================] - 2s 305us/sample - loss: 1.3232 - acc: 0.4810 - val_loss: 1.3275 - val_acc: 0.4636\n",
      "Epoch 8/100\n",
      "5435/5435 [==============================] - 2s 310us/sample - loss: 1.2989 - acc: 0.4975 - val_loss: 1.3507 - val_acc: 0.4592\n",
      "Epoch 9/100\n",
      "5435/5435 [==============================] - 2s 311us/sample - loss: 1.2727 - acc: 0.4995 - val_loss: 1.3029 - val_acc: 0.4621\n",
      "Epoch 10/100\n",
      "5435/5435 [==============================] - 2s 315us/sample - loss: 1.2568 - acc: 0.5030 - val_loss: 1.3120 - val_acc: 0.4467\n",
      "Epoch 11/100\n",
      "5435/5435 [==============================] - 2s 314us/sample - loss: 1.2291 - acc: 0.5185 - val_loss: 1.2884 - val_acc: 0.4776\n",
      "Epoch 12/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 1.2245 - acc: 0.5284 - val_loss: 1.2690 - val_acc: 0.4768\n",
      "Epoch 13/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 1.1890 - acc: 0.5360 - val_loss: 1.2922 - val_acc: 0.4820\n",
      "Epoch 14/100\n",
      "5435/5435 [==============================] - 2s 313us/sample - loss: 1.1947 - acc: 0.5316 - val_loss: 1.2905 - val_acc: 0.4864\n",
      "Epoch 15/100\n",
      "5435/5435 [==============================] - 2s 311us/sample - loss: 1.1561 - acc: 0.5498 - val_loss: 1.2652 - val_acc: 0.4908\n",
      "Epoch 16/100\n",
      "5435/5435 [==============================] - 2s 309us/sample - loss: 1.1608 - acc: 0.5463 - val_loss: 1.2652 - val_acc: 0.4908\n",
      "Epoch 17/100\n",
      "5435/5435 [==============================] - 2s 305us/sample - loss: 1.1407 - acc: 0.5566 - val_loss: 1.2503 - val_acc: 0.5011\n",
      "Epoch 18/100\n",
      "5435/5435 [==============================] - 2s 315us/sample - loss: 1.1350 - acc: 0.5656 - val_loss: 1.2380 - val_acc: 0.5107\n",
      "Epoch 19/100\n",
      "5435/5435 [==============================] - 2s 313us/sample - loss: 1.1195 - acc: 0.5599 - val_loss: 1.2179 - val_acc: 0.4974\n",
      "Epoch 20/100\n",
      "5435/5435 [==============================] - 2s 309us/sample - loss: 1.1197 - acc: 0.5689 - val_loss: 1.2389 - val_acc: 0.5026\n",
      "Epoch 21/100\n",
      "5435/5435 [==============================] - 2s 308us/sample - loss: 1.1081 - acc: 0.5671 - val_loss: 1.2583 - val_acc: 0.4989\n",
      "Epoch 22/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 1.1170 - acc: 0.5715 - val_loss: 1.2286 - val_acc: 0.4879\n",
      "Epoch 23/100\n",
      "5435/5435 [==============================] - 2s 311us/sample - loss: 1.0947 - acc: 0.5785 - val_loss: 1.2111 - val_acc: 0.5026\n",
      "Epoch 24/100\n",
      "5435/5435 [==============================] - 2s 309us/sample - loss: 1.0882 - acc: 0.5827 - val_loss: 1.2055 - val_acc: 0.5188\n",
      "Epoch 25/100\n",
      "5435/5435 [==============================] - 2s 309us/sample - loss: 1.0934 - acc: 0.5801 - val_loss: 1.1974 - val_acc: 0.5166\n",
      "Epoch 26/100\n",
      "5435/5435 [==============================] - 2s 309us/sample - loss: 1.0730 - acc: 0.5879 - val_loss: 1.1956 - val_acc: 0.5173\n",
      "Epoch 27/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 1.0601 - acc: 0.5976 - val_loss: 1.2074 - val_acc: 0.5143\n",
      "Epoch 28/100\n",
      "5435/5435 [==============================] - 2s 310us/sample - loss: 1.0624 - acc: 0.5936 - val_loss: 1.1879 - val_acc: 0.5158\n",
      "Epoch 29/100\n",
      "5435/5435 [==============================] - 2s 310us/sample - loss: 1.0578 - acc: 0.5926 - val_loss: 1.1999 - val_acc: 0.5188\n",
      "Epoch 30/100\n",
      "5435/5435 [==============================] - 2s 309us/sample - loss: 1.0435 - acc: 0.5976 - val_loss: 1.1958 - val_acc: 0.5188\n",
      "Epoch 31/100\n",
      "5435/5435 [==============================] - 2s 308us/sample - loss: 1.0522 - acc: 0.5915 - val_loss: 1.1897 - val_acc: 0.5276\n",
      "Epoch 32/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 1.0567 - acc: 0.5969 - val_loss: 1.1924 - val_acc: 0.5224\n",
      "Epoch 33/100\n",
      "5435/5435 [==============================] - 2s 309us/sample - loss: 1.0488 - acc: 0.5853 - val_loss: 1.1789 - val_acc: 0.5180\n",
      "Epoch 34/100\n",
      "5435/5435 [==============================] - 2s 308us/sample - loss: 1.0445 - acc: 0.5919 - val_loss: 1.1800 - val_acc: 0.5180\n",
      "Epoch 35/100\n",
      "5435/5435 [==============================] - 2s 311us/sample - loss: 1.0191 - acc: 0.6040 - val_loss: 1.1546 - val_acc: 0.5386\n",
      "Epoch 36/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 1.0234 - acc: 0.6048 - val_loss: 1.1635 - val_acc: 0.5394\n",
      "Epoch 37/100\n",
      "5435/5435 [==============================] - 2s 315us/sample - loss: 1.0372 - acc: 0.5987 - val_loss: 1.1673 - val_acc: 0.5320\n",
      "Epoch 38/100\n",
      "5435/5435 [==============================] - 2s 311us/sample - loss: 1.0173 - acc: 0.6103 - val_loss: 1.1628 - val_acc: 0.5298\n",
      "Epoch 39/100\n",
      "5435/5435 [==============================] - 2s 309us/sample - loss: 1.0088 - acc: 0.6105 - val_loss: 1.1561 - val_acc: 0.5276\n",
      "Epoch 40/100\n",
      "5435/5435 [==============================] - 2s 313us/sample - loss: 1.0111 - acc: 0.6061 - val_loss: 1.1636 - val_acc: 0.5247\n",
      "Epoch 41/100\n",
      "5435/5435 [==============================] - 2s 314us/sample - loss: 1.0094 - acc: 0.6151 - val_loss: 1.1690 - val_acc: 0.5423\n",
      "Epoch 42/100\n",
      "5435/5435 [==============================] - 2s 323us/sample - loss: 1.0187 - acc: 0.6094 - val_loss: 1.1769 - val_acc: 0.5401\n",
      "Epoch 43/100\n",
      "5435/5435 [==============================] - 2s 317us/sample - loss: 1.0030 - acc: 0.6075 - val_loss: 1.1731 - val_acc: 0.5210\n",
      "Epoch 44/100\n",
      "5435/5435 [==============================] - 2s 314us/sample - loss: 0.9874 - acc: 0.6190 - val_loss: 1.1484 - val_acc: 0.5430\n",
      "Epoch 45/100\n",
      "5435/5435 [==============================] - 2s 309us/sample - loss: 1.0043 - acc: 0.6162 - val_loss: 1.1651 - val_acc: 0.5276\n",
      "Epoch 46/100\n",
      "5435/5435 [==============================] - 2s 311us/sample - loss: 0.9735 - acc: 0.6256 - val_loss: 1.1641 - val_acc: 0.5519\n",
      "Epoch 47/100\n",
      "5435/5435 [==============================] - 2s 308us/sample - loss: 0.9740 - acc: 0.6265 - val_loss: 1.1643 - val_acc: 0.5239\n",
      "Epoch 48/100\n",
      "5435/5435 [==============================] - 2s 313us/sample - loss: 0.9787 - acc: 0.6223 - val_loss: 1.1612 - val_acc: 0.5261\n",
      "Epoch 49/100\n",
      "5435/5435 [==============================] - 2s 320us/sample - loss: 0.9752 - acc: 0.6241 - val_loss: 1.1477 - val_acc: 0.5342\n",
      "Epoch 50/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 0.9664 - acc: 0.6293 - val_loss: 1.1853 - val_acc: 0.5202\n",
      "Epoch 51/100\n",
      "5435/5435 [==============================] - 2s 311us/sample - loss: 0.9705 - acc: 0.6228 - val_loss: 1.1493 - val_acc: 0.5350\n",
      "Epoch 52/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 0.9724 - acc: 0.6269 - val_loss: 1.1430 - val_acc: 0.5519\n",
      "Epoch 53/100\n",
      "5435/5435 [==============================] - 2s 314us/sample - loss: 0.9619 - acc: 0.6322 - val_loss: 1.1414 - val_acc: 0.5504\n",
      "Epoch 54/100\n",
      "5435/5435 [==============================] - 2s 310us/sample - loss: 0.9685 - acc: 0.6254 - val_loss: 1.1628 - val_acc: 0.5335\n",
      "Epoch 55/100\n",
      "5435/5435 [==============================] - 2s 311us/sample - loss: 0.9593 - acc: 0.6309 - val_loss: 1.1756 - val_acc: 0.5364\n",
      "Epoch 56/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 0.9715 - acc: 0.6322 - val_loss: 1.1474 - val_acc: 0.5401\n",
      "Epoch 57/100\n",
      "5435/5435 [==============================] - 2s 310us/sample - loss: 0.9465 - acc: 0.6342 - val_loss: 1.1338 - val_acc: 0.5607\n",
      "Epoch 58/100\n",
      "5435/5435 [==============================] - 2s 310us/sample - loss: 0.9559 - acc: 0.6333 - val_loss: 1.1363 - val_acc: 0.5541\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5435/5435 [==============================] - 2s 308us/sample - loss: 0.9612 - acc: 0.6245 - val_loss: 1.1282 - val_acc: 0.5585\n",
      "Epoch 60/100\n",
      "5435/5435 [==============================] - 2s 311us/sample - loss: 0.9531 - acc: 0.6386 - val_loss: 1.1385 - val_acc: 0.5533\n",
      "Epoch 61/100\n",
      "5435/5435 [==============================] - 2s 310us/sample - loss: 0.9492 - acc: 0.6316 - val_loss: 1.1338 - val_acc: 0.5600\n",
      "Epoch 62/100\n",
      "5435/5435 [==============================] - 2s 310us/sample - loss: 0.9206 - acc: 0.6449 - val_loss: 1.1150 - val_acc: 0.5592\n",
      "Epoch 63/100\n",
      "5435/5435 [==============================] - 2s 310us/sample - loss: 0.9315 - acc: 0.6460 - val_loss: 1.1226 - val_acc: 0.5533\n",
      "Epoch 64/100\n",
      "5435/5435 [==============================] - 2s 309us/sample - loss: 0.9504 - acc: 0.6329 - val_loss: 1.1428 - val_acc: 0.5438\n",
      "Epoch 65/100\n",
      "5435/5435 [==============================] - 2s 314us/sample - loss: 0.9451 - acc: 0.6328 - val_loss: 1.1485 - val_acc: 0.5453\n",
      "Epoch 66/100\n",
      "5435/5435 [==============================] - 2s 309us/sample - loss: 0.9351 - acc: 0.6390 - val_loss: 1.1251 - val_acc: 0.5533\n",
      "Epoch 67/100\n",
      "5435/5435 [==============================] - 2s 317us/sample - loss: 0.9300 - acc: 0.6374 - val_loss: 1.1367 - val_acc: 0.5533\n",
      "Epoch 68/100\n",
      "5435/5435 [==============================] - 2s 314us/sample - loss: 0.9538 - acc: 0.6399 - val_loss: 1.1304 - val_acc: 0.5401\n",
      "Epoch 69/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 0.9196 - acc: 0.6489 - val_loss: 1.1476 - val_acc: 0.5541\n",
      "Epoch 70/100\n",
      "5435/5435 [==============================] - 2s 314us/sample - loss: 0.9081 - acc: 0.6478 - val_loss: 1.1262 - val_acc: 0.5556\n",
      "Epoch 71/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 0.9262 - acc: 0.6493 - val_loss: 1.1431 - val_acc: 0.5585\n",
      "Epoch 72/100\n",
      "5435/5435 [==============================] - 2s 313us/sample - loss: 0.9217 - acc: 0.6475 - val_loss: 1.1209 - val_acc: 0.5578\n",
      "Epoch 73/100\n",
      "5435/5435 [==============================] - 2s 310us/sample - loss: 0.9308 - acc: 0.6388 - val_loss: 1.1234 - val_acc: 0.5556\n",
      "Epoch 74/100\n",
      "5435/5435 [==============================] - 2s 316us/sample - loss: 0.9144 - acc: 0.6489 - val_loss: 1.1367 - val_acc: 0.5519\n",
      "Epoch 75/100\n",
      "5435/5435 [==============================] - 2s 316us/sample - loss: 0.9296 - acc: 0.6396 - val_loss: 1.1276 - val_acc: 0.5416\n",
      "Epoch 76/100\n",
      "5435/5435 [==============================] - 2s 316us/sample - loss: 0.9017 - acc: 0.6504 - val_loss: 1.1408 - val_acc: 0.5570\n",
      "Epoch 77/100\n",
      "5435/5435 [==============================] - 2s 315us/sample - loss: 0.9120 - acc: 0.6489 - val_loss: 1.1257 - val_acc: 0.5548\n",
      "Epoch 78/100\n",
      "5435/5435 [==============================] - 2s 311us/sample - loss: 0.9215 - acc: 0.6482 - val_loss: 1.1171 - val_acc: 0.5644\n",
      "Epoch 79/100\n",
      "5435/5435 [==============================] - 2s 311us/sample - loss: 0.9132 - acc: 0.6508 - val_loss: 1.1336 - val_acc: 0.5666\n",
      "Epoch 80/100\n",
      "5435/5435 [==============================] - 2s 314us/sample - loss: 0.9049 - acc: 0.6493 - val_loss: 1.1329 - val_acc: 0.5556\n",
      "Epoch 81/100\n",
      "5435/5435 [==============================] - 2s 308us/sample - loss: 0.9328 - acc: 0.6451 - val_loss: 1.1227 - val_acc: 0.5688\n",
      "Epoch 82/100\n",
      "5435/5435 [==============================] - 2s 308us/sample - loss: 0.9103 - acc: 0.6473 - val_loss: 1.1259 - val_acc: 0.5651\n",
      "Epoch 83/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 0.9070 - acc: 0.6502 - val_loss: 1.1056 - val_acc: 0.5681\n",
      "Epoch 84/100\n",
      "5435/5435 [==============================] - 2s 308us/sample - loss: 0.9141 - acc: 0.6489 - val_loss: 1.1197 - val_acc: 0.5717\n",
      "Epoch 85/100\n",
      "5435/5435 [==============================] - 2s 309us/sample - loss: 0.8824 - acc: 0.6620 - val_loss: 1.1192 - val_acc: 0.5585\n",
      "Epoch 86/100\n",
      "5435/5435 [==============================] - 2s 307us/sample - loss: 0.9027 - acc: 0.6521 - val_loss: 1.1239 - val_acc: 0.5519\n",
      "Epoch 87/100\n",
      "5435/5435 [==============================] - 2s 308us/sample - loss: 0.8885 - acc: 0.6602 - val_loss: 1.1530 - val_acc: 0.5717\n",
      "Epoch 88/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 0.8957 - acc: 0.6603 - val_loss: 1.1138 - val_acc: 0.5666\n",
      "Epoch 89/100\n",
      "5435/5435 [==============================] - 2s 313us/sample - loss: 0.8928 - acc: 0.6605 - val_loss: 1.1240 - val_acc: 0.5636\n",
      "Epoch 90/100\n",
      "5435/5435 [==============================] - 2s 313us/sample - loss: 0.8929 - acc: 0.6543 - val_loss: 1.1365 - val_acc: 0.5504\n",
      "Epoch 91/100\n",
      "5435/5435 [==============================] - 2s 313us/sample - loss: 0.9011 - acc: 0.6508 - val_loss: 1.1139 - val_acc: 0.5710\n",
      "Epoch 92/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 0.8851 - acc: 0.6633 - val_loss: 1.1087 - val_acc: 0.5703\n",
      "Epoch 93/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 0.8677 - acc: 0.6684 - val_loss: 1.1095 - val_acc: 0.5673\n",
      "Epoch 94/100\n",
      "5435/5435 [==============================] - 2s 314us/sample - loss: 0.8729 - acc: 0.6686 - val_loss: 1.1103 - val_acc: 0.5614\n",
      "Epoch 95/100\n",
      "5435/5435 [==============================] - 2s 311us/sample - loss: 0.8820 - acc: 0.6620 - val_loss: 1.1280 - val_acc: 0.5681\n",
      "Epoch 96/100\n",
      "5435/5435 [==============================] - 2s 315us/sample - loss: 0.8726 - acc: 0.6626 - val_loss: 1.1220 - val_acc: 0.5703\n",
      "Epoch 97/100\n",
      "5435/5435 [==============================] - 2s 311us/sample - loss: 0.8792 - acc: 0.6603 - val_loss: 1.1206 - val_acc: 0.5651\n",
      "Epoch 98/100\n",
      "5435/5435 [==============================] - 2s 309us/sample - loss: 0.8751 - acc: 0.6683 - val_loss: 1.1388 - val_acc: 0.5703\n",
      "Epoch 99/100\n",
      "5435/5435 [==============================] - 2s 310us/sample - loss: 0.8754 - acc: 0.6620 - val_loss: 1.1320 - val_acc: 0.5636\n",
      "Epoch 100/100\n",
      "5435/5435 [==============================] - 2s 312us/sample - loss: 0.8865 - acc: 0.6631 - val_loss: 1.1323 - val_acc: 0.5673\n"
     ]
    }
   ],
   "source": [
    "vm.model.train(X_train, Y_train, batch_size=64, epoch=100, validation_data=(X_test, Y_test), callbacks=[logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f21843be588>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[164  24   4   8  16  30]\n",
      " [  9 121  24  25  24  15]\n",
      " [  5  24 164  19  12  12]\n",
      " [  6  22  30 111  25  17]\n",
      " [  9  28  19  32 103  21]\n",
      " [ 39  33  15  26  15 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.71      0.67      0.69       246\n",
      "       happy       0.48      0.56      0.51       218\n",
      "       angry       0.64      0.69      0.67       236\n",
      "     fearful       0.50      0.53      0.51       211\n",
      "   surprised       0.53      0.49      0.51       212\n",
      "         sad       0.53      0.46      0.49       236\n",
      "\n",
      "    accuracy                           0.57      1359\n",
      "   macro avg       0.57      0.56      0.56      1359\n",
      "weighted avg       0.57      0.57      0.57      1359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(list(range(0, len(logger.training))), list(map(lambda x:x[1], logger.training)), label=\"training data\")\n",
    "plt.plot(list(range(0, len(logger.testing))), list(map(lambda x:x[1], logger.testing)), label=\"testing data\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "print_metrics(X_test, Y_test, emotion_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this graph we can see that the model largely overfit around the 20st epoch\n",
    "We can also see that the testing data's accuracy continues to grow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we save the model so we don't have to retrain it each time\n",
    "vm.model.save(\"emotion_cnn-1s.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Here we load the model to check if nothing went wrong\n",
    "vm.model.load(\"emotion_lstm-1s.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing calm\n",
      "Doing happy\n",
      "Doing angry\n",
      "Doing fearful\n",
      "Doing surprised\n",
      "Doing sad\n"
     ]
    }
   ],
   "source": [
    "# Now we load the new dataset (savee)\n",
    "\n",
    "# First we change the folder path\n",
    "folder_path += \"/savee\"\n",
    "\n",
    "# Now we load the data\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in emotion_list}\n",
    "X_savee, Y_savee = preprare_wav(data, vm, sample_duration, step)\n",
    "X_savee = X_savee.astype('float32')\n",
    "X_savee_train, X_savee_test, Y_savee_train, Y_savee_test = train_test_split(X_savee, Y_savee, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2582, 35, 13)\n",
      "2582/2582 [==============================] - 0s 131us/sample - loss: 7.2557 - acc: 0.2091\n",
      "[[ 58 219 180   0 155  73]\n",
      " [ 13 126 106   5  89  29]\n",
      " [  7  91 141   0  98  21]\n",
      " [ 15  85 126   3 106  23]\n",
      " [  7  77  93   9 156  21]\n",
      " [ 36 122 141   7  88  56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.43      0.08      0.14       685\n",
      "       happy       0.17      0.34      0.23       368\n",
      "       angry       0.18      0.39      0.25       358\n",
      "     fearful       0.12      0.01      0.02       358\n",
      "   surprised       0.23      0.43      0.30       363\n",
      "         sad       0.25      0.12      0.17       450\n",
      "\n",
      "    accuracy                           0.21      2582\n",
      "   macro avg       0.23      0.23      0.18      2582\n",
      "weighted avg       0.26      0.21      0.18      2582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X_savee.shape)\n",
    "vm.model._model.evaluate(X_savee, Y_savee)\n",
    "print_metrics(X_savee, Y_savee, emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_noise_2\n",
      "batch_normalization_2\n",
      "conv1d_1\n",
      "activation_2\n",
      "max_pooling1d_1\n",
      "flatten_1\n",
      "batch_normalization_3\n",
      "dropout_1\n",
      "gaussian_noise_3\n"
     ]
    }
   ],
   "source": [
    "# Now we freeze every layer used for extracting features from data\n",
    "for layer in vm.model._model.layers[:-3]:\n",
    "    print(layer.name)\n",
    "    layer.trainable = False\n",
    "vm.model._model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2065 samples, validate on 517 samples\n",
      "Epoch 1/100\n",
      "2065/2065 [==============================] - 2s 913us/sample - loss: 1.6701 - acc: 0.3419 - val_loss: 3.4358 - val_acc: 0.3578\n",
      "Epoch 2/100\n",
      "2065/2065 [==============================] - 2s 787us/sample - loss: 1.3238 - acc: 0.4547 - val_loss: 4.5347 - val_acc: 0.3617\n",
      "Epoch 3/100\n",
      "2065/2065 [==============================] - 2s 770us/sample - loss: 1.2746 - acc: 0.4872 - val_loss: 3.8573 - val_acc: 0.3830\n",
      "Epoch 4/100\n",
      "2065/2065 [==============================] - 2s 773us/sample - loss: 1.2522 - acc: 0.5031 - val_loss: 3.9890 - val_acc: 0.3868\n",
      "Epoch 5/100\n",
      "2065/2065 [==============================] - 2s 752us/sample - loss: 1.1888 - acc: 0.5177 - val_loss: 4.2616 - val_acc: 0.3830\n",
      "Epoch 6/100\n",
      "2065/2065 [==============================] - 2s 748us/sample - loss: 1.1902 - acc: 0.5337 - val_loss: 4.4251 - val_acc: 0.3636\n",
      "Epoch 7/100\n",
      "2065/2065 [==============================] - 2s 758us/sample - loss: 1.1551 - acc: 0.5259 - val_loss: 5.0121 - val_acc: 0.3482\n",
      "Epoch 8/100\n",
      "2065/2065 [==============================] - 2s 741us/sample - loss: 1.1177 - acc: 0.5462 - val_loss: 4.7344 - val_acc: 0.3752\n",
      "Epoch 9/100\n",
      "2065/2065 [==============================] - 2s 769us/sample - loss: 1.1576 - acc: 0.5375 - val_loss: 4.0734 - val_acc: 0.3656\n",
      "Epoch 10/100\n",
      "2065/2065 [==============================] - 2s 752us/sample - loss: 1.1448 - acc: 0.5332 - val_loss: 4.3782 - val_acc: 0.3985\n",
      "Epoch 11/100\n",
      "2065/2065 [==============================] - 2s 749us/sample - loss: 1.1138 - acc: 0.5588 - val_loss: 4.1641 - val_acc: 0.3907\n",
      "Epoch 12/100\n",
      "2065/2065 [==============================] - 2s 759us/sample - loss: 1.0944 - acc: 0.5797 - val_loss: 4.5388 - val_acc: 0.3791\n",
      "Epoch 13/100\n",
      "2065/2065 [==============================] - 2s 761us/sample - loss: 1.1160 - acc: 0.5603 - val_loss: 5.2775 - val_acc: 0.3714\n",
      "Epoch 14/100\n",
      "2065/2065 [==============================] - 2s 758us/sample - loss: 1.1117 - acc: 0.5709 - val_loss: 4.7366 - val_acc: 0.3733\n",
      "Epoch 15/100\n",
      "2065/2065 [==============================] - 2s 755us/sample - loss: 1.0936 - acc: 0.5680 - val_loss: 4.3923 - val_acc: 0.3675\n",
      "Epoch 16/100\n",
      "2065/2065 [==============================] - 2s 746us/sample - loss: 1.1101 - acc: 0.5574 - val_loss: 5.2297 - val_acc: 0.3752\n",
      "Epoch 17/100\n",
      "2065/2065 [==============================] - 2s 744us/sample - loss: 1.1236 - acc: 0.5627 - val_loss: 5.0264 - val_acc: 0.3714\n",
      "Epoch 18/100\n",
      "2065/2065 [==============================] - 2s 766us/sample - loss: 1.1205 - acc: 0.5506 - val_loss: 4.8173 - val_acc: 0.3714\n",
      "Epoch 19/100\n",
      "2065/2065 [==============================] - 2s 760us/sample - loss: 1.0974 - acc: 0.5637 - val_loss: 4.4760 - val_acc: 0.3598\n",
      "Epoch 20/100\n",
      "2065/2065 [==============================] - 2s 760us/sample - loss: 1.0897 - acc: 0.5792 - val_loss: 5.1083 - val_acc: 0.3830\n",
      "Epoch 21/100\n",
      "2065/2065 [==============================] - 2s 764us/sample - loss: 1.1093 - acc: 0.5651 - val_loss: 5.0242 - val_acc: 0.3830\n",
      "Epoch 22/100\n",
      "2065/2065 [==============================] - 2s 760us/sample - loss: 1.0922 - acc: 0.5792 - val_loss: 5.5069 - val_acc: 0.3772\n",
      "Epoch 23/100\n",
      "2065/2065 [==============================] - 2s 755us/sample - loss: 1.0861 - acc: 0.5709 - val_loss: 4.6580 - val_acc: 0.3636\n",
      "Epoch 24/100\n",
      "2065/2065 [==============================] - 2s 751us/sample - loss: 1.0887 - acc: 0.5787 - val_loss: 4.9248 - val_acc: 0.3694\n",
      "Epoch 25/100\n",
      "2065/2065 [==============================] - 2s 760us/sample - loss: 1.0546 - acc: 0.5782 - val_loss: 6.0675 - val_acc: 0.3617\n",
      "Epoch 26/100\n",
      "2065/2065 [==============================] - 2s 758us/sample - loss: 1.1050 - acc: 0.5613 - val_loss: 4.8763 - val_acc: 0.3810\n",
      "Epoch 27/100\n",
      "2065/2065 [==============================] - 2s 750us/sample - loss: 1.0801 - acc: 0.5661 - val_loss: 5.4676 - val_acc: 0.3868\n",
      "Epoch 28/100\n",
      "2065/2065 [==============================] - 2s 758us/sample - loss: 1.0831 - acc: 0.5801 - val_loss: 5.9575 - val_acc: 0.3733\n",
      "Epoch 29/100\n",
      "2065/2065 [==============================] - 2s 755us/sample - loss: 1.0663 - acc: 0.5685 - val_loss: 4.7236 - val_acc: 0.3694\n",
      "Epoch 30/100\n",
      "2065/2065 [==============================] - 2s 759us/sample - loss: 1.0680 - acc: 0.5763 - val_loss: 5.6317 - val_acc: 0.3578\n",
      "Epoch 31/100\n",
      "2065/2065 [==============================] - 2s 759us/sample - loss: 1.0890 - acc: 0.5763 - val_loss: 4.5648 - val_acc: 0.3772\n",
      "Epoch 32/100\n",
      "2065/2065 [==============================] - 2s 760us/sample - loss: 1.0963 - acc: 0.5719 - val_loss: 5.4821 - val_acc: 0.3791\n",
      "Epoch 33/100\n",
      "2065/2065 [==============================] - 2s 763us/sample - loss: 1.0770 - acc: 0.5719 - val_loss: 5.7014 - val_acc: 0.3907\n",
      "Epoch 34/100\n",
      "2065/2065 [==============================] - 2s 753us/sample - loss: 1.0897 - acc: 0.5593 - val_loss: 4.9402 - val_acc: 0.3849\n",
      "Epoch 35/100\n",
      "2065/2065 [==============================] - 2s 764us/sample - loss: 1.0887 - acc: 0.5787 - val_loss: 5.8784 - val_acc: 0.3327\n",
      "Epoch 36/100\n",
      "2065/2065 [==============================] - 2s 756us/sample - loss: 1.0731 - acc: 0.5642 - val_loss: 5.4377 - val_acc: 0.3694\n",
      "Epoch 37/100\n",
      "2065/2065 [==============================] - 2s 756us/sample - loss: 1.0902 - acc: 0.5758 - val_loss: 4.5996 - val_acc: 0.3830\n",
      "Epoch 38/100\n",
      "2065/2065 [==============================] - 2s 752us/sample - loss: 1.0812 - acc: 0.5637 - val_loss: 5.3945 - val_acc: 0.3772\n",
      "Epoch 39/100\n",
      "2065/2065 [==============================] - 2s 749us/sample - loss: 1.0645 - acc: 0.5864 - val_loss: 5.3573 - val_acc: 0.3559\n",
      "Epoch 40/100\n",
      "2065/2065 [==============================] - 2s 757us/sample - loss: 1.0801 - acc: 0.5782 - val_loss: 5.1907 - val_acc: 0.3772\n",
      "Epoch 41/100\n",
      "2065/2065 [==============================] - 2s 757us/sample - loss: 1.1012 - acc: 0.5579 - val_loss: 5.5491 - val_acc: 0.3636\n",
      "Epoch 42/100\n",
      "2065/2065 [==============================] - 2s 765us/sample - loss: 1.0762 - acc: 0.5729 - val_loss: 5.2947 - val_acc: 0.3617\n",
      "Epoch 43/100\n",
      "2065/2065 [==============================] - 2s 758us/sample - loss: 1.0718 - acc: 0.5811 - val_loss: 4.4611 - val_acc: 0.3830\n",
      "Epoch 44/100\n",
      "2065/2065 [==============================] - 2s 758us/sample - loss: 1.0871 - acc: 0.5729 - val_loss: 5.6796 - val_acc: 0.3675\n",
      "Epoch 45/100\n",
      "2065/2065 [==============================] - 2s 764us/sample - loss: 1.1211 - acc: 0.5666 - val_loss: 5.6734 - val_acc: 0.3501\n",
      "Epoch 46/100\n",
      "2065/2065 [==============================] - 2s 767us/sample - loss: 1.0496 - acc: 0.5923 - val_loss: 4.9938 - val_acc: 0.3926\n",
      "Epoch 47/100\n",
      "2065/2065 [==============================] - 2s 758us/sample - loss: 1.0925 - acc: 0.5743 - val_loss: 4.7075 - val_acc: 0.3907\n",
      "Epoch 48/100\n",
      "2065/2065 [==============================] - 2s 763us/sample - loss: 1.0680 - acc: 0.5855 - val_loss: 5.5812 - val_acc: 0.3752\n",
      "Epoch 49/100\n",
      "2065/2065 [==============================] - 2s 762us/sample - loss: 1.0565 - acc: 0.5850 - val_loss: 5.3372 - val_acc: 0.3733\n",
      "Epoch 50/100\n",
      "2065/2065 [==============================] - 2s 774us/sample - loss: 1.0693 - acc: 0.5961 - val_loss: 4.6961 - val_acc: 0.3810\n",
      "Epoch 51/100\n",
      "2065/2065 [==============================] - 2s 756us/sample - loss: 1.0550 - acc: 0.5942 - val_loss: 5.3603 - val_acc: 0.3830\n",
      "Epoch 52/100\n",
      "2065/2065 [==============================] - 2s 758us/sample - loss: 1.0898 - acc: 0.5860 - val_loss: 5.1460 - val_acc: 0.3694\n",
      "Epoch 53/100\n",
      "2065/2065 [==============================] - 2s 768us/sample - loss: 1.0703 - acc: 0.5709 - val_loss: 4.9002 - val_acc: 0.3810\n",
      "Epoch 54/100\n",
      "2065/2065 [==============================] - 2s 767us/sample - loss: 1.0680 - acc: 0.5772 - val_loss: 5.7471 - val_acc: 0.3482\n",
      "Epoch 55/100\n",
      "2065/2065 [==============================] - 2s 767us/sample - loss: 1.0549 - acc: 0.5840 - val_loss: 4.6968 - val_acc: 0.3849\n",
      "Epoch 56/100\n",
      "2065/2065 [==============================] - 2s 768us/sample - loss: 1.0679 - acc: 0.5685 - val_loss: 5.0431 - val_acc: 0.3946\n",
      "Epoch 57/100\n",
      "2065/2065 [==============================] - 2s 760us/sample - loss: 1.0890 - acc: 0.5758 - val_loss: 5.3561 - val_acc: 0.3598\n",
      "Epoch 58/100\n",
      "2065/2065 [==============================] - 2s 758us/sample - loss: 1.0727 - acc: 0.5748 - val_loss: 4.8957 - val_acc: 0.4004\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2065/2065 [==============================] - 2s 761us/sample - loss: 1.0328 - acc: 0.6000 - val_loss: 4.7415 - val_acc: 0.3965\n",
      "Epoch 60/100\n",
      "2065/2065 [==============================] - 2s 771us/sample - loss: 1.0737 - acc: 0.5869 - val_loss: 5.3767 - val_acc: 0.3694\n",
      "Epoch 61/100\n",
      "2065/2065 [==============================] - 2s 764us/sample - loss: 1.0573 - acc: 0.5816 - val_loss: 4.7294 - val_acc: 0.3714\n",
      "Epoch 62/100\n",
      "2065/2065 [==============================] - 2s 762us/sample - loss: 1.0669 - acc: 0.5821 - val_loss: 5.0207 - val_acc: 0.3714\n",
      "Epoch 63/100\n",
      "2065/2065 [==============================] - 2s 763us/sample - loss: 1.0514 - acc: 0.5763 - val_loss: 5.1709 - val_acc: 0.3714\n",
      "Epoch 64/100\n",
      "2065/2065 [==============================] - 2s 759us/sample - loss: 1.0977 - acc: 0.5855 - val_loss: 5.3795 - val_acc: 0.3636\n",
      "Epoch 65/100\n",
      "2065/2065 [==============================] - 2s 754us/sample - loss: 1.0795 - acc: 0.5627 - val_loss: 4.2547 - val_acc: 0.3830\n",
      "Epoch 66/100\n",
      "2065/2065 [==============================] - 2s 761us/sample - loss: 1.0464 - acc: 0.5971 - val_loss: 4.6335 - val_acc: 0.3694\n",
      "Epoch 67/100\n",
      "2065/2065 [==============================] - 2s 763us/sample - loss: 1.0512 - acc: 0.5816 - val_loss: 5.6066 - val_acc: 0.3656\n",
      "Epoch 68/100\n",
      "2065/2065 [==============================] - 2s 761us/sample - loss: 1.0876 - acc: 0.5855 - val_loss: 5.4242 - val_acc: 0.3636\n",
      "Epoch 69/100\n",
      "2065/2065 [==============================] - 2s 758us/sample - loss: 1.0627 - acc: 0.5879 - val_loss: 5.0087 - val_acc: 0.3907\n",
      "Epoch 70/100\n",
      "2065/2065 [==============================] - 2s 745us/sample - loss: 1.0638 - acc: 0.5864 - val_loss: 4.9770 - val_acc: 0.3907\n",
      "Epoch 71/100\n",
      "2065/2065 [==============================] - 2s 743us/sample - loss: 1.0518 - acc: 0.5835 - val_loss: 5.2472 - val_acc: 0.3752\n",
      "Epoch 72/100\n",
      "2065/2065 [==============================] - 2s 773us/sample - loss: 1.0646 - acc: 0.5860 - val_loss: 5.0159 - val_acc: 0.3810\n",
      "Epoch 73/100\n",
      "2065/2065 [==============================] - 2s 766us/sample - loss: 1.0607 - acc: 0.5738 - val_loss: 5.1349 - val_acc: 0.3965\n",
      "Epoch 74/100\n",
      "2065/2065 [==============================] - 2s 758us/sample - loss: 1.0605 - acc: 0.5903 - val_loss: 5.1745 - val_acc: 0.3868\n",
      "Epoch 75/100\n",
      "2065/2065 [==============================] - 2s 760us/sample - loss: 1.1046 - acc: 0.5729 - val_loss: 5.1380 - val_acc: 0.3714\n",
      "Epoch 76/100\n",
      "2065/2065 [==============================] - 2s 753us/sample - loss: 1.0703 - acc: 0.5792 - val_loss: 5.4967 - val_acc: 0.3733\n",
      "Epoch 77/100\n",
      "2065/2065 [==============================] - 2s 761us/sample - loss: 1.0300 - acc: 0.5976 - val_loss: 6.3439 - val_acc: 0.3617\n",
      "Epoch 78/100\n",
      "2065/2065 [==============================] - 2s 760us/sample - loss: 1.0330 - acc: 0.6024 - val_loss: 5.3870 - val_acc: 0.3868\n",
      "Epoch 79/100\n",
      "2065/2065 [==============================] - 2s 749us/sample - loss: 1.0729 - acc: 0.5729 - val_loss: 4.3353 - val_acc: 0.3520\n",
      "Epoch 80/100\n",
      "2065/2065 [==============================] - 2s 754us/sample - loss: 1.0714 - acc: 0.5797 - val_loss: 5.3427 - val_acc: 0.3868\n",
      "Epoch 81/100\n",
      "2065/2065 [==============================] - 2s 755us/sample - loss: 1.0342 - acc: 0.6063 - val_loss: 6.0446 - val_acc: 0.3694\n",
      "Epoch 82/100\n",
      "2065/2065 [==============================] - 2s 752us/sample - loss: 1.0467 - acc: 0.5855 - val_loss: 6.0649 - val_acc: 0.3617\n",
      "Epoch 83/100\n",
      "2065/2065 [==============================] - 2s 756us/sample - loss: 1.0600 - acc: 0.5860 - val_loss: 5.2197 - val_acc: 0.3888\n",
      "Epoch 84/100\n",
      "2065/2065 [==============================] - 2s 753us/sample - loss: 1.0538 - acc: 0.5855 - val_loss: 5.1947 - val_acc: 0.3868\n",
      "Epoch 85/100\n",
      "2065/2065 [==============================] - 2s 764us/sample - loss: 1.0223 - acc: 0.5893 - val_loss: 6.3519 - val_acc: 0.3733\n",
      "Epoch 86/100\n",
      "2065/2065 [==============================] - 2s 759us/sample - loss: 1.0636 - acc: 0.5864 - val_loss: 5.0864 - val_acc: 0.3772\n",
      "Epoch 87/100\n",
      "2065/2065 [==============================] - 2s 760us/sample - loss: 1.0338 - acc: 0.6024 - val_loss: 5.5164 - val_acc: 0.3849\n",
      "Epoch 88/100\n",
      "2065/2065 [==============================] - 2s 748us/sample - loss: 1.0604 - acc: 0.5898 - val_loss: 5.9444 - val_acc: 0.3578\n",
      "Epoch 89/100\n",
      "2065/2065 [==============================] - 2s 751us/sample - loss: 1.0578 - acc: 0.5879 - val_loss: 6.2673 - val_acc: 0.3578\n",
      "Epoch 90/100\n",
      "2065/2065 [==============================] - 2s 753us/sample - loss: 1.0713 - acc: 0.5860 - val_loss: 5.1002 - val_acc: 0.3752\n",
      "Epoch 91/100\n",
      "2065/2065 [==============================] - 2s 755us/sample - loss: 1.0586 - acc: 0.5864 - val_loss: 4.5897 - val_acc: 0.3868\n",
      "Epoch 92/100\n",
      "2065/2065 [==============================] - 2s 760us/sample - loss: 1.0612 - acc: 0.5850 - val_loss: 4.8880 - val_acc: 0.3888\n",
      "Epoch 93/100\n",
      "2065/2065 [==============================] - 2s 762us/sample - loss: 1.0536 - acc: 0.5898 - val_loss: 4.8536 - val_acc: 0.3791\n",
      "Epoch 94/100\n",
      "2065/2065 [==============================] - 2s 757us/sample - loss: 1.0651 - acc: 0.5835 - val_loss: 5.3406 - val_acc: 0.3694\n",
      "Epoch 95/100\n",
      "2065/2065 [==============================] - 2s 760us/sample - loss: 1.0543 - acc: 0.5840 - val_loss: 5.2137 - val_acc: 0.3849\n",
      "Epoch 96/100\n",
      "2065/2065 [==============================] - 2s 753us/sample - loss: 1.0535 - acc: 0.5840 - val_loss: 5.2752 - val_acc: 0.3791\n",
      "Epoch 97/100\n",
      "2065/2065 [==============================] - 2s 762us/sample - loss: 1.0392 - acc: 0.5801 - val_loss: 5.3161 - val_acc: 0.3810\n",
      "Epoch 98/100\n",
      "2065/2065 [==============================] - 2s 765us/sample - loss: 1.0718 - acc: 0.5840 - val_loss: 5.2471 - val_acc: 0.3810\n",
      "Epoch 99/100\n",
      "2065/2065 [==============================] - 2s 768us/sample - loss: 1.0504 - acc: 0.5831 - val_loss: 5.3888 - val_acc: 0.3849\n",
      "Epoch 100/100\n",
      "2065/2065 [==============================] - 2s 733us/sample - loss: 1.0775 - acc: 0.5738 - val_loss: 5.2808 - val_acc: 0.3849\n"
     ]
    }
   ],
   "source": [
    "# And we train the two last layers\n",
    "# This is classic fine tuning\n",
    "vm.model.train(X_savee_train, Y_savee_train, batch_size=10, validation_data=(X_savee_test, Y_savee_test), epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[142   0   0   0   0   2]\n",
      " [ 41   3  20   0   0   3]\n",
      " [ 34   0  43   0   0   5]\n",
      " [ 38   1  22   1   1  11]\n",
      " [ 34   8  19   0   2   3]\n",
      " [ 76   0   0   0   0   8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.39      0.99      0.56       144\n",
      "       happy       0.25      0.04      0.08        67\n",
      "       angry       0.41      0.52      0.46        82\n",
      "     fearful       1.00      0.01      0.03        74\n",
      "   surprised       0.67      0.03      0.06        66\n",
      "         sad       0.25      0.10      0.14        84\n",
      "\n",
      "    accuracy                           0.38       517\n",
      "   macro avg       0.49      0.28      0.22       517\n",
      "weighted avg       0.48      0.38      0.27       517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_metrics(X_savee_test, Y_savee_test, emotion_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
