{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arc/fdp5/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/arc/fdp5/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/arc/fdp5/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/arc/fdp5/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/arc/fdp5/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/arc/fdp5/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/arc/fdp5/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/arc/fdp5/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/arc/fdp5/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/arc/fdp5/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/arc/fdp5/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/arc/fdp5/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Import phase if every import is here it is to allow you to run this cell and know if you have any issue and not after a few hours of training\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, Activation, Flatten, MaxPooling1D, BatchNormalization, LSTM, GaussianNoise\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "from src.VoiceModule import VoiceModule\n",
    "from src.classifiers.KerasClassifier import KerasClassifier\n",
    "from prepare_data_utils import load_wav, preprare_wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fearful\n",
      "savee\n",
      "calm\n",
      "happy\n",
      "bdes\n",
      "surprised\n",
      "angry\n",
      "sad\n",
      "keywords\n"
     ]
    }
   ],
   "source": [
    "# print environment\n",
    "folder_path = \"../../data\"\n",
    "for l in os.listdir(folder_path):\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data method\n",
    "\n",
    "def mfcc(buffer, samplerate, dim):\n",
    "    a = librosa.feature.mfcc(y=buffer, sr=samplerate, n_mfcc=dim)\n",
    "    a = np.transpose(a)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback to later draw some graphs\n",
    "\n",
    "class PerformanceLogger(Callback):\n",
    "    def __init__(self):\n",
    "        # List of tuple (loss, accuracy)\n",
    "        self.training = []\n",
    "        self.testing = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.training.append((logs[\"loss\"], logs[\"acc\"]))\n",
    "        self.testing.append((logs[\"val_loss\"], logs[\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prints metrics about a model\n",
    "def print_metrics(voice_module, X, Y, label_name_list):\n",
    "    Y_pred = voice_module.model._model.predict(X)\n",
    "    Y_pred = np.argmax(Y_pred, axis=1)\n",
    "    Y_max = np.argmax(Y, axis=1)\n",
    "    print(confusion_matrix(Y_max, Y_pred))\n",
    "    print(classification_report(Y_max, Y_pred, target_names=label_name_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class\n",
    "class EmotionClassifierCnn(KerasClassifier):\n",
    "    def __init__(self, file_path=None):\n",
    "        super().__init__(file_path)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.expand_dims(np.array([x]), axis=2)\n",
    "        return self._model.predict(x)\n",
    "\n",
    "    def build(self):\n",
    "        model = Sequential()\n",
    "        model.add(GaussianNoise(0.4))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv1D(128, 3, input_shape=(35, 13), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(64, 5, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(GaussianNoise(0.4))\n",
    "        model.add(Dense(64))\n",
    "        model.add(Dense(5))\n",
    "        model.add(Activation('softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self._model = model\n",
    "        \n",
    "    def train(self, X, Y, batch_size=32, epoch=720, validation_data=None, callbacks=[]):\n",
    "        self._model.fit(X, Y, batch_size=batch_size, epochs=epoch, validation_data=validation_data, callbacks=callbacks)\n",
    "\n",
    "    def transform(self, x, samplerate):\n",
    "        to_process = mfcc(x, samplerate, 13)\n",
    "        to_process = pad_sequences([to_process], maxlen=35, padding='post')[0]\n",
    "        return to_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/arc/fdp5/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#Instanciate model\n",
    "emotion_list = [\"calm\", \"happy\", \"angry\", \"fearful\", \"sad\"]\n",
    "dimension_mfcc = 13\n",
    "samplerate = 16000\n",
    "nb_break=None\n",
    "sample_duration=1\n",
    "step=0.5\n",
    "\n",
    "logger = PerformanceLogger()\n",
    "\n",
    "cls = EmotionClassifierCnn()\n",
    "vm = VoiceModule(\"emotion-1s\", emotion_list, cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing calm\n",
      "Doing happy\n",
      "Doing angry\n",
      "Doing fearful\n",
      "Doing sad\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in emotion_list}\n",
    "X, Y = preprare_wav(data, vm, sample_duration, step)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_file = f\"x_{'_'.join(emotion_list)}-{vm._name}.npy\"\n",
    "Y_file = f\"y_{'_'.join(emotion_list)}-{vm._name}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the prepared input data \n",
    "np.save(X_file, X)\n",
    "np.save(Y_file, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for training\n",
    "X, Y = np.load(X_file), np.load(Y_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4584 1147\n",
      "(35, 13)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "\"\"\"train_size = 80 * len(X) // 100\n",
    "test_size = 20 * len(X) // 100\n",
    "#X = np.expand_dims(X, axis=3)\n",
    "X_train, X_test, = X[:train_size], X[train_size:]\n",
    "Y_train, Y_test = Y[:train_size], Y[train_size:]\"\"\"\n",
    "X = X.astype('float32')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(len(X_train), len(X_test))\n",
    "\n",
    "print(X[0].shape)\n",
    "print( X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4584 samples, validate on 1147 samples\n",
      "Epoch 1/100\n",
      "4584/4584 [==============================] - 3s 729us/sample - loss: 1.9840 - acc: 0.3418 - val_loss: 2.4065 - val_acc: 0.2485\n",
      "Epoch 2/100\n",
      "4584/4584 [==============================] - 2s 383us/sample - loss: 1.3984 - acc: 0.4335 - val_loss: 1.5336 - val_acc: 0.3601\n",
      "Epoch 3/100\n",
      "4584/4584 [==============================] - 2s 420us/sample - loss: 1.2286 - acc: 0.5085 - val_loss: 1.3524 - val_acc: 0.4342\n",
      "Epoch 4/100\n",
      "4584/4584 [==============================] - 2s 410us/sample - loss: 1.1316 - acc: 0.5369 - val_loss: 1.1593 - val_acc: 0.5327\n",
      "Epoch 5/100\n",
      "4584/4584 [==============================] - 2s 364us/sample - loss: 1.0579 - acc: 0.5700 - val_loss: 1.1548 - val_acc: 0.5179\n",
      "Epoch 6/100\n",
      "4584/4584 [==============================] - 2s 398us/sample - loss: 1.0064 - acc: 0.5927 - val_loss: 1.0477 - val_acc: 0.5772\n",
      "Epoch 7/100\n",
      "4584/4584 [==============================] - 2s 378us/sample - loss: 0.9607 - acc: 0.6187 - val_loss: 1.0271 - val_acc: 0.5728\n",
      "Epoch 8/100\n",
      "4584/4584 [==============================] - 2s 350us/sample - loss: 0.8924 - acc: 0.6385 - val_loss: 0.9903 - val_acc: 0.5990\n",
      "Epoch 9/100\n",
      "4584/4584 [==============================] - 2s 350us/sample - loss: 0.8772 - acc: 0.6414 - val_loss: 0.9618 - val_acc: 0.6042\n",
      "Epoch 10/100\n",
      "4584/4584 [==============================] - 2s 375us/sample - loss: 0.8338 - acc: 0.6612 - val_loss: 0.9811 - val_acc: 0.5998\n",
      "Epoch 11/100\n",
      "4584/4584 [==============================] - 2s 369us/sample - loss: 0.7973 - acc: 0.6839 - val_loss: 0.9359 - val_acc: 0.6338\n",
      "Epoch 12/100\n",
      "4584/4584 [==============================] - 2s 387us/sample - loss: 0.7571 - acc: 0.6948 - val_loss: 0.8906 - val_acc: 0.6425\n",
      "Epoch 13/100\n",
      "4584/4584 [==============================] - 2s 377us/sample - loss: 0.7561 - acc: 0.7038 - val_loss: 0.8539 - val_acc: 0.6643\n",
      "Epoch 14/100\n",
      "4584/4584 [==============================] - 2s 367us/sample - loss: 0.7125 - acc: 0.7269 - val_loss: 0.9005 - val_acc: 0.6399\n",
      "Epoch 15/100\n",
      "4584/4584 [==============================] - 2s 425us/sample - loss: 0.6769 - acc: 0.7341 - val_loss: 0.8442 - val_acc: 0.6696\n",
      "Epoch 16/100\n",
      "4584/4584 [==============================] - 2s 377us/sample - loss: 0.6851 - acc: 0.7297 - val_loss: 0.7883 - val_acc: 0.6931\n",
      "Epoch 17/100\n",
      "4584/4584 [==============================] - 2s 361us/sample - loss: 0.6538 - acc: 0.7487 - val_loss: 0.8330 - val_acc: 0.6713\n",
      "Epoch 18/100\n",
      "4584/4584 [==============================] - 2s 379us/sample - loss: 0.6168 - acc: 0.7568 - val_loss: 0.7630 - val_acc: 0.6992\n",
      "Epoch 19/100\n",
      "4584/4584 [==============================] - 2s 400us/sample - loss: 0.6050 - acc: 0.7659 - val_loss: 0.8245 - val_acc: 0.6792\n",
      "Epoch 20/100\n",
      "4584/4584 [==============================] - 2s 376us/sample - loss: 0.6039 - acc: 0.7659 - val_loss: 0.8029 - val_acc: 0.6827\n",
      "Epoch 21/100\n",
      "4584/4584 [==============================] - 2s 398us/sample - loss: 0.5747 - acc: 0.7705 - val_loss: 0.7539 - val_acc: 0.6975\n",
      "Epoch 22/100\n",
      "4584/4584 [==============================] - 2s 360us/sample - loss: 0.5562 - acc: 0.7877 - val_loss: 0.8561 - val_acc: 0.6539\n",
      "Epoch 23/100\n",
      "4584/4584 [==============================] - 2s 377us/sample - loss: 0.5792 - acc: 0.7736 - val_loss: 0.7423 - val_acc: 0.7071\n",
      "Epoch 24/100\n",
      "4584/4584 [==============================] - 2s 374us/sample - loss: 0.5539 - acc: 0.7808 - val_loss: 0.7263 - val_acc: 0.7114\n",
      "Epoch 25/100\n",
      "4584/4584 [==============================] - 2s 389us/sample - loss: 0.5449 - acc: 0.7897 - val_loss: 0.6962 - val_acc: 0.7167\n",
      "Epoch 26/100\n",
      "4584/4584 [==============================] - 2s 383us/sample - loss: 0.4975 - acc: 0.8058 - val_loss: 0.7083 - val_acc: 0.7210\n",
      "Epoch 27/100\n",
      "4584/4584 [==============================] - 2s 366us/sample - loss: 0.5121 - acc: 0.8037 - val_loss: 0.7701 - val_acc: 0.6940\n",
      "Epoch 28/100\n",
      "4584/4584 [==============================] - 2s 369us/sample - loss: 0.4934 - acc: 0.8085 - val_loss: 0.8132 - val_acc: 0.6966\n",
      "Epoch 29/100\n",
      "4584/4584 [==============================] - 2s 346us/sample - loss: 0.4784 - acc: 0.8194 - val_loss: 0.7280 - val_acc: 0.7271\n",
      "Epoch 30/100\n",
      "4584/4584 [==============================] - 2s 381us/sample - loss: 0.4726 - acc: 0.8168 - val_loss: 0.6970 - val_acc: 0.7332\n",
      "Epoch 31/100\n",
      "4584/4584 [==============================] - 2s 382us/sample - loss: 0.4591 - acc: 0.8281 - val_loss: 0.6784 - val_acc: 0.7480\n",
      "Epoch 32/100\n",
      "4584/4584 [==============================] - 2s 363us/sample - loss: 0.4189 - acc: 0.8381 - val_loss: 0.7087 - val_acc: 0.7306\n",
      "Epoch 33/100\n",
      "4584/4584 [==============================] - 2s 360us/sample - loss: 0.4637 - acc: 0.8220 - val_loss: 0.7188 - val_acc: 0.7297\n",
      "Epoch 34/100\n",
      "4584/4584 [==============================] - 1s 323us/sample - loss: 0.4326 - acc: 0.8338 - val_loss: 0.7331 - val_acc: 0.7306\n",
      "Epoch 35/100\n",
      "4584/4584 [==============================] - 2s 338us/sample - loss: 0.4376 - acc: 0.8325 - val_loss: 0.6542 - val_acc: 0.7463\n",
      "Epoch 36/100\n",
      "4584/4584 [==============================] - 2s 376us/sample - loss: 0.4120 - acc: 0.8442 - val_loss: 0.6763 - val_acc: 0.7454\n",
      "Epoch 37/100\n",
      "4584/4584 [==============================] - 2s 350us/sample - loss: 0.3994 - acc: 0.8501 - val_loss: 0.6769 - val_acc: 0.7402\n",
      "Epoch 38/100\n",
      "4584/4584 [==============================] - 2s 349us/sample - loss: 0.4319 - acc: 0.8408 - val_loss: 0.7075 - val_acc: 0.7393\n",
      "Epoch 39/100\n",
      "4584/4584 [==============================] - 2s 396us/sample - loss: 0.4170 - acc: 0.8449 - val_loss: 0.7466 - val_acc: 0.7088\n",
      "Epoch 40/100\n",
      "4584/4584 [==============================] - 2s 385us/sample - loss: 0.3797 - acc: 0.8558 - val_loss: 0.8403 - val_acc: 0.7010\n",
      "Epoch 41/100\n",
      "4584/4584 [==============================] - 2s 373us/sample - loss: 0.3847 - acc: 0.8580 - val_loss: 0.7046 - val_acc: 0.7446\n",
      "Epoch 42/100\n",
      "4584/4584 [==============================] - 2s 366us/sample - loss: 0.3941 - acc: 0.8530 - val_loss: 0.7507 - val_acc: 0.7245\n",
      "Epoch 43/100\n",
      "4584/4584 [==============================] - 2s 360us/sample - loss: 0.3479 - acc: 0.8667 - val_loss: 0.6729 - val_acc: 0.7472\n",
      "Epoch 44/100\n",
      "4584/4584 [==============================] - 2s 378us/sample - loss: 0.3599 - acc: 0.8669 - val_loss: 0.7112 - val_acc: 0.7332\n",
      "Epoch 45/100\n",
      "4584/4584 [==============================] - 2s 371us/sample - loss: 0.3783 - acc: 0.8584 - val_loss: 0.7660 - val_acc: 0.7105\n",
      "Epoch 46/100\n",
      "4584/4584 [==============================] - 2s 358us/sample - loss: 0.3542 - acc: 0.8676 - val_loss: 0.6795 - val_acc: 0.7446\n",
      "Epoch 47/100\n",
      "4584/4584 [==============================] - 2s 381us/sample - loss: 0.3276 - acc: 0.8759 - val_loss: 0.6603 - val_acc: 0.7629\n",
      "Epoch 48/100\n",
      "4584/4584 [==============================] - 2s 361us/sample - loss: 0.3487 - acc: 0.8669 - val_loss: 0.8014 - val_acc: 0.7184\n",
      "Epoch 49/100\n",
      "4584/4584 [==============================] - 2s 356us/sample - loss: 0.3425 - acc: 0.8698 - val_loss: 0.6977 - val_acc: 0.7393\n",
      "Epoch 50/100\n",
      "4584/4584 [==============================] - 2s 382us/sample - loss: 0.3397 - acc: 0.8706 - val_loss: 0.7007 - val_acc: 0.7454\n",
      "Epoch 51/100\n",
      "4584/4584 [==============================] - 2s 355us/sample - loss: 0.3492 - acc: 0.8613 - val_loss: 0.6733 - val_acc: 0.7402\n",
      "Epoch 52/100\n",
      "4584/4584 [==============================] - 2s 403us/sample - loss: 0.3124 - acc: 0.8857 - val_loss: 0.6677 - val_acc: 0.7576\n",
      "Epoch 53/100\n",
      "4584/4584 [==============================] - 2s 402us/sample - loss: 0.3133 - acc: 0.8829 - val_loss: 0.6989 - val_acc: 0.7585\n",
      "Epoch 54/100\n",
      "4584/4584 [==============================] - 2s 383us/sample - loss: 0.3257 - acc: 0.8781 - val_loss: 0.7475 - val_acc: 0.7262\n",
      "Epoch 55/100\n",
      "4584/4584 [==============================] - 2s 383us/sample - loss: 0.3153 - acc: 0.8848 - val_loss: 0.7077 - val_acc: 0.7454\n",
      "Epoch 56/100\n",
      "4584/4584 [==============================] - 2s 350us/sample - loss: 0.3330 - acc: 0.8733 - val_loss: 0.7441 - val_acc: 0.7201\n",
      "Epoch 57/100\n",
      "4584/4584 [==============================] - 2s 384us/sample - loss: 0.3052 - acc: 0.8835 - val_loss: 0.6959 - val_acc: 0.7524\n",
      "Epoch 58/100\n",
      "4584/4584 [==============================] - 2s 363us/sample - loss: 0.3010 - acc: 0.8853 - val_loss: 0.7011 - val_acc: 0.7393\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4584/4584 [==============================] - 2s 360us/sample - loss: 0.2879 - acc: 0.8938 - val_loss: 0.6970 - val_acc: 0.7489\n",
      "Epoch 60/100\n",
      "4584/4584 [==============================] - 2s 369us/sample - loss: 0.2838 - acc: 0.8938 - val_loss: 0.6992 - val_acc: 0.7550\n",
      "Epoch 61/100\n",
      "4584/4584 [==============================] - 2s 392us/sample - loss: 0.2688 - acc: 0.8951 - val_loss: 0.7273 - val_acc: 0.7541\n",
      "Epoch 62/100\n",
      "4584/4584 [==============================] - 2s 354us/sample - loss: 0.3027 - acc: 0.8809 - val_loss: 0.7441 - val_acc: 0.7376\n",
      "Epoch 63/100\n",
      "4584/4584 [==============================] - 2s 361us/sample - loss: 0.2826 - acc: 0.8938 - val_loss: 0.7664 - val_acc: 0.7411\n",
      "Epoch 64/100\n",
      "4584/4584 [==============================] - 2s 389us/sample - loss: 0.3013 - acc: 0.8870 - val_loss: 0.6472 - val_acc: 0.7724\n",
      "Epoch 65/100\n",
      "4584/4584 [==============================] - 2s 356us/sample - loss: 0.2658 - acc: 0.8997 - val_loss: 0.6716 - val_acc: 0.7716\n",
      "Epoch 66/100\n",
      "4584/4584 [==============================] - 2s 372us/sample - loss: 0.2690 - acc: 0.9025 - val_loss: 0.7777 - val_acc: 0.7411\n",
      "Epoch 67/100\n",
      "4584/4584 [==============================] - 2s 398us/sample - loss: 0.2603 - acc: 0.9021 - val_loss: 0.6645 - val_acc: 0.7724\n",
      "Epoch 68/100\n",
      "4584/4584 [==============================] - 2s 380us/sample - loss: 0.2746 - acc: 0.8973 - val_loss: 0.6580 - val_acc: 0.7812\n",
      "Epoch 69/100\n",
      "4584/4584 [==============================] - 2s 380us/sample - loss: 0.2606 - acc: 0.9018 - val_loss: 0.6708 - val_acc: 0.7672\n",
      "Epoch 70/100\n",
      "4584/4584 [==============================] - 2s 397us/sample - loss: 0.2557 - acc: 0.9064 - val_loss: 0.6727 - val_acc: 0.7681\n",
      "Epoch 71/100\n",
      "4584/4584 [==============================] - 2s 394us/sample - loss: 0.2741 - acc: 0.8970 - val_loss: 0.6721 - val_acc: 0.7602\n",
      "Epoch 72/100\n",
      "4584/4584 [==============================] - 2s 356us/sample - loss: 0.2663 - acc: 0.8944 - val_loss: 0.6664 - val_acc: 0.7629\n",
      "Epoch 73/100\n",
      "4584/4584 [==============================] - 2s 341us/sample - loss: 0.2481 - acc: 0.9079 - val_loss: 0.6393 - val_acc: 0.7777\n",
      "Epoch 74/100\n",
      "4584/4584 [==============================] - 2s 394us/sample - loss: 0.2387 - acc: 0.9121 - val_loss: 0.6939 - val_acc: 0.7568\n",
      "Epoch 75/100\n",
      "4584/4584 [==============================] - 2s 418us/sample - loss: 0.2303 - acc: 0.9110 - val_loss: 0.6936 - val_acc: 0.7716\n",
      "Epoch 76/100\n",
      "4584/4584 [==============================] - 2s 372us/sample - loss: 0.2215 - acc: 0.9188 - val_loss: 0.6865 - val_acc: 0.7672\n",
      "Epoch 77/100\n",
      "4584/4584 [==============================] - 2s 376us/sample - loss: 0.2271 - acc: 0.9188 - val_loss: 0.7656 - val_acc: 0.7594\n",
      "Epoch 78/100\n",
      "4584/4584 [==============================] - 2s 379us/sample - loss: 0.2333 - acc: 0.9099 - val_loss: 0.7018 - val_acc: 0.7594\n",
      "Epoch 79/100\n",
      "4584/4584 [==============================] - 2s 367us/sample - loss: 0.2302 - acc: 0.9184 - val_loss: 0.7063 - val_acc: 0.7698\n",
      "Epoch 80/100\n",
      "4584/4584 [==============================] - 2s 344us/sample - loss: 0.2425 - acc: 0.9112 - val_loss: 0.7963 - val_acc: 0.7463\n",
      "Epoch 81/100\n",
      "4584/4584 [==============================] - 2s 388us/sample - loss: 0.2490 - acc: 0.9079 - val_loss: 0.6991 - val_acc: 0.7594\n",
      "Epoch 82/100\n",
      "4584/4584 [==============================] - 2s 353us/sample - loss: 0.2369 - acc: 0.9134 - val_loss: 0.6818 - val_acc: 0.7655\n",
      "Epoch 83/100\n",
      "4584/4584 [==============================] - 2s 353us/sample - loss: 0.2246 - acc: 0.9154 - val_loss: 0.7092 - val_acc: 0.7768\n",
      "Epoch 84/100\n",
      "4584/4584 [==============================] - 2s 370us/sample - loss: 0.2304 - acc: 0.9147 - val_loss: 0.7826 - val_acc: 0.7489\n",
      "Epoch 85/100\n",
      "4584/4584 [==============================] - 2s 429us/sample - loss: 0.2111 - acc: 0.9232 - val_loss: 0.7433 - val_acc: 0.7585\n",
      "Epoch 86/100\n",
      "4584/4584 [==============================] - 2s 375us/sample - loss: 0.2165 - acc: 0.9199 - val_loss: 0.7312 - val_acc: 0.7611\n",
      "Epoch 87/100\n",
      "4584/4584 [==============================] - 2s 367us/sample - loss: 0.2382 - acc: 0.9095 - val_loss: 0.7626 - val_acc: 0.7454\n",
      "Epoch 88/100\n",
      "4584/4584 [==============================] - 2s 345us/sample - loss: 0.2357 - acc: 0.9106 - val_loss: 0.7460 - val_acc: 0.7602\n",
      "Epoch 89/100\n",
      "4584/4584 [==============================] - 2s 339us/sample - loss: 0.2189 - acc: 0.9210 - val_loss: 0.7822 - val_acc: 0.7629\n",
      "Epoch 90/100\n",
      "4584/4584 [==============================] - 2s 374us/sample - loss: 0.2060 - acc: 0.9234 - val_loss: 0.7053 - val_acc: 0.7698\n",
      "Epoch 91/100\n",
      "4584/4584 [==============================] - 2s 362us/sample - loss: 0.2006 - acc: 0.9243 - val_loss: 0.6659 - val_acc: 0.7803\n",
      "Epoch 92/100\n",
      "4584/4584 [==============================] - 2s 406us/sample - loss: 0.2011 - acc: 0.9276 - val_loss: 0.7618 - val_acc: 0.7655\n",
      "Epoch 93/100\n",
      "4584/4584 [==============================] - 2s 396us/sample - loss: 0.2134 - acc: 0.9219 - val_loss: 0.7082 - val_acc: 0.7646\n",
      "Epoch 94/100\n",
      "4584/4584 [==============================] - 2s 383us/sample - loss: 0.2076 - acc: 0.9254 - val_loss: 0.7256 - val_acc: 0.7733\n",
      "Epoch 95/100\n",
      "4584/4584 [==============================] - 2s 366us/sample - loss: 0.2175 - acc: 0.9212 - val_loss: 0.7370 - val_acc: 0.7672\n",
      "Epoch 96/100\n",
      "4584/4584 [==============================] - 2s 376us/sample - loss: 0.2101 - acc: 0.9254 - val_loss: 0.6974 - val_acc: 0.7751\n",
      "Epoch 97/100\n",
      "4584/4584 [==============================] - 2s 386us/sample - loss: 0.2110 - acc: 0.9208 - val_loss: 0.7425 - val_acc: 0.7524\n",
      "Epoch 98/100\n",
      "4584/4584 [==============================] - 2s 377us/sample - loss: 0.2060 - acc: 0.9217 - val_loss: 0.7456 - val_acc: 0.7550\n",
      "Epoch 99/100\n",
      "4584/4584 [==============================] - 2s 366us/sample - loss: 0.1891 - acc: 0.9308 - val_loss: 0.8435 - val_acc: 0.7245\n",
      "Epoch 100/100\n",
      "4584/4584 [==============================] - 2s 345us/sample - loss: 0.1898 - acc: 0.9313 - val_loss: 0.6979 - val_acc: 0.7716\n"
     ]
    }
   ],
   "source": [
    "vm.model.train(X_train, Y_train, batch_size=64, epoch=100, validation_data=(X_test, Y_test), callbacks=[logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise (GaussianNois multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  52        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              multiple                  5120      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            multiple                  41024     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  2048      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNo multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  32832     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  325       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    multiple                  0         \n",
      "=================================================================\n",
      "Total params: 81,401\n",
      "Trainable params: 80,351\n",
      "Non-trainable params: 1,050\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1aac160828>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[219   7   4   6  19]\n",
      " [ 16 152  18  18  12]\n",
      " [ 11  10 184  18  10]\n",
      " [ 11  12   9 164  16]\n",
      " [ 30  13  10  12 166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.76      0.86      0.81       255\n",
      "       happy       0.78      0.70      0.74       216\n",
      "       angry       0.82      0.79      0.80       233\n",
      "     fearful       0.75      0.77      0.76       212\n",
      "         sad       0.74      0.72      0.73       231\n",
      "\n",
      "    accuracy                           0.77      1147\n",
      "   macro avg       0.77      0.77      0.77      1147\n",
      "weighted avg       0.77      0.77      0.77      1147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vm.model._model.summary()\n",
    "\n",
    "\n",
    "plt.plot(list(range(0, len(logger.training))), list(map(lambda x:x[1], logger.training)), label=\"training data\")\n",
    "plt.plot(list(range(0, len(logger.testing))), list(map(lambda x:x[1], logger.testing)), label=\"testing data\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "print_metrics(vm, X_test, Y_test, emotion_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this graph we can see that the model largely overfit around the 20st epoch\n",
    "We can also see that the testing data's accuracy continues to grow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we save the model so we don't have to retrain it each time\n",
    "vm.model.save(\"emotion_cnn-1s.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Here we load the model to check if nothing went wrong\n",
    "vm.model.load(\"emotion_cnn-1s.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing calm\n",
      "Doing happy\n",
      "Doing angry\n",
      "Doing fearful\n",
      "Doing sad\n"
     ]
    }
   ],
   "source": [
    "# Now we load the new dataset (savee)\n",
    "\n",
    "# First we change the folder path\n",
    "folder_path = \"../../data/savee\"\n",
    "\n",
    "# Now we load the data\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in emotion_list}\n",
    "X_savee, Y_savee = preprare_wav(data, vm, sample_duration, step)\n",
    "X_savee = X_savee.astype('float32')\n",
    "X_savee_train, X_savee_test, Y_savee_train, Y_savee_test = train_test_split(X_savee, Y_savee, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1894, 35, 13)\n",
      "1894/1894 [==============================] - 1s 407us/sample - loss: 7.6659 - acc: 0.2920\n",
      "[[197  59  82   0  22]\n",
      " [ 73 157 108  12  18]\n",
      " [ 76 104 156  12  10]\n",
      " [ 95  99 126  21  17]\n",
      " [194 112 116   6  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.31      0.55      0.40       360\n",
      "       happy       0.30      0.43      0.35       368\n",
      "       angry       0.27      0.44      0.33       358\n",
      "     fearful       0.41      0.06      0.10       358\n",
      "         sad       0.25      0.05      0.08       450\n",
      "\n",
      "    accuracy                           0.29      1894\n",
      "   macro avg       0.31      0.30      0.25      1894\n",
      "weighted avg       0.30      0.29      0.24      1894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X_savee.shape)\n",
    "vm.model._model.evaluate(X_savee, Y_savee)\n",
    "print_metrics(vm, X_savee, Y_savee, emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_noise\n",
      "batch_normalization\n",
      "conv1d\n",
      "activation\n",
      "max_pooling1d\n",
      "conv1d_1\n",
      "activation_1\n",
      "max_pooling1d_1\n",
      "flatten\n",
      "batch_normalization_1\n",
      "dropout\n",
      "gaussian_noise_1\n"
     ]
    }
   ],
   "source": [
    "# Now we freeze every layer used for extracting features from data\n",
    "savee_model = keras.models.clone_model(vm.model._model)\n",
    "for layer in savee_model.layers[:-3]:\n",
    "    print(layer.name)\n",
    "    layer.trainable = False\n",
    "savee_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "savee_cls = EmotionClassifierCnn()\n",
    "savee_cls._model = savee_model\n",
    "savee_vm = VoiceModule(\"emotion-1s\", emotion_list, savee_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1515 samples, validate on 379 samples\n",
      "Epoch 1/100\n",
      "1515/1515 [==============================] - 3s 2ms/sample - loss: 2.1702 - acc: 0.3168 - val_loss: 94.7780 - val_acc: 0.1979\n",
      "Epoch 2/100\n",
      "1515/1515 [==============================] - 2s 998us/sample - loss: 1.5881 - acc: 0.4198 - val_loss: 74.2938 - val_acc: 0.1926\n",
      "Epoch 3/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.4049 - acc: 0.4581 - val_loss: 106.4523 - val_acc: 0.1900\n",
      "Epoch 4/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.3100 - acc: 0.4785 - val_loss: 94.2494 - val_acc: 0.1900\n",
      "Epoch 5/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.2670 - acc: 0.4871 - val_loss: 96.5158 - val_acc: 0.1900\n",
      "Epoch 6/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.2464 - acc: 0.4911 - val_loss: 92.4279 - val_acc: 0.1900\n",
      "Epoch 7/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.2108 - acc: 0.5122 - val_loss: 112.2898 - val_acc: 0.1900\n",
      "Epoch 8/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1924 - acc: 0.5142 - val_loss: 95.2709 - val_acc: 0.1900\n",
      "Epoch 9/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.2374 - acc: 0.4799 - val_loss: 102.6980 - val_acc: 0.1900\n",
      "Epoch 10/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1628 - acc: 0.5254 - val_loss: 106.1677 - val_acc: 0.1900\n",
      "Epoch 11/100\n",
      "1515/1515 [==============================] - 1s 964us/sample - loss: 1.1824 - acc: 0.5129 - val_loss: 94.1277 - val_acc: 0.1900\n",
      "Epoch 12/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1552 - acc: 0.5089 - val_loss: 83.8508 - val_acc: 0.1900\n",
      "Epoch 13/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1405 - acc: 0.5399 - val_loss: 91.0642 - val_acc: 0.1900\n",
      "Epoch 14/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1663 - acc: 0.5017 - val_loss: 79.8106 - val_acc: 0.1900\n",
      "Epoch 15/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1437 - acc: 0.5221 - val_loss: 80.8365 - val_acc: 0.1900\n",
      "Epoch 16/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1268 - acc: 0.5340 - val_loss: 100.5117 - val_acc: 0.1900\n",
      "Epoch 17/100\n",
      "1515/1515 [==============================] - 1s 961us/sample - loss: 1.1342 - acc: 0.5287 - val_loss: 93.0835 - val_acc: 0.1900\n",
      "Epoch 18/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1432 - acc: 0.5347 - val_loss: 72.9934 - val_acc: 0.1900\n",
      "Epoch 19/100\n",
      "1515/1515 [==============================] - 1s 984us/sample - loss: 1.1218 - acc: 0.5406 - val_loss: 90.9705 - val_acc: 0.1900\n",
      "Epoch 20/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1331 - acc: 0.5228 - val_loss: 88.9151 - val_acc: 0.1900\n",
      "Epoch 21/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1301 - acc: 0.5353 - val_loss: 106.5713 - val_acc: 0.1900\n",
      "Epoch 22/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1146 - acc: 0.5465 - val_loss: 99.2434 - val_acc: 0.1900\n",
      "Epoch 23/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1238 - acc: 0.5413 - val_loss: 98.9002 - val_acc: 0.1900\n",
      "Epoch 24/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1245 - acc: 0.5459 - val_loss: 87.2341 - val_acc: 0.1900\n",
      "Epoch 25/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1289 - acc: 0.5446 - val_loss: 84.8388 - val_acc: 0.1900\n",
      "Epoch 26/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1017 - acc: 0.5531 - val_loss: 95.3663 - val_acc: 0.1900\n",
      "Epoch 27/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1078 - acc: 0.5518 - val_loss: 79.5233 - val_acc: 0.1900\n",
      "Epoch 28/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0874 - acc: 0.5578 - val_loss: 97.2278 - val_acc: 0.1900\n",
      "Epoch 29/100\n",
      "1515/1515 [==============================] - 1s 985us/sample - loss: 1.1126 - acc: 0.5452 - val_loss: 81.1838 - val_acc: 0.1900\n",
      "Epoch 30/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1183 - acc: 0.5320 - val_loss: 79.4627 - val_acc: 0.1900\n",
      "Epoch 31/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1034 - acc: 0.5525 - val_loss: 83.1144 - val_acc: 0.1900\n",
      "Epoch 32/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0832 - acc: 0.5663 - val_loss: 73.2317 - val_acc: 0.1900\n",
      "Epoch 33/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1166 - acc: 0.5472 - val_loss: 94.1490 - val_acc: 0.1900\n",
      "Epoch 34/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0749 - acc: 0.5512 - val_loss: 82.3843 - val_acc: 0.1900\n",
      "Epoch 35/100\n",
      "1515/1515 [==============================] - 2s 992us/sample - loss: 1.1064 - acc: 0.5452 - val_loss: 87.3467 - val_acc: 0.1900\n",
      "Epoch 36/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1102 - acc: 0.5366 - val_loss: 91.5864 - val_acc: 0.1900\n",
      "Epoch 37/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0744 - acc: 0.5663 - val_loss: 78.8184 - val_acc: 0.1900\n",
      "Epoch 38/100\n",
      "1515/1515 [==============================] - 2s 997us/sample - loss: 1.0986 - acc: 0.5525 - val_loss: 81.4368 - val_acc: 0.1900\n",
      "Epoch 39/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0914 - acc: 0.5426 - val_loss: 108.6324 - val_acc: 0.1900\n",
      "Epoch 40/100\n",
      "1515/1515 [==============================] - 2s 992us/sample - loss: 1.1023 - acc: 0.5558 - val_loss: 95.2380 - val_acc: 0.1900\n",
      "Epoch 41/100\n",
      "1515/1515 [==============================] - 1s 971us/sample - loss: 1.0800 - acc: 0.5650 - val_loss: 101.5830 - val_acc: 0.1900\n",
      "Epoch 42/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0960 - acc: 0.5551 - val_loss: 83.9945 - val_acc: 0.1900\n",
      "Epoch 43/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1279 - acc: 0.5446 - val_loss: 94.1997 - val_acc: 0.1900\n",
      "Epoch 44/100\n",
      "1515/1515 [==============================] - 1s 976us/sample - loss: 1.0868 - acc: 0.5498 - val_loss: 72.8253 - val_acc: 0.1926\n",
      "Epoch 45/100\n",
      "1515/1515 [==============================] - 2s 996us/sample - loss: 1.1054 - acc: 0.5617 - val_loss: 88.0866 - val_acc: 0.1900\n",
      "Epoch 46/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1084 - acc: 0.5663 - val_loss: 83.5463 - val_acc: 0.1900\n",
      "Epoch 47/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0863 - acc: 0.5472 - val_loss: 121.1179 - val_acc: 0.1900\n",
      "Epoch 48/100\n",
      "1515/1515 [==============================] - 2s 993us/sample - loss: 1.0698 - acc: 0.5683 - val_loss: 103.9050 - val_acc: 0.1900\n",
      "Epoch 49/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1161 - acc: 0.5485 - val_loss: 105.1594 - val_acc: 0.1900\n",
      "Epoch 50/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0988 - acc: 0.5630 - val_loss: 89.6131 - val_acc: 0.1900\n",
      "Epoch 51/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0699 - acc: 0.5611 - val_loss: 90.8556 - val_acc: 0.1900\n",
      "Epoch 52/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1006 - acc: 0.5637 - val_loss: 82.8971 - val_acc: 0.1900\n",
      "Epoch 53/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0787 - acc: 0.5624 - val_loss: 80.9018 - val_acc: 0.1900\n",
      "Epoch 54/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1348 - acc: 0.5347 - val_loss: 81.7832 - val_acc: 0.1900\n",
      "Epoch 55/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0917 - acc: 0.5558 - val_loss: 76.7331 - val_acc: 0.1900\n",
      "Epoch 56/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1110 - acc: 0.5413 - val_loss: 75.5522 - val_acc: 0.1900\n",
      "Epoch 57/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0985 - acc: 0.5578 - val_loss: 87.5980 - val_acc: 0.1900\n",
      "Epoch 58/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0938 - acc: 0.5551 - val_loss: 107.3107 - val_acc: 0.1900\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0917 - acc: 0.5677 - val_loss: 91.4770 - val_acc: 0.1900\n",
      "Epoch 60/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1029 - acc: 0.5604 - val_loss: 77.9855 - val_acc: 0.1900\n",
      "Epoch 61/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1061 - acc: 0.5472 - val_loss: 84.5402 - val_acc: 0.1900\n",
      "Epoch 62/100\n",
      "1515/1515 [==============================] - 1s 982us/sample - loss: 1.1029 - acc: 0.5426 - val_loss: 95.3044 - val_acc: 0.1900\n",
      "Epoch 63/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0979 - acc: 0.5657 - val_loss: 71.5488 - val_acc: 0.1900\n",
      "Epoch 64/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0788 - acc: 0.5670 - val_loss: 106.4081 - val_acc: 0.1900\n",
      "Epoch 65/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0704 - acc: 0.5604 - val_loss: 88.6138 - val_acc: 0.1900\n",
      "Epoch 66/100\n",
      "1515/1515 [==============================] - 1s 972us/sample - loss: 1.0869 - acc: 0.5637 - val_loss: 89.8560 - val_acc: 0.1900\n",
      "Epoch 67/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0767 - acc: 0.5518 - val_loss: 100.2412 - val_acc: 0.1900\n",
      "Epoch 68/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1000 - acc: 0.5551 - val_loss: 85.3654 - val_acc: 0.1900\n",
      "Epoch 69/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0732 - acc: 0.5505 - val_loss: 114.3964 - val_acc: 0.1900\n",
      "Epoch 70/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0953 - acc: 0.5604 - val_loss: 99.5112 - val_acc: 0.1900\n",
      "Epoch 71/100\n",
      "1515/1515 [==============================] - 2s 995us/sample - loss: 1.0764 - acc: 0.5518 - val_loss: 87.8377 - val_acc: 0.1900\n",
      "Epoch 72/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1021 - acc: 0.5512 - val_loss: 83.2848 - val_acc: 0.1900\n",
      "Epoch 73/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0828 - acc: 0.5617 - val_loss: 82.5913 - val_acc: 0.1900\n",
      "Epoch 74/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0927 - acc: 0.5452 - val_loss: 72.4727 - val_acc: 0.1900\n",
      "Epoch 75/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0647 - acc: 0.5670 - val_loss: 80.3225 - val_acc: 0.1900\n",
      "Epoch 76/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0822 - acc: 0.5611 - val_loss: 95.8657 - val_acc: 0.1900\n",
      "Epoch 77/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0519 - acc: 0.5630 - val_loss: 88.4440 - val_acc: 0.1900\n",
      "Epoch 78/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0602 - acc: 0.5637 - val_loss: 91.1667 - val_acc: 0.1900\n",
      "Epoch 79/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0738 - acc: 0.5386 - val_loss: 81.7896 - val_acc: 0.1900\n",
      "Epoch 80/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1227 - acc: 0.5347 - val_loss: 96.7903 - val_acc: 0.1900\n",
      "Epoch 81/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0868 - acc: 0.5630 - val_loss: 76.1876 - val_acc: 0.1900\n",
      "Epoch 82/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1025 - acc: 0.5479 - val_loss: 93.8615 - val_acc: 0.1900\n",
      "Epoch 83/100\n",
      "1515/1515 [==============================] - 2s 996us/sample - loss: 1.0837 - acc: 0.5597 - val_loss: 83.3398 - val_acc: 0.1900\n",
      "Epoch 84/100\n",
      "1515/1515 [==============================] - 1s 979us/sample - loss: 1.0530 - acc: 0.5782 - val_loss: 81.1782 - val_acc: 0.1900\n",
      "Epoch 85/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1354 - acc: 0.5366 - val_loss: 96.2924 - val_acc: 0.1900\n",
      "Epoch 86/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0733 - acc: 0.5564 - val_loss: 84.9389 - val_acc: 0.1900\n",
      "Epoch 87/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0956 - acc: 0.5604 - val_loss: 102.8019 - val_acc: 0.1900\n",
      "Epoch 88/100\n",
      "1515/1515 [==============================] - 2s 999us/sample - loss: 1.0679 - acc: 0.5558 - val_loss: 97.7387 - val_acc: 0.1900\n",
      "Epoch 89/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0801 - acc: 0.5571 - val_loss: 100.4903 - val_acc: 0.1900\n",
      "Epoch 90/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0905 - acc: 0.5663 - val_loss: 94.0870 - val_acc: 0.1900\n",
      "Epoch 91/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0952 - acc: 0.5294 - val_loss: 74.2819 - val_acc: 0.1900\n",
      "Epoch 92/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0573 - acc: 0.5795 - val_loss: 98.9954 - val_acc: 0.1900\n",
      "Epoch 93/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0537 - acc: 0.5776 - val_loss: 93.5713 - val_acc: 0.1900\n",
      "Epoch 94/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0939 - acc: 0.5459 - val_loss: 85.7905 - val_acc: 0.1900\n",
      "Epoch 95/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0779 - acc: 0.5696 - val_loss: 81.0038 - val_acc: 0.1900\n",
      "Epoch 96/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0593 - acc: 0.5584 - val_loss: 109.7346 - val_acc: 0.1900\n",
      "Epoch 97/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.1058 - acc: 0.5597 - val_loss: 112.0635 - val_acc: 0.1900\n",
      "Epoch 98/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0912 - acc: 0.5611 - val_loss: 76.4165 - val_acc: 0.1900\n",
      "Epoch 99/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0735 - acc: 0.5650 - val_loss: 92.4071 - val_acc: 0.1900\n",
      "Epoch 100/100\n",
      "1515/1515 [==============================] - 2s 1ms/sample - loss: 1.0854 - acc: 0.5591 - val_loss: 104.3391 - val_acc: 0.1900\n"
     ]
    }
   ],
   "source": [
    "# And we train the two last layers\n",
    "# This is classic fine tuning\n",
    "savee_vm.model.train(X_savee_train, Y_savee_train, batch_size=10, validation_data=(X_savee_test, Y_savee_test), epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72  0  0  0  0]\n",
      " [78  0  0  0  0]\n",
      " [65  0  0  0  0]\n",
      " [72  0  0  0  0]\n",
      " [92  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.19      1.00      0.32        72\n",
      "       happy       0.00      0.00      0.00        78\n",
      "       angry       0.00      0.00      0.00        65\n",
      "     fearful       0.00      0.00      0.00        72\n",
      "         sad       0.00      0.00      0.00        92\n",
      "\n",
      "    accuracy                           0.19       379\n",
      "   macro avg       0.04      0.20      0.06       379\n",
      "weighted avg       0.04      0.19      0.06       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arc/fdp5/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print_metrics(savee_vm, X_savee_test, Y_savee_test, emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing calm\n",
      "Doing happy\n",
      "Doing angry\n",
      "Doing fearful\n",
      "Doing sad\n"
     ]
    }
   ],
   "source": [
    "# Now we load the new dataset (savee)\n",
    "\n",
    "# First we change the folder path\n",
    "folder_path = \"../../data/bdes\"\n",
    "\n",
    "# Now we load the data\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in emotion_list}\n",
    "X_bdes, Y_bdes = preprare_wav(data, vm, sample_duration, step)\n",
    "X_bdes = X_bdes.astype('float32')\n",
    "X_bdes_train, X_bdes_test, Y_bdes_train, Y_bdes_test = train_test_split(X_bdes, Y_bdes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1448, 35, 13)\n",
      "1448/1448 [==============================] - 0s 226us/sample - loss: 6.4236 - acc: 0.2459\n",
      "[[ 14  41 190  11   2]\n",
      " [  1  31 186  37   2]\n",
      " [  2  22 261  35   0]\n",
      " [  2  15 141  50   0]\n",
      " [ 45  45 131 184   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.22      0.05      0.09       258\n",
      "       happy       0.20      0.12      0.15       257\n",
      "       angry       0.29      0.82      0.42       320\n",
      "     fearful       0.16      0.24      0.19       208\n",
      "         sad       0.00      0.00      0.00       405\n",
      "\n",
      "    accuracy                           0.25      1448\n",
      "   macro avg       0.17      0.25      0.17      1448\n",
      "weighted avg       0.16      0.25      0.16      1448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X_bdes.shape)\n",
    "vm.model._model.evaluate(X_bdes, Y_bdes)\n",
    "print_metrics(vm, X_bdes, Y_bdes, emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_noise\n",
      "batch_normalization\n",
      "conv1d\n",
      "activation\n",
      "max_pooling1d\n",
      "conv1d_1\n",
      "activation_1\n",
      "max_pooling1d_1\n",
      "flatten\n",
      "batch_normalization_1\n",
      "dropout\n",
      "gaussian_noise_1\n"
     ]
    }
   ],
   "source": [
    "# Now we freeze every layer used for extracting features from data\n",
    "bdes_model = keras.models.clone_model(vm.model._model)\n",
    "for layer in bdes_model.layers[:-3]:\n",
    "    print(layer.name)\n",
    "    layer.trainable = False\n",
    "bdes_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "bdes_cls = EmotionClassifierCnn()\n",
    "bdes_cls._model = bdes_model\n",
    "bdes_vm = VoiceModule(\"emotion-1s\", emotion_list, bdes_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1158 samples, validate on 290 samples\n",
      "Epoch 1/100\n",
      "1158/1158 [==============================] - 2s 2ms/sample - loss: 1.6845 - acc: 0.4845 - val_loss: 59.5957 - val_acc: 0.3414\n",
      "Epoch 2/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 1.1592 - acc: 0.6054 - val_loss: 64.9340 - val_acc: 0.2724\n",
      "Epoch 3/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 1.0099 - acc: 0.6416 - val_loss: 83.3389 - val_acc: 0.2586\n",
      "Epoch 4/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.9135 - acc: 0.6623 - val_loss: 80.1418 - val_acc: 0.2759\n",
      "Epoch 5/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.9667 - acc: 0.6485 - val_loss: 65.3132 - val_acc: 0.2759\n",
      "Epoch 6/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.8741 - acc: 0.6649 - val_loss: 82.1915 - val_acc: 0.2586\n",
      "Epoch 7/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.8403 - acc: 0.6710 - val_loss: 83.8893 - val_acc: 0.2345\n",
      "Epoch 8/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7848 - acc: 0.6891 - val_loss: 94.5364 - val_acc: 0.2276\n",
      "Epoch 9/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7892 - acc: 0.6900 - val_loss: 97.1570 - val_acc: 0.2414\n",
      "Epoch 10/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7697 - acc: 0.6848 - val_loss: 86.4804 - val_acc: 0.2828\n",
      "Epoch 11/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.8086 - acc: 0.6943 - val_loss: 80.3057 - val_acc: 0.3000\n",
      "Epoch 12/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7555 - acc: 0.7021 - val_loss: 91.7008 - val_acc: 0.3310\n",
      "Epoch 13/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7402 - acc: 0.7029 - val_loss: 94.5574 - val_acc: 0.2276\n",
      "Epoch 14/100\n",
      "1158/1158 [==============================] - 1s 982us/sample - loss: 0.7421 - acc: 0.7055 - val_loss: 86.8130 - val_acc: 0.3379\n",
      "Epoch 15/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7700 - acc: 0.6813 - val_loss: 84.8456 - val_acc: 0.3483\n",
      "Epoch 16/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7487 - acc: 0.6995 - val_loss: 75.4146 - val_acc: 0.3310\n",
      "Epoch 17/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6900 - acc: 0.7280 - val_loss: 74.0725 - val_acc: 0.3310\n",
      "Epoch 18/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7556 - acc: 0.6986 - val_loss: 74.7032 - val_acc: 0.3448\n",
      "Epoch 19/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7509 - acc: 0.6891 - val_loss: 75.4844 - val_acc: 0.3069\n",
      "Epoch 20/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7378 - acc: 0.7047 - val_loss: 78.1165 - val_acc: 0.3414\n",
      "Epoch 21/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7338 - acc: 0.7064 - val_loss: 74.8614 - val_acc: 0.3448\n",
      "Epoch 22/100\n",
      "1158/1158 [==============================] - 2s 1ms/sample - loss: 0.7098 - acc: 0.7168 - val_loss: 75.2560 - val_acc: 0.3241\n",
      "Epoch 23/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7466 - acc: 0.6926 - val_loss: 74.3061 - val_acc: 0.3310\n",
      "Epoch 24/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7243 - acc: 0.7133 - val_loss: 82.4699 - val_acc: 0.3483\n",
      "Epoch 25/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7520 - acc: 0.6762 - val_loss: 81.4257 - val_acc: 0.3207\n",
      "Epoch 26/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6713 - acc: 0.7142 - val_loss: 78.9137 - val_acc: 0.3379\n",
      "Epoch 27/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7140 - acc: 0.7159 - val_loss: 80.8482 - val_acc: 0.3448\n",
      "Epoch 28/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7447 - acc: 0.7038 - val_loss: 71.2078 - val_acc: 0.3586\n",
      "Epoch 29/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7177 - acc: 0.7055 - val_loss: 77.8855 - val_acc: 0.2966\n",
      "Epoch 30/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7199 - acc: 0.7142 - val_loss: 69.5485 - val_acc: 0.3310\n",
      "Epoch 31/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7390 - acc: 0.7133 - val_loss: 75.6393 - val_acc: 0.3138\n",
      "Epoch 32/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7024 - acc: 0.7176 - val_loss: 70.4777 - val_acc: 0.3586\n",
      "Epoch 33/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7160 - acc: 0.7150 - val_loss: 69.3544 - val_acc: 0.3241\n",
      "Epoch 34/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6847 - acc: 0.7245 - val_loss: 68.5300 - val_acc: 0.3448\n",
      "Epoch 35/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7009 - acc: 0.7211 - val_loss: 76.8002 - val_acc: 0.2793\n",
      "Epoch 36/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6966 - acc: 0.7185 - val_loss: 67.0826 - val_acc: 0.3414\n",
      "Epoch 37/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6881 - acc: 0.7245 - val_loss: 75.5722 - val_acc: 0.3276\n",
      "Epoch 38/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7380 - acc: 0.7047 - val_loss: 81.4507 - val_acc: 0.3172\n",
      "Epoch 39/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6933 - acc: 0.7107 - val_loss: 65.1147 - val_acc: 0.3448\n",
      "Epoch 40/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6822 - acc: 0.7392 - val_loss: 80.3463 - val_acc: 0.3448\n",
      "Epoch 41/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7380 - acc: 0.7055 - val_loss: 74.0628 - val_acc: 0.3483\n",
      "Epoch 42/100\n",
      "1158/1158 [==============================] - 1s 993us/sample - loss: 0.6658 - acc: 0.7392 - val_loss: 72.1992 - val_acc: 0.2862\n",
      "Epoch 43/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6861 - acc: 0.7263 - val_loss: 68.8980 - val_acc: 0.2931\n",
      "Epoch 44/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6814 - acc: 0.7288 - val_loss: 77.8351 - val_acc: 0.2690\n",
      "Epoch 45/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6743 - acc: 0.7185 - val_loss: 81.3154 - val_acc: 0.3448\n",
      "Epoch 46/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6804 - acc: 0.7358 - val_loss: 78.0440 - val_acc: 0.3000\n",
      "Epoch 47/100\n",
      "1158/1158 [==============================] - 1s 998us/sample - loss: 0.6973 - acc: 0.7116 - val_loss: 67.8591 - val_acc: 0.3414\n",
      "Epoch 48/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6918 - acc: 0.7323 - val_loss: 84.1901 - val_acc: 0.2517\n",
      "Epoch 49/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6620 - acc: 0.7401 - val_loss: 75.9957 - val_acc: 0.3138\n",
      "Epoch 50/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7054 - acc: 0.7176 - val_loss: 75.6254 - val_acc: 0.3517\n",
      "Epoch 51/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7449 - acc: 0.7012 - val_loss: 71.0675 - val_acc: 0.3207\n",
      "Epoch 52/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6631 - acc: 0.7366 - val_loss: 80.4918 - val_acc: 0.3310\n",
      "Epoch 53/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6836 - acc: 0.7185 - val_loss: 72.1673 - val_acc: 0.3103\n",
      "Epoch 54/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6738 - acc: 0.7185 - val_loss: 70.7000 - val_acc: 0.3414\n",
      "Epoch 55/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7075 - acc: 0.7081 - val_loss: 78.5421 - val_acc: 0.2655\n",
      "Epoch 56/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6607 - acc: 0.7288 - val_loss: 70.2643 - val_acc: 0.3241\n",
      "Epoch 57/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7137 - acc: 0.6995 - val_loss: 87.2777 - val_acc: 0.3310\n",
      "Epoch 58/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6908 - acc: 0.7090 - val_loss: 79.6375 - val_acc: 0.3345\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6818 - acc: 0.7107 - val_loss: 75.7383 - val_acc: 0.3207\n",
      "Epoch 60/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7156 - acc: 0.7142 - val_loss: 81.9980 - val_acc: 0.3414\n",
      "Epoch 61/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6323 - acc: 0.7547 - val_loss: 90.7898 - val_acc: 0.3310\n",
      "Epoch 62/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6961 - acc: 0.7107 - val_loss: 84.0374 - val_acc: 0.3448\n",
      "Epoch 63/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7109 - acc: 0.7193 - val_loss: 78.6729 - val_acc: 0.2759\n",
      "Epoch 64/100\n",
      "1158/1158 [==============================] - 1s 986us/sample - loss: 0.6629 - acc: 0.7271 - val_loss: 72.3993 - val_acc: 0.3517\n",
      "Epoch 65/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6720 - acc: 0.7340 - val_loss: 68.4743 - val_acc: 0.3483\n",
      "Epoch 66/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6899 - acc: 0.7219 - val_loss: 76.6613 - val_acc: 0.3138\n",
      "Epoch 67/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7123 - acc: 0.7150 - val_loss: 86.2280 - val_acc: 0.2483\n",
      "Epoch 68/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7197 - acc: 0.7116 - val_loss: 78.6195 - val_acc: 0.3276\n",
      "Epoch 69/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6716 - acc: 0.7288 - val_loss: 72.4711 - val_acc: 0.3345\n",
      "Epoch 70/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6843 - acc: 0.7392 - val_loss: 74.3459 - val_acc: 0.3483\n",
      "Epoch 71/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6855 - acc: 0.7133 - val_loss: 77.8355 - val_acc: 0.3138\n",
      "Epoch 72/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6585 - acc: 0.7444 - val_loss: 84.0758 - val_acc: 0.2759\n",
      "Epoch 73/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6751 - acc: 0.7427 - val_loss: 80.9771 - val_acc: 0.2655\n",
      "Epoch 74/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7201 - acc: 0.6952 - val_loss: 65.1722 - val_acc: 0.3379\n",
      "Epoch 75/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6652 - acc: 0.7288 - val_loss: 95.7543 - val_acc: 0.2069\n",
      "Epoch 76/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6754 - acc: 0.7288 - val_loss: 86.6051 - val_acc: 0.2000\n",
      "Epoch 77/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6589 - acc: 0.7323 - val_loss: 86.1124 - val_acc: 0.3414\n",
      "Epoch 78/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6542 - acc: 0.7358 - val_loss: 93.6323 - val_acc: 0.3414\n",
      "Epoch 79/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7104 - acc: 0.7116 - val_loss: 68.1911 - val_acc: 0.3345\n",
      "Epoch 80/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6537 - acc: 0.7530 - val_loss: 90.2051 - val_acc: 0.3241\n",
      "Epoch 81/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6829 - acc: 0.7409 - val_loss: 75.2965 - val_acc: 0.3379\n",
      "Epoch 82/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6951 - acc: 0.7349 - val_loss: 80.5450 - val_acc: 0.3414\n",
      "Epoch 83/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6854 - acc: 0.7159 - val_loss: 94.6600 - val_acc: 0.1966\n",
      "Epoch 84/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6725 - acc: 0.7185 - val_loss: 84.2798 - val_acc: 0.3379\n",
      "Epoch 85/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6843 - acc: 0.7254 - val_loss: 73.0847 - val_acc: 0.3207\n",
      "Epoch 86/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7113 - acc: 0.7219 - val_loss: 78.5484 - val_acc: 0.3483\n",
      "Epoch 87/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6213 - acc: 0.7453 - val_loss: 93.9076 - val_acc: 0.2241\n",
      "Epoch 88/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6538 - acc: 0.7383 - val_loss: 93.4526 - val_acc: 0.3345\n",
      "Epoch 89/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6798 - acc: 0.7263 - val_loss: 88.9425 - val_acc: 0.3414\n",
      "Epoch 90/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6937 - acc: 0.7288 - val_loss: 84.5370 - val_acc: 0.3379\n",
      "Epoch 91/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7012 - acc: 0.7090 - val_loss: 73.9312 - val_acc: 0.3448\n",
      "Epoch 92/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7305 - acc: 0.7012 - val_loss: 84.9900 - val_acc: 0.2966\n",
      "Epoch 93/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6656 - acc: 0.7358 - val_loss: 62.7280 - val_acc: 0.3517\n",
      "Epoch 94/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7129 - acc: 0.7055 - val_loss: 75.2412 - val_acc: 0.3138\n",
      "Epoch 95/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6754 - acc: 0.7193 - val_loss: 82.6754 - val_acc: 0.3483\n",
      "Epoch 96/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7159 - acc: 0.7185 - val_loss: 81.7678 - val_acc: 0.3103\n",
      "Epoch 97/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6941 - acc: 0.7133 - val_loss: 85.0687 - val_acc: 0.3103\n",
      "Epoch 98/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6852 - acc: 0.7219 - val_loss: 75.4447 - val_acc: 0.3414\n",
      "Epoch 99/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.6994 - acc: 0.7228 - val_loss: 87.2576 - val_acc: 0.2448\n",
      "Epoch 100/100\n",
      "1158/1158 [==============================] - 1s 1ms/sample - loss: 0.7167 - acc: 0.7038 - val_loss: 78.9851 - val_acc: 0.3414\n"
     ]
    }
   ],
   "source": [
    "# And we train the two last layers\n",
    "# This is classic fine tuning\n",
    "bdes_vm.model.train(X_bdes_train, Y_bdes_train, batch_size=10, validation_data=(X_bdes_test, Y_bdes_test), epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43  0  3  0  0]\n",
      " [11  0 41  0  0]\n",
      " [ 3  1 56  0  0]\n",
      " [27  1 23  0  0]\n",
      " [66  0 15  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.29      0.93      0.44        46\n",
      "       happy       0.00      0.00      0.00        52\n",
      "       angry       0.41      0.93      0.57        60\n",
      "     fearful       0.00      0.00      0.00        51\n",
      "         sad       0.00      0.00      0.00        81\n",
      "\n",
      "    accuracy                           0.34       290\n",
      "   macro avg       0.14      0.37      0.20       290\n",
      "weighted avg       0.13      0.34      0.19       290\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arc/fdp5/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print_metrics(bdes_vm, X_bdes_test, Y_bdes_test, emotion_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
