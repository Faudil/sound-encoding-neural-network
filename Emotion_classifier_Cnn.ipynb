{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import phase if every import is here it is to allow you to run this cell and know if you have any issue and not after a few hours of training\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, Activation, Flatten, MaxPooling1D, BatchNormalization, LSTM, GaussianNoise\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "from src.VoiceModule import VoiceModule\n",
    "from src.classifiers.KerasClassifier import KerasClassifier\n",
    "from prepare_data_utils import load_wav, preprare_wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bdes.zip\n",
      "fearful\n",
      "savee\n",
      "calm\n",
      "happy\n",
      "surprised\n",
      "angry\n",
      "sad\n",
      "keywords\n"
     ]
    }
   ],
   "source": [
    "# print environment\n",
    "folder_path = \"../../data\"\n",
    "for l in os.listdir(folder_path):\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data method\n",
    "\n",
    "def mfcc(buffer, samplerate, dim):\n",
    "    a = librosa.feature.mfcc(y=buffer, sr=samplerate, n_mfcc=dim)\n",
    "    a = np.transpose(a)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback to later draw some graphs\n",
    "\n",
    "class PerformanceLogger(Callback):\n",
    "    def __init__(self):\n",
    "        # List of tuple (loss, accuracy)\n",
    "        self.training = []\n",
    "        self.testing = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.training.append((logs[\"loss\"], logs[\"acc\"]))\n",
    "        self.testing.append((logs[\"val_loss\"], logs[\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prints metrics about a model\n",
    "def print_metrics(X, Y, label_name_list):\n",
    "    Y_pred = vm.model._model.predict(X)\n",
    "    Y_pred = np.argmax(Y_pred, axis=1)\n",
    "    Y_max = np.argmax(Y, axis=1)\n",
    "    print(confusion_matrix(Y_max, Y_pred))\n",
    "    print(classification_report(Y_max, Y_pred, target_names=label_name_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class\n",
    "class EmotionClassifierCnn(KerasClassifier):\n",
    "    def __init__(self, file_path=None):\n",
    "        super().__init__(file_path)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.expand_dims(np.array([x]), axis=2)\n",
    "        return self._model.predict(x)\n",
    "\n",
    "    def build(self):\n",
    "        model = Sequential()\n",
    "        model.add(GaussianNoise(0.4))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv1D(64, 3, input_shape=(70, 13), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Flatten())\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(GaussianNoise(0.4))\n",
    "        model.add(Dense(64))\n",
    "        model.add(Dense(6))\n",
    "        model.add(Activation('softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self._model = model\n",
    "        \n",
    "    def train(self, X, Y, batch_size=32, epoch=720, validation_data=None, callbacks=[]):\n",
    "        self._model.fit(X, Y, batch_size=batch_size, epochs=epoch, validation_data=validation_data, callbacks=callbacks)\n",
    "\n",
    "    def transform(self, x, samplerate):\n",
    "        to_process = mfcc(x, samplerate, 13)\n",
    "        to_process = pad_sequences([to_process], maxlen=70, padding='post')[0]\n",
    "        return to_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciate model\n",
    "emotion_list = [\"calm\", \"happy\", \"angry\", \"fearful\", \"surprised\", \"sad\"]\n",
    "dimension_mfcc = 13\n",
    "samplerate = 16000\n",
    "nb_break=None\n",
    "sample_duration=2\n",
    "step=2\n",
    "\n",
    "logger = PerformanceLogger()\n",
    "\n",
    "cls = EmotionClassifierCnn()\n",
    "vm = VoiceModule(\"emotion\", emotion_list, cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing calm\n",
      "Doing happy\n",
      "Doing angry\n",
      "Doing fearful\n",
      "Doing surprised\n",
      "Doing sad\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in emotion_list}\n",
    "X, Y = preprare_wav(data, vm, sample_duration, step)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_file = f\"x_{'_'.join(emotion_list)}-{vm._name}.npy\"\n",
    "Y_file = f\"y_{'_'.join(emotion_list)}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-59818a14a35c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Saving the prepared input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Saving the prepared input data \n",
    "np.save(X_file, X)\n",
    "np.save(Y_file, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for training\n",
    "X, Y = np.load(X_file), np.load(Y_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063 266\n",
      "(70, 13)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "\"\"\"train_size = 80 * len(X) // 100\n",
    "test_size = 20 * len(X) // 100\n",
    "#X = np.expand_dims(X, axis=3)\n",
    "X_train, X_test, = X[:train_size], X[train_size:]\n",
    "Y_train, Y_test = Y[:train_size], Y[train_size:]\"\"\"\n",
    "X = X.astype('float32')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(len(X_train), len(X_test))\n",
    "\n",
    "print(X[0].shape)\n",
    "print( X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1063 samples, validate on 266 samples\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 2s 2ms/sample - loss: 2.5488 - acc: 0.3641 - val_loss: 5.1706 - val_acc: 0.2744\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s 353us/sample - loss: 1.6078 - acc: 0.5353 - val_loss: 4.8114 - val_acc: 0.2481\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s 359us/sample - loss: 1.2547 - acc: 0.6115 - val_loss: 3.3055 - val_acc: 0.3346\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s 351us/sample - loss: 1.1054 - acc: 0.6312 - val_loss: 3.0298 - val_acc: 0.3195\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s 359us/sample - loss: 0.8874 - acc: 0.6905 - val_loss: 2.7950 - val_acc: 0.3271\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s 339us/sample - loss: 0.8517 - acc: 0.7121 - val_loss: 2.3764 - val_acc: 0.4098\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s 326us/sample - loss: 0.7916 - acc: 0.7225 - val_loss: 2.0186 - val_acc: 0.4398\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s 325us/sample - loss: 0.7223 - acc: 0.7545 - val_loss: 1.8351 - val_acc: 0.4925\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s 365us/sample - loss: 0.7087 - acc: 0.7498 - val_loss: 1.7026 - val_acc: 0.4887\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s 345us/sample - loss: 0.6231 - acc: 0.7874 - val_loss: 1.6093 - val_acc: 0.5226\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s 335us/sample - loss: 0.6306 - acc: 0.7789 - val_loss: 1.5356 - val_acc: 0.5226\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s 349us/sample - loss: 0.5901 - acc: 0.7930 - val_loss: 1.3943 - val_acc: 0.5639\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s 350us/sample - loss: 0.5397 - acc: 0.8147 - val_loss: 1.4896 - val_acc: 0.5526\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s 361us/sample - loss: 0.5649 - acc: 0.8043 - val_loss: 1.4273 - val_acc: 0.5602\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s 345us/sample - loss: 0.5317 - acc: 0.8081 - val_loss: 1.4598 - val_acc: 0.5489\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s 353us/sample - loss: 0.4994 - acc: 0.8194 - val_loss: 1.4168 - val_acc: 0.5940\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s 334us/sample - loss: 0.4101 - acc: 0.8495 - val_loss: 1.4239 - val_acc: 0.5639\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s 320us/sample - loss: 0.4213 - acc: 0.8532 - val_loss: 1.4069 - val_acc: 0.6053\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s 334us/sample - loss: 0.3815 - acc: 0.8523 - val_loss: 1.4329 - val_acc: 0.6128\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s 347us/sample - loss: 0.4822 - acc: 0.8382 - val_loss: 1.5134 - val_acc: 0.5977\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s 343us/sample - loss: 0.4335 - acc: 0.8401 - val_loss: 1.4323 - val_acc: 0.5940\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s 355us/sample - loss: 0.5012 - acc: 0.8269 - val_loss: 1.5702 - val_acc: 0.5714\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s 355us/sample - loss: 0.4187 - acc: 0.8627 - val_loss: 1.6800 - val_acc: 0.5752\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s 346us/sample - loss: 0.3938 - acc: 0.8702 - val_loss: 1.5824 - val_acc: 0.5865\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s 358us/sample - loss: 0.3520 - acc: 0.8692 - val_loss: 1.5767 - val_acc: 0.6015\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s 344us/sample - loss: 0.3625 - acc: 0.8777 - val_loss: 1.5653 - val_acc: 0.6165\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s 329us/sample - loss: 0.3650 - acc: 0.8711 - val_loss: 1.5985 - val_acc: 0.6203\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s 336us/sample - loss: 0.3272 - acc: 0.8815 - val_loss: 1.6728 - val_acc: 0.5827\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s 329us/sample - loss: 0.3674 - acc: 0.8721 - val_loss: 1.6363 - val_acc: 0.6015\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s 358us/sample - loss: 0.3307 - acc: 0.8833 - val_loss: 1.6082 - val_acc: 0.6241\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s 330us/sample - loss: 0.3090 - acc: 0.8899 - val_loss: 1.5522 - val_acc: 0.6165\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s 353us/sample - loss: 0.3517 - acc: 0.8758 - val_loss: 1.7369 - val_acc: 0.5827\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s 328us/sample - loss: 0.3162 - acc: 0.8777 - val_loss: 1.6416 - val_acc: 0.6128\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s 350us/sample - loss: 0.2544 - acc: 0.9022 - val_loss: 1.5471 - val_acc: 0.6241\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s 359us/sample - loss: 0.2656 - acc: 0.9050 - val_loss: 1.6080 - val_acc: 0.6316\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s 321us/sample - loss: 0.3128 - acc: 0.8918 - val_loss: 1.5395 - val_acc: 0.6203\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s 348us/sample - loss: 0.2554 - acc: 0.9040 - val_loss: 1.6203 - val_acc: 0.6015\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s 340us/sample - loss: 0.2494 - acc: 0.9125 - val_loss: 1.7309 - val_acc: 0.5827\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s 343us/sample - loss: 0.2650 - acc: 0.8993 - val_loss: 1.7121 - val_acc: 0.5902\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s 325us/sample - loss: 0.2901 - acc: 0.8956 - val_loss: 1.7225 - val_acc: 0.5977\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s 332us/sample - loss: 0.2879 - acc: 0.8928 - val_loss: 1.6631 - val_acc: 0.6203\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s 356us/sample - loss: 0.2733 - acc: 0.9097 - val_loss: 1.8160 - val_acc: 0.6241\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s 341us/sample - loss: 0.2639 - acc: 0.9069 - val_loss: 1.7103 - val_acc: 0.6128\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s 357us/sample - loss: 0.2553 - acc: 0.9097 - val_loss: 1.7741 - val_acc: 0.6241\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s 371us/sample - loss: 0.2888 - acc: 0.8993 - val_loss: 1.8253 - val_acc: 0.6504\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s 354us/sample - loss: 0.2798 - acc: 0.9069 - val_loss: 1.7490 - val_acc: 0.6128\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s 352us/sample - loss: 0.2461 - acc: 0.9087 - val_loss: 1.7829 - val_acc: 0.6128\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s 353us/sample - loss: 0.2534 - acc: 0.9135 - val_loss: 1.7948 - val_acc: 0.6316\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s 342us/sample - loss: 0.2525 - acc: 0.9172 - val_loss: 1.7984 - val_acc: 0.6015\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s 307us/sample - loss: 0.2092 - acc: 0.9247 - val_loss: 1.7929 - val_acc: 0.6316\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s 327us/sample - loss: 0.2373 - acc: 0.9182 - val_loss: 1.8325 - val_acc: 0.6316\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s 342us/sample - loss: 0.2792 - acc: 0.9069 - val_loss: 1.7878 - val_acc: 0.6165\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s 350us/sample - loss: 0.2216 - acc: 0.9257 - val_loss: 1.8077 - val_acc: 0.6353\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s 343us/sample - loss: 0.2540 - acc: 0.9050 - val_loss: 1.9092 - val_acc: 0.6278\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s 350us/sample - loss: 0.2214 - acc: 0.9285 - val_loss: 1.7970 - val_acc: 0.6241\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s 336us/sample - loss: 0.2377 - acc: 0.9304 - val_loss: 1.7401 - val_acc: 0.6128\n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s 365us/sample - loss: 0.2172 - acc: 0.9172 - val_loss: 1.8068 - val_acc: 0.6391\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s 362us/sample - loss: 0.2363 - acc: 0.9200 - val_loss: 1.8722 - val_acc: 0.6090\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s 354us/sample - loss: 0.2085 - acc: 0.9247 - val_loss: 1.8654 - val_acc: 0.5977\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s 338us/sample - loss: 0.2002 - acc: 0.9323 - val_loss: 1.7857 - val_acc: 0.6053\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s 339us/sample - loss: 0.2048 - acc: 0.9257 - val_loss: 1.8444 - val_acc: 0.6165\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s 333us/sample - loss: 0.1880 - acc: 0.9379 - val_loss: 1.7537 - val_acc: 0.6353\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s 361us/sample - loss: 0.2457 - acc: 0.9219 - val_loss: 1.9059 - val_acc: 0.6203\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s 365us/sample - loss: 0.2274 - acc: 0.9191 - val_loss: 2.0101 - val_acc: 0.6353\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s 344us/sample - loss: 0.2369 - acc: 0.9210 - val_loss: 1.8651 - val_acc: 0.6353\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s 354us/sample - loss: 0.2300 - acc: 0.9219 - val_loss: 1.8799 - val_acc: 0.6241\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s 352us/sample - loss: 0.1919 - acc: 0.9360 - val_loss: 1.8907 - val_acc: 0.6466\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s 346us/sample - loss: 0.1826 - acc: 0.9351 - val_loss: 1.9051 - val_acc: 0.6203\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s 346us/sample - loss: 0.1852 - acc: 0.9360 - val_loss: 1.8501 - val_acc: 0.6241\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s 342us/sample - loss: 0.1777 - acc: 0.9370 - val_loss: 1.8713 - val_acc: 0.6128\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s 330us/sample - loss: 0.1915 - acc: 0.9323 - val_loss: 1.9092 - val_acc: 0.6278\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s 337us/sample - loss: 0.2086 - acc: 0.9238 - val_loss: 1.8315 - val_acc: 0.6128\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s 366us/sample - loss: 0.2066 - acc: 0.9257 - val_loss: 1.8317 - val_acc: 0.6466\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s 355us/sample - loss: 0.1787 - acc: 0.9398 - val_loss: 1.8747 - val_acc: 0.6165\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s 356us/sample - loss: 0.2006 - acc: 0.9341 - val_loss: 1.9660 - val_acc: 0.6165\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s 348us/sample - loss: 0.2008 - acc: 0.9285 - val_loss: 1.9154 - val_acc: 0.6429\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s 347us/sample - loss: 0.1686 - acc: 0.9351 - val_loss: 1.8616 - val_acc: 0.6353\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s 363us/sample - loss: 0.2676 - acc: 0.9087 - val_loss: 1.7770 - val_acc: 0.6353\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s 362us/sample - loss: 0.2176 - acc: 0.9247 - val_loss: 1.8210 - val_acc: 0.6090\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s 351us/sample - loss: 0.2142 - acc: 0.9200 - val_loss: 1.8198 - val_acc: 0.6316\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s 362us/sample - loss: 0.2175 - acc: 0.9219 - val_loss: 1.8955 - val_acc: 0.6165\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s 325us/sample - loss: 0.2397 - acc: 0.9229 - val_loss: 1.8507 - val_acc: 0.6241\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s 331us/sample - loss: 0.1798 - acc: 0.9341 - val_loss: 1.9940 - val_acc: 0.6203\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s 347us/sample - loss: 0.2159 - acc: 0.9370 - val_loss: 1.8269 - val_acc: 0.6541\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s 361us/sample - loss: 0.1926 - acc: 0.9313 - val_loss: 1.8272 - val_acc: 0.6429\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s 340us/sample - loss: 0.1258 - acc: 0.9511 - val_loss: 2.0039 - val_acc: 0.6128\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s 341us/sample - loss: 0.2140 - acc: 0.9210 - val_loss: 1.8874 - val_acc: 0.6316\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s 358us/sample - loss: 0.2138 - acc: 0.9276 - val_loss: 1.8706 - val_acc: 0.6316\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s 357us/sample - loss: 0.1638 - acc: 0.9445 - val_loss: 1.8268 - val_acc: 0.6579\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s 348us/sample - loss: 0.1543 - acc: 0.9360 - val_loss: 1.8901 - val_acc: 0.6165\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s 360us/sample - loss: 0.1326 - acc: 0.9548 - val_loss: 1.9176 - val_acc: 0.6353\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s 337us/sample - loss: 0.1585 - acc: 0.9398 - val_loss: 1.9134 - val_acc: 0.6579\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s 314us/sample - loss: 0.1398 - acc: 0.9417 - val_loss: 1.9257 - val_acc: 0.6391\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s 351us/sample - loss: 0.1409 - acc: 0.9577 - val_loss: 2.0062 - val_acc: 0.6165\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s 324us/sample - loss: 0.1793 - acc: 0.9351 - val_loss: 1.9829 - val_acc: 0.6053\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s 365us/sample - loss: 0.1702 - acc: 0.9436 - val_loss: 1.9710 - val_acc: 0.6165\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s 341us/sample - loss: 0.1422 - acc: 0.9492 - val_loss: 1.9718 - val_acc: 0.6353\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s 346us/sample - loss: 0.1456 - acc: 0.9454 - val_loss: 1.9433 - val_acc: 0.6278\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s 338us/sample - loss: 0.1815 - acc: 0.9332 - val_loss: 2.1053 - val_acc: 0.6015\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s 307us/sample - loss: 0.2084 - acc: 0.9276 - val_loss: 1.9494 - val_acc: 0.6203\n"
     ]
    }
   ],
   "source": [
    "vm.model.train(X_train, Y_train, batch_size=64, epoch=100, validation_data=(X_test, Y_test), callbacks=[logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f452c6bd978>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41  1  0  1  0  3]\n",
      " [ 4 22  4  5  5  4]\n",
      " [ 1  4 42  2  3  1]\n",
      " [ 2  6  5 23  4  6]\n",
      " [ 0  5  2  3 18  6]\n",
      " [10  7  1  1  5 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.71      0.89      0.79        46\n",
      "       happy       0.49      0.50      0.49        44\n",
      "       angry       0.78      0.79      0.79        53\n",
      "     fearful       0.66      0.50      0.57        46\n",
      "   surprised       0.51      0.53      0.52        34\n",
      "         sad       0.49      0.44      0.46        43\n",
      "\n",
      "    accuracy                           0.62       266\n",
      "   macro avg       0.61      0.61      0.60       266\n",
      "weighted avg       0.62      0.62      0.61       266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(list(range(0, len(logger.training))), list(map(lambda x:x[1], logger.training)), label=\"training data\")\n",
    "plt.plot(list(range(0, len(logger.testing))), list(map(lambda x:x[1], logger.testing)), label=\"testing data\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "print_metrics(X_test, Y_test, emotion_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this graph we can see that the model largely overfit around the 20st epoch\n",
    "We can also see that the testing data's accuracy continues to grow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we save the model so we don't have to retrain it each time\n",
    "vm.model.save(\"emotion_cnn.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Here we load the model to check if nothing went wrong\n",
    "vm.model.load(\"emotion_lstm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing calm\n",
      "Doing happy\n",
      "Doing angry\n",
      "Doing fearful\n",
      "Doing surprised\n",
      "Doing sad\n"
     ]
    }
   ],
   "source": [
    "# Now we load the new dataset (savee)\n",
    "\n",
    "# First we change the folder path\n",
    "folder_path += \"/savee\"\n",
    "\n",
    "# Now we load the data\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in emotion_list}\n",
    "X_savee, Y_savee = preprare_wav(data, vm, sample_duration, step)\n",
    "X_savee = X_savee.astype('float32')\n",
    "X_savee_train, X_savee_test, Y_savee_train, Y_savee_test = train_test_split(X_savee, Y_savee, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580/580 [==============================] - 0s 150us/sample - loss: 11.1960 - acc: 0.2259\n",
      "[[37 37  8  0 52 16]\n",
      " [ 5 26 13  2 30  6]\n",
      " [14 22 25  0 19  1]\n",
      " [19 10 18  4 24  5]\n",
      " [12 11 21  1 33  3]\n",
      " [29 22 10  1 38  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.32      0.25      0.28       150\n",
      "       happy       0.20      0.32      0.25        82\n",
      "       angry       0.26      0.31      0.28        81\n",
      "     fearful       0.50      0.05      0.09        80\n",
      "   surprised       0.17      0.41      0.24        81\n",
      "         sad       0.16      0.06      0.08       106\n",
      "\n",
      "    accuracy                           0.23       580\n",
      "   macro avg       0.27      0.23      0.20       580\n",
      "weighted avg       0.27      0.23      0.21       580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vm.model._model.evaluate(X_savee, Y_savee)\n",
    "print_metrics(X_savee, Y_savee, emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_noise_6\n",
      "batch_normalization_10\n",
      "conv1d_5\n",
      "activation_10\n",
      "max_pooling1d_5\n",
      "flatten_5\n",
      "batch_normalization_11\n",
      "dropout_5\n",
      "gaussian_noise_7\n"
     ]
    }
   ],
   "source": [
    "# Now we freeze every layer used for extracting features from data\n",
    "for layer in vm.model._model.layers[:-3]:\n",
    "    print(layer.name)\n",
    "    layer.trainable = False\n",
    "vm.model._model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 464 samples, validate on 116 samples\n",
      "Epoch 1/100\n",
      "464/464 [==============================] - 0s 873us/sample - loss: 0.3298 - acc: 0.8879 - val_loss: 14.1871 - val_acc: 0.2672\n",
      "Epoch 2/100\n",
      "464/464 [==============================] - 0s 873us/sample - loss: 0.3084 - acc: 0.8879 - val_loss: 14.9794 - val_acc: 0.2759\n",
      "Epoch 3/100\n",
      "464/464 [==============================] - 0s 852us/sample - loss: 0.3245 - acc: 0.8879 - val_loss: 14.9846 - val_acc: 0.2672\n",
      "Epoch 4/100\n",
      "464/464 [==============================] - 0s 886us/sample - loss: 0.3565 - acc: 0.8750 - val_loss: 13.3398 - val_acc: 0.2672\n",
      "Epoch 5/100\n",
      "464/464 [==============================] - 0s 860us/sample - loss: 0.3996 - acc: 0.8772 - val_loss: 14.0526 - val_acc: 0.2672\n",
      "Epoch 6/100\n",
      "464/464 [==============================] - 0s 850us/sample - loss: 0.2632 - acc: 0.9030 - val_loss: 13.8477 - val_acc: 0.2672\n",
      "Epoch 7/100\n",
      "464/464 [==============================] - 0s 817us/sample - loss: 0.2091 - acc: 0.9159 - val_loss: 14.3281 - val_acc: 0.2759\n",
      "Epoch 8/100\n",
      "464/464 [==============================] - 0s 901us/sample - loss: 0.2644 - acc: 0.9030 - val_loss: 16.2305 - val_acc: 0.2759\n",
      "Epoch 9/100\n",
      "464/464 [==============================] - 0s 885us/sample - loss: 0.3230 - acc: 0.9073 - val_loss: 14.2649 - val_acc: 0.2672\n",
      "Epoch 10/100\n",
      "464/464 [==============================] - 0s 902us/sample - loss: 0.3766 - acc: 0.8728 - val_loss: 12.8833 - val_acc: 0.2845\n",
      "Epoch 11/100\n",
      "464/464 [==============================] - 0s 856us/sample - loss: 0.3137 - acc: 0.8944 - val_loss: 12.7243 - val_acc: 0.2845\n",
      "Epoch 12/100\n",
      "464/464 [==============================] - 0s 867us/sample - loss: 0.3043 - acc: 0.8836 - val_loss: 13.7061 - val_acc: 0.2845\n",
      "Epoch 13/100\n",
      "464/464 [==============================] - 0s 875us/sample - loss: 0.3106 - acc: 0.8922 - val_loss: 14.1197 - val_acc: 0.2672\n",
      "Epoch 14/100\n",
      "464/464 [==============================] - 0s 859us/sample - loss: 0.2593 - acc: 0.9009 - val_loss: 15.4110 - val_acc: 0.2759\n",
      "Epoch 15/100\n",
      "464/464 [==============================] - 0s 893us/sample - loss: 0.3650 - acc: 0.8728 - val_loss: 14.9726 - val_acc: 0.2759\n",
      "Epoch 16/100\n",
      "464/464 [==============================] - 0s 841us/sample - loss: 0.3316 - acc: 0.8815 - val_loss: 16.3893 - val_acc: 0.2759\n",
      "Epoch 17/100\n",
      "464/464 [==============================] - 0s 792us/sample - loss: 0.2738 - acc: 0.9073 - val_loss: 15.9518 - val_acc: 0.2845\n",
      "Epoch 18/100\n",
      "464/464 [==============================] - 0s 857us/sample - loss: 0.2425 - acc: 0.9159 - val_loss: 15.6439 - val_acc: 0.2845\n",
      "Epoch 19/100\n",
      "464/464 [==============================] - 0s 838us/sample - loss: 0.3104 - acc: 0.8793 - val_loss: 14.5283 - val_acc: 0.2931\n",
      "Epoch 20/100\n",
      "464/464 [==============================] - 0s 840us/sample - loss: 0.2313 - acc: 0.9073 - val_loss: 13.7598 - val_acc: 0.2931\n",
      "Epoch 21/100\n",
      "464/464 [==============================] - 0s 834us/sample - loss: 0.2402 - acc: 0.9095 - val_loss: 14.7798 - val_acc: 0.2845\n",
      "Epoch 22/100\n",
      "464/464 [==============================] - 0s 864us/sample - loss: 0.2931 - acc: 0.8922 - val_loss: 15.3610 - val_acc: 0.2845\n",
      "Epoch 23/100\n",
      "464/464 [==============================] - 0s 907us/sample - loss: 0.3444 - acc: 0.8858 - val_loss: 15.1382 - val_acc: 0.2759\n",
      "Epoch 24/100\n",
      "464/464 [==============================] - 0s 867us/sample - loss: 0.2358 - acc: 0.9138 - val_loss: 14.7318 - val_acc: 0.2845\n",
      "Epoch 25/100\n",
      "464/464 [==============================] - 0s 840us/sample - loss: 0.2176 - acc: 0.9289 - val_loss: 14.9973 - val_acc: 0.2672\n",
      "Epoch 26/100\n",
      "464/464 [==============================] - 0s 801us/sample - loss: 0.3292 - acc: 0.8836 - val_loss: 15.4512 - val_acc: 0.2759\n",
      "Epoch 27/100\n",
      "464/464 [==============================] - 0s 817us/sample - loss: 0.2686 - acc: 0.9116 - val_loss: 16.5477 - val_acc: 0.2759\n",
      "Epoch 28/100\n",
      "464/464 [==============================] - 0s 872us/sample - loss: 0.2373 - acc: 0.9159 - val_loss: 15.3711 - val_acc: 0.2672\n",
      "Epoch 29/100\n",
      "464/464 [==============================] - 0s 859us/sample - loss: 0.2781 - acc: 0.9116 - val_loss: 15.1476 - val_acc: 0.2845\n",
      "Epoch 30/100\n",
      "464/464 [==============================] - 0s 813us/sample - loss: 0.1829 - acc: 0.9375 - val_loss: 14.4474 - val_acc: 0.2759\n",
      "Epoch 31/100\n",
      "464/464 [==============================] - 0s 834us/sample - loss: 0.2810 - acc: 0.9030 - val_loss: 15.6584 - val_acc: 0.2759\n",
      "Epoch 32/100\n",
      "464/464 [==============================] - 0s 845us/sample - loss: 0.2454 - acc: 0.9203 - val_loss: 15.3748 - val_acc: 0.2759\n",
      "Epoch 33/100\n",
      "464/464 [==============================] - 0s 862us/sample - loss: 0.2042 - acc: 0.9289 - val_loss: 14.3617 - val_acc: 0.2759\n",
      "Epoch 34/100\n",
      "464/464 [==============================] - 0s 863us/sample - loss: 0.2139 - acc: 0.9181 - val_loss: 15.7586 - val_acc: 0.2672\n",
      "Epoch 35/100\n",
      "464/464 [==============================] - 0s 840us/sample - loss: 0.2781 - acc: 0.9181 - val_loss: 15.5757 - val_acc: 0.2759\n",
      "Epoch 36/100\n",
      "464/464 [==============================] - 0s 862us/sample - loss: 0.1792 - acc: 0.9159 - val_loss: 17.9369 - val_acc: 0.2759\n",
      "Epoch 37/100\n",
      "464/464 [==============================] - 0s 763us/sample - loss: 0.2670 - acc: 0.9052 - val_loss: 16.5259 - val_acc: 0.2759\n",
      "Epoch 38/100\n",
      "464/464 [==============================] - 0s 874us/sample - loss: 0.1964 - acc: 0.9440 - val_loss: 16.1840 - val_acc: 0.2759\n",
      "Epoch 39/100\n",
      "464/464 [==============================] - 0s 866us/sample - loss: 0.2448 - acc: 0.9203 - val_loss: 17.5033 - val_acc: 0.2759\n",
      "Epoch 40/100\n",
      "464/464 [==============================] - 0s 870us/sample - loss: 0.2904 - acc: 0.9138 - val_loss: 17.3831 - val_acc: 0.2845\n",
      "Epoch 41/100\n",
      "464/464 [==============================] - 0s 869us/sample - loss: 0.2805 - acc: 0.9030 - val_loss: 18.1232 - val_acc: 0.2759\n",
      "Epoch 42/100\n",
      "464/464 [==============================] - 0s 836us/sample - loss: 0.2608 - acc: 0.9095 - val_loss: 15.8255 - val_acc: 0.2931\n",
      "Epoch 43/100\n",
      "464/464 [==============================] - 0s 865us/sample - loss: 0.2834 - acc: 0.9159 - val_loss: 14.1900 - val_acc: 0.2845\n",
      "Epoch 44/100\n",
      "464/464 [==============================] - 0s 849us/sample - loss: 0.2585 - acc: 0.9030 - val_loss: 12.5714 - val_acc: 0.2931\n",
      "Epoch 45/100\n",
      "464/464 [==============================] - 0s 822us/sample - loss: 0.2281 - acc: 0.9246 - val_loss: 13.8758 - val_acc: 0.2845\n",
      "Epoch 46/100\n",
      "464/464 [==============================] - 0s 804us/sample - loss: 0.2100 - acc: 0.9332 - val_loss: 14.9011 - val_acc: 0.2759\n",
      "Epoch 47/100\n",
      "464/464 [==============================] - 0s 796us/sample - loss: 0.2162 - acc: 0.9181 - val_loss: 16.8276 - val_acc: 0.2759\n",
      "Epoch 48/100\n",
      "464/464 [==============================] - 0s 827us/sample - loss: 0.2531 - acc: 0.9138 - val_loss: 14.0365 - val_acc: 0.2672\n",
      "Epoch 49/100\n",
      "464/464 [==============================] - 0s 846us/sample - loss: 0.2158 - acc: 0.9203 - val_loss: 14.9778 - val_acc: 0.2759\n",
      "Epoch 50/100\n",
      "464/464 [==============================] - 0s 872us/sample - loss: 0.1711 - acc: 0.9375 - val_loss: 15.5809 - val_acc: 0.2759\n",
      "Epoch 51/100\n",
      "464/464 [==============================] - 0s 850us/sample - loss: 0.2143 - acc: 0.9224 - val_loss: 14.4403 - val_acc: 0.2845\n",
      "Epoch 52/100\n",
      "464/464 [==============================] - 0s 850us/sample - loss: 0.2492 - acc: 0.9267 - val_loss: 15.4345 - val_acc: 0.2672\n",
      "Epoch 53/100\n",
      "464/464 [==============================] - 0s 835us/sample - loss: 0.1930 - acc: 0.9310 - val_loss: 14.9853 - val_acc: 0.2672\n",
      "Epoch 54/100\n",
      "464/464 [==============================] - 0s 850us/sample - loss: 0.2252 - acc: 0.9246 - val_loss: 15.8643 - val_acc: 0.2672\n",
      "Epoch 55/100\n",
      "464/464 [==============================] - 0s 874us/sample - loss: 0.1987 - acc: 0.9224 - val_loss: 16.1576 - val_acc: 0.2672\n",
      "Epoch 56/100\n",
      "464/464 [==============================] - 0s 828us/sample - loss: 0.2113 - acc: 0.9353 - val_loss: 16.6105 - val_acc: 0.2672\n",
      "Epoch 57/100\n",
      "464/464 [==============================] - 0s 838us/sample - loss: 0.2555 - acc: 0.9009 - val_loss: 15.2864 - val_acc: 0.2759\n",
      "Epoch 58/100\n",
      "464/464 [==============================] - 0s 832us/sample - loss: 0.1801 - acc: 0.9267 - val_loss: 17.0795 - val_acc: 0.2672\n",
      "Epoch 59/100\n",
      "464/464 [==============================] - 0s 900us/sample - loss: 0.2193 - acc: 0.9267 - val_loss: 15.0028 - val_acc: 0.2672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "464/464 [==============================] - 0s 923us/sample - loss: 0.1507 - acc: 0.9504 - val_loss: 16.8374 - val_acc: 0.2672\n",
      "Epoch 61/100\n",
      "464/464 [==============================] - 0s 850us/sample - loss: 0.1594 - acc: 0.9461 - val_loss: 19.7974 - val_acc: 0.2759\n",
      "Epoch 62/100\n",
      "464/464 [==============================] - 0s 905us/sample - loss: 0.2310 - acc: 0.9181 - val_loss: 14.7259 - val_acc: 0.2931\n",
      "Epoch 63/100\n",
      "464/464 [==============================] - 0s 904us/sample - loss: 0.2424 - acc: 0.9095 - val_loss: 15.8181 - val_acc: 0.2672\n",
      "Epoch 64/100\n",
      "464/464 [==============================] - 0s 870us/sample - loss: 0.2063 - acc: 0.9267 - val_loss: 15.3982 - val_acc: 0.2759\n",
      "Epoch 65/100\n",
      "464/464 [==============================] - 0s 852us/sample - loss: 0.2487 - acc: 0.9138 - val_loss: 15.9388 - val_acc: 0.2672\n",
      "Epoch 66/100\n",
      "464/464 [==============================] - 0s 813us/sample - loss: 0.1963 - acc: 0.9246 - val_loss: 17.3642 - val_acc: 0.2672\n",
      "Epoch 67/100\n",
      "464/464 [==============================] - 0s 844us/sample - loss: 0.2364 - acc: 0.9246 - val_loss: 14.6165 - val_acc: 0.2931\n",
      "Epoch 68/100\n",
      "464/464 [==============================] - 0s 866us/sample - loss: 0.2302 - acc: 0.9116 - val_loss: 17.5128 - val_acc: 0.2672\n",
      "Epoch 69/100\n",
      "464/464 [==============================] - 0s 845us/sample - loss: 0.1712 - acc: 0.9332 - val_loss: 16.5094 - val_acc: 0.2672\n",
      "Epoch 70/100\n",
      "464/464 [==============================] - 0s 834us/sample - loss: 0.1753 - acc: 0.9375 - val_loss: 15.2731 - val_acc: 0.2845\n",
      "Epoch 71/100\n",
      "464/464 [==============================] - 0s 859us/sample - loss: 0.1935 - acc: 0.9289 - val_loss: 16.9426 - val_acc: 0.2759\n",
      "Epoch 72/100\n",
      "464/464 [==============================] - 0s 857us/sample - loss: 0.1546 - acc: 0.9397 - val_loss: 18.0864 - val_acc: 0.2759\n",
      "Epoch 73/100\n",
      "464/464 [==============================] - 0s 815us/sample - loss: 0.1942 - acc: 0.9224 - val_loss: 18.4182 - val_acc: 0.2759\n",
      "Epoch 74/100\n",
      "464/464 [==============================] - 0s 838us/sample - loss: 0.2285 - acc: 0.9224 - val_loss: 17.0753 - val_acc: 0.2845\n",
      "Epoch 75/100\n",
      "464/464 [==============================] - 0s 875us/sample - loss: 0.1825 - acc: 0.9289 - val_loss: 19.1042 - val_acc: 0.2759\n",
      "Epoch 76/100\n",
      "464/464 [==============================] - 0s 852us/sample - loss: 0.1840 - acc: 0.9375 - val_loss: 16.2812 - val_acc: 0.2845\n",
      "Epoch 77/100\n",
      "464/464 [==============================] - 0s 845us/sample - loss: 0.2251 - acc: 0.9246 - val_loss: 19.7322 - val_acc: 0.2759\n",
      "Epoch 78/100\n",
      "464/464 [==============================] - 0s 850us/sample - loss: 0.1872 - acc: 0.9353 - val_loss: 18.5166 - val_acc: 0.2845\n",
      "Epoch 79/100\n",
      "464/464 [==============================] - 0s 888us/sample - loss: 0.1857 - acc: 0.9203 - val_loss: 17.6231 - val_acc: 0.2931\n",
      "Epoch 80/100\n",
      "464/464 [==============================] - 0s 890us/sample - loss: 0.2887 - acc: 0.8966 - val_loss: 16.5201 - val_acc: 0.2931\n",
      "Epoch 81/100\n",
      "464/464 [==============================] - 0s 905us/sample - loss: 0.1993 - acc: 0.9289 - val_loss: 14.8542 - val_acc: 0.3017\n",
      "Epoch 82/100\n",
      "464/464 [==============================] - 0s 866us/sample - loss: 0.2250 - acc: 0.9289 - val_loss: 14.8934 - val_acc: 0.2931\n",
      "Epoch 83/100\n",
      "464/464 [==============================] - 0s 882us/sample - loss: 0.1659 - acc: 0.9418 - val_loss: 14.1017 - val_acc: 0.3017\n",
      "Epoch 84/100\n",
      "464/464 [==============================] - 0s 855us/sample - loss: 0.1889 - acc: 0.9353 - val_loss: 14.8522 - val_acc: 0.2931\n",
      "Epoch 85/100\n",
      "464/464 [==============================] - 0s 840us/sample - loss: 0.2493 - acc: 0.9073 - val_loss: 16.2192 - val_acc: 0.2845\n",
      "Epoch 86/100\n",
      "464/464 [==============================] - 0s 773us/sample - loss: 0.2261 - acc: 0.9267 - val_loss: 18.4866 - val_acc: 0.2845\n",
      "Epoch 87/100\n",
      "464/464 [==============================] - 0s 828us/sample - loss: 0.2129 - acc: 0.9224 - val_loss: 17.4674 - val_acc: 0.2759\n",
      "Epoch 88/100\n",
      "464/464 [==============================] - 0s 875us/sample - loss: 0.1876 - acc: 0.9418 - val_loss: 16.6918 - val_acc: 0.2759\n",
      "Epoch 89/100\n",
      "464/464 [==============================] - 0s 905us/sample - loss: 0.2315 - acc: 0.9073 - val_loss: 18.4393 - val_acc: 0.2931\n",
      "Epoch 90/100\n",
      "464/464 [==============================] - 0s 903us/sample - loss: 0.2301 - acc: 0.9224 - val_loss: 15.2553 - val_acc: 0.2931\n",
      "Epoch 91/100\n",
      "464/464 [==============================] - 0s 851us/sample - loss: 0.1693 - acc: 0.9375 - val_loss: 15.7854 - val_acc: 0.2931\n",
      "Epoch 92/100\n",
      "464/464 [==============================] - 0s 879us/sample - loss: 0.2189 - acc: 0.9181 - val_loss: 17.9886 - val_acc: 0.2931\n",
      "Epoch 93/100\n",
      "464/464 [==============================] - 0s 894us/sample - loss: 0.2655 - acc: 0.9073 - val_loss: 16.2622 - val_acc: 0.2845\n",
      "Epoch 94/100\n",
      "464/464 [==============================] - 0s 904us/sample - loss: 0.3062 - acc: 0.8944 - val_loss: 15.3413 - val_acc: 0.2845\n",
      "Epoch 95/100\n",
      "464/464 [==============================] - 0s 795us/sample - loss: 0.2617 - acc: 0.9116 - val_loss: 15.6793 - val_acc: 0.2845\n",
      "Epoch 96/100\n",
      "464/464 [==============================] - 0s 812us/sample - loss: 0.1997 - acc: 0.9246 - val_loss: 15.0466 - val_acc: 0.2845\n",
      "Epoch 97/100\n",
      "464/464 [==============================] - 0s 833us/sample - loss: 0.1745 - acc: 0.9418 - val_loss: 16.7653 - val_acc: 0.2672\n",
      "Epoch 98/100\n",
      "464/464 [==============================] - 0s 864us/sample - loss: 0.1677 - acc: 0.9353 - val_loss: 16.9647 - val_acc: 0.2672\n",
      "Epoch 99/100\n",
      "464/464 [==============================] - 0s 865us/sample - loss: 0.1986 - acc: 0.9332 - val_loss: 17.3336 - val_acc: 0.2672\n",
      "Epoch 100/100\n",
      "464/464 [==============================] - 0s 898us/sample - loss: 0.2981 - acc: 0.9073 - val_loss: 15.6583 - val_acc: 0.2845\n"
     ]
    }
   ],
   "source": [
    "# And we train the two last layers\n",
    "# This is classic fine tuning\n",
    "vm.model.train(X_savee_train, Y_savee_train, batch_size=10, validation_data=(X_savee_test, Y_savee_test), epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  0  0  0  0  1]\n",
      " [19  0  0  0  0  0]\n",
      " [19  0  0  0  0  1]\n",
      " [ 6  0  0  0  0  0]\n",
      " [13  0  0  0  0  0]\n",
      " [24  0  0  0  0  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.28      0.97      0.43        32\n",
      "       happy       0.00      0.00      0.00        19\n",
      "       angry       0.00      0.00      0.00        20\n",
      "     fearful       0.00      0.00      0.00         6\n",
      "   surprised       0.00      0.00      0.00        13\n",
      "         sad       0.50      0.08      0.13        26\n",
      "\n",
      "    accuracy                           0.28       116\n",
      "   macro avg       0.13      0.17      0.09       116\n",
      "weighted avg       0.19      0.28      0.15       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_metrics(X_savee_test, Y_savee_test, emotion_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
