{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import phase if every import is here it is to allow you to run this cell and know if you have any issue and not after a few hours of training\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, Activation, Flatten, MaxPooling1D, BatchNormalization, LSTM, GaussianNoise\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "from src.VoiceModule import VoiceModule\n",
    "from src.classifiers.KerasClassifier import KerasClassifier\n",
    "from prepare_data_utils import load_wav, preprare_wav, split_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n",
      "tree\n",
      "_background_noise_\n",
      "go\n",
      "house\n",
      "validation_list.txt\n",
      "eight\n",
      "up\n",
      "bed\n",
      "two\n",
      "dog\n",
      "no\n",
      "bird\n",
      "five\n",
      "marvin\n",
      "seven\n",
      "four\n",
      "visual\n",
      "happy\n",
      "nine\n",
      "data_speech_commands_v0.02.tar.gz\n",
      "off\n",
      "yes\n",
      "forward\n",
      "follow\n",
      "README.md\n",
      "cat\n",
      "three\n",
      "on\n",
      "right\n",
      "backward\n",
      "testing_list.txt\n",
      "sheila\n",
      "wow\n",
      ".DS_Store\n",
      "stop\n",
      "one\n",
      "zero\n",
      "six\n",
      "learn\n",
      "LICENSE\n",
      "left\n"
     ]
    }
   ],
   "source": [
    "# print environment\n",
    "folder_path = \"../../data/keywords\"\n",
    "for l in os.listdir(folder_path):\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data method\n",
    "\n",
    "def mfcc(buffer, samplerate, dim):\n",
    "    a = librosa.feature.mfcc(y=buffer, sr=samplerate, n_mfcc=dim)\n",
    "    a = np.transpose(a)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback to later draw some graphs\n",
    "\n",
    "class PerformanceLogger(Callback):\n",
    "    def __init__(self):\n",
    "        # List of tuple (loss, accuracy)\n",
    "        self.training = []\n",
    "        self.testing = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.training.append((logs[\"loss\"], logs[\"acc\"]))\n",
    "        self.testing.append((logs[\"val_loss\"], logs[\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prints metrics about a model\n",
    "def print_metrics(X, Y, label_name_list, voice_module):\n",
    "    Y_pred = voice_module.model._model.predict(X)\n",
    "    Y_pred = np.argmax(Y_pred, axis=1)\n",
    "    Y_max = np.argmax(Y, axis=1)\n",
    "    print(confusion_matrix(Y_max, Y_pred))\n",
    "    print(classification_report(Y_max, Y_pred, target_names=label_name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class\n",
    "class KeywordClassifierCnn(KerasClassifier):\n",
    "    def __init__(self, file_path=None):\n",
    "        super().__init__(file_path)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.expand_dims(np.array([x]), axis=2)\n",
    "        return self._model.predict(x)\n",
    "\n",
    "    def build(self):\n",
    "        model = Sequential()\n",
    "        # Adding noise to the training data\n",
    "        model.add(GaussianNoise(0.2))\n",
    "        \n",
    "        # feature Extraction layers\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv1D(256, 3, input_shape=(50, 13), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(128, 3, input_shape=(50, 13), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(64, 3, input_shape=(50, 13), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(64, 3, input_shape=(50, 13), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        \n",
    "        # End of the neuron and classification part\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Flatten())\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Dense(35))\n",
    "        model.add(Activation('softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self._model = model\n",
    "        \n",
    "    def train(self, X, Y, batch_size=32, epoch=720, validation_data=None, callbacks=[]):\n",
    "        self._model.fit(X, Y, batch_size=batch_size, epochs=epoch, validation_data=validation_data, callbacks=callbacks)\n",
    "\n",
    "    def transform(self, x, samplerate):\n",
    "        to_process = mfcc(x, samplerate, 13)\n",
    "        to_process = pad_sequences([to_process], maxlen=35, padding='post')[0]\n",
    "        return to_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "WARNING:tensorflow:From /home/arc/fdp5/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#Instanciate model\n",
    "digit_list = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
    "keyword_list = [\"backward\", \"bed\", \"bird\", \"cat\", \"dog\", \"down\", \"follow\", \"forward\",\n",
    "               \"go\", \"happy\", \"house\", \"learn\", \"left\", \"marvin\", \"no\", \"off\", \"on\",\n",
    "               \"right\", \"sheila\", \"stop\", \"tree\", \"up\", \"visual\", \"wow\", \"yes\"] + digit_list\n",
    "print(len(keyword_list))\n",
    "dimension_mfcc = 13\n",
    "samplerate = 16000\n",
    "nb_break=None\n",
    "sample_duration=1\n",
    "step=1\n",
    "\n",
    "logger = PerformanceLogger()\n",
    "\n",
    "cls = KeywordClassifierCnn()\n",
    "vm = VoiceModule(\"digit\", keyword_list, cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing backward\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e9a6f04d564c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Prepare data for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{folder_path}/{f}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_break\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeyword_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprare_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_duration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/notebook/soundlib/prepare_data_utils.py\u001b[0m in \u001b[0;36mpreprare_wav\u001b[0;34m(data, vm, sample_duration, step)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_duration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ac4dbbf593fd>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, x, samplerate)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mto_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mto_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_process\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mto_process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7bc8e070bc98>\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(buffer, samplerate, dim)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mS\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1706\u001b[0;31m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdct_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_mfcc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[0mmel_basis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1836\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_basis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in keyword_list}\n",
    "X, Y = preprare_wav(data, vm, sample_duration, step)\n",
    "print(\"Done\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_file = f\"x_{'_'.join(keyword_list)}-{vm._name}.npy\"\n",
    "Y_file = f\"y_{'_'.join(keyword_list)}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the prepared input data \n",
    "np.save(X_file, X)\n",
    "np.save(Y_file, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for training\n",
    "X, Y = np.load(X_file), np.load(Y_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95394, 35, 13)\n",
      "76315 19079\n",
      "(35, 13)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "\"\"\"train_size = 80 * len(X) // 100\n",
    "test_size = 20 * len(X) // 100\n",
    "#X = np.expand_dims(X, axis=3)\n",
    "X_train, X_test, = X[:train_size], X[train_size:]\n",
    "Y_train, Y_test = Y[:train_size], Y[train_size:]\"\"\"\n",
    "X = X.astype('float32')\n",
    "print(X.shape)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(len(X_train), len(X_test))\n",
    "\n",
    "print(X[0].shape)\n",
    "print( X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76315 samples, validate on 19079 samples\n",
      "Epoch 1/100\n",
      "76315/76315 [==============================] - 15s 191us/sample - loss: 2.2697 - acc: 0.3695 - val_loss: 2.0216 - val_acc: 0.5962\n",
      "Epoch 2/100\n",
      "76315/76315 [==============================] - 13s 165us/sample - loss: 1.0319 - acc: 0.6973 - val_loss: 1.1486 - val_acc: 0.7911\n",
      "Epoch 3/100\n",
      "76315/76315 [==============================] - 12s 156us/sample - loss: 0.7072 - acc: 0.7912 - val_loss: 0.7195 - val_acc: 0.8493\n",
      "Epoch 4/100\n",
      "76315/76315 [==============================] - 12s 157us/sample - loss: 0.5665 - acc: 0.8323 - val_loss: 0.5284 - val_acc: 0.8615\n",
      "Epoch 5/100\n",
      "76315/76315 [==============================] - 12s 163us/sample - loss: 0.4779 - acc: 0.8579 - val_loss: 0.3958 - val_acc: 0.8892\n",
      "Epoch 6/100\n",
      "76315/76315 [==============================] - 12s 160us/sample - loss: 0.4153 - acc: 0.8767 - val_loss: 0.3612 - val_acc: 0.8943\n",
      "Epoch 7/100\n",
      "76315/76315 [==============================] - 12s 157us/sample - loss: 0.3738 - acc: 0.8887 - val_loss: 0.3232 - val_acc: 0.9036\n",
      "Epoch 8/100\n",
      "76315/76315 [==============================] - 13s 171us/sample - loss: 0.3378 - acc: 0.8976 - val_loss: 0.3198 - val_acc: 0.9047\n",
      "Epoch 9/100\n",
      "76315/76315 [==============================] - 13s 169us/sample - loss: 0.3114 - acc: 0.9061 - val_loss: 0.2933 - val_acc: 0.9139\n",
      "Epoch 10/100\n",
      "76315/76315 [==============================] - 13s 168us/sample - loss: 0.2846 - acc: 0.9136 - val_loss: 0.2853 - val_acc: 0.9157\n",
      "Epoch 11/100\n",
      "76315/76315 [==============================] - 13s 169us/sample - loss: 0.2619 - acc: 0.9200 - val_loss: 0.2790 - val_acc: 0.9183\n",
      "Epoch 12/100\n",
      "76315/76315 [==============================] - 13s 168us/sample - loss: 0.2464 - acc: 0.9241 - val_loss: 0.2854 - val_acc: 0.9156\n",
      "Epoch 13/100\n",
      "76315/76315 [==============================] - 13s 172us/sample - loss: 0.2317 - acc: 0.9292 - val_loss: 0.2778 - val_acc: 0.9185\n",
      "Epoch 14/100\n",
      "76315/76315 [==============================] - 14s 179us/sample - loss: 0.2129 - acc: 0.9349 - val_loss: 0.2658 - val_acc: 0.9223\n",
      "Epoch 15/100\n",
      "76315/76315 [==============================] - 14s 178us/sample - loss: 0.2001 - acc: 0.9385 - val_loss: 0.2563 - val_acc: 0.9269\n",
      "Epoch 16/100\n",
      "76315/76315 [==============================] - 13s 174us/sample - loss: 0.1875 - acc: 0.9414 - val_loss: 0.2616 - val_acc: 0.9263\n",
      "Epoch 17/100\n",
      "76315/76315 [==============================] - 13s 174us/sample - loss: 0.1768 - acc: 0.9446 - val_loss: 0.2716 - val_acc: 0.9228\n",
      "Epoch 18/100\n",
      "76315/76315 [==============================] - 14s 182us/sample - loss: 0.1683 - acc: 0.9470 - val_loss: 0.2581 - val_acc: 0.9284\n",
      "Epoch 19/100\n",
      "76315/76315 [==============================] - 14s 182us/sample - loss: 0.1622 - acc: 0.9496 - val_loss: 0.2505 - val_acc: 0.9304\n",
      "Epoch 20/100\n",
      "76315/76315 [==============================] - 14s 178us/sample - loss: 0.1520 - acc: 0.9526 - val_loss: 0.2561 - val_acc: 0.9296\n",
      "Epoch 21/100\n",
      "76315/76315 [==============================] - 13s 173us/sample - loss: 0.1463 - acc: 0.9538 - val_loss: 0.2693 - val_acc: 0.9265\n",
      "Epoch 22/100\n",
      "76315/76315 [==============================] - 13s 170us/sample - loss: 0.1428 - acc: 0.9549 - val_loss: 0.2529 - val_acc: 0.9299\n",
      "Epoch 23/100\n",
      "76315/76315 [==============================] - 12s 160us/sample - loss: 0.1393 - acc: 0.9562 - val_loss: 0.2499 - val_acc: 0.9320\n",
      "Epoch 24/100\n",
      "76315/76315 [==============================] - 12s 161us/sample - loss: 0.1247 - acc: 0.9611 - val_loss: 0.2599 - val_acc: 0.9334\n",
      "Epoch 25/100\n",
      "76315/76315 [==============================] - 12s 157us/sample - loss: 0.1199 - acc: 0.9629 - val_loss: 0.2670 - val_acc: 0.9296\n",
      "Epoch 26/100\n",
      "76315/76315 [==============================] - 12s 158us/sample - loss: 0.1223 - acc: 0.9611 - val_loss: 0.2599 - val_acc: 0.9332\n",
      "Epoch 27/100\n",
      "76315/76315 [==============================] - 12s 160us/sample - loss: 0.1102 - acc: 0.9653 - val_loss: 0.2697 - val_acc: 0.9334\n",
      "Epoch 28/100\n",
      "76315/76315 [==============================] - 12s 160us/sample - loss: 0.1064 - acc: 0.9659 - val_loss: 0.2592 - val_acc: 0.9345\n",
      "Epoch 29/100\n",
      "76315/76315 [==============================] - 13s 164us/sample - loss: 0.1065 - acc: 0.9661 - val_loss: 0.2644 - val_acc: 0.9329\n",
      "Epoch 30/100\n",
      "76315/76315 [==============================] - 12s 157us/sample - loss: 0.1024 - acc: 0.9676 - val_loss: 0.2798 - val_acc: 0.9320\n",
      "Epoch 31/100\n",
      "76315/76315 [==============================] - 13s 166us/sample - loss: 0.1030 - acc: 0.9671 - val_loss: 0.2725 - val_acc: 0.9331\n",
      "Epoch 32/100\n",
      "76315/76315 [==============================] - 12s 157us/sample - loss: 0.0945 - acc: 0.9697 - val_loss: 0.2817 - val_acc: 0.9324\n",
      "Epoch 33/100\n",
      "76315/76315 [==============================] - 12s 160us/sample - loss: 0.0919 - acc: 0.9705 - val_loss: 0.2803 - val_acc: 0.9328\n",
      "Epoch 34/100\n",
      "76315/76315 [==============================] - 12s 155us/sample - loss: 0.0903 - acc: 0.9714 - val_loss: 0.2917 - val_acc: 0.9309\n",
      "Epoch 35/100\n",
      "76315/76315 [==============================] - 12s 161us/sample - loss: 0.0860 - acc: 0.9725 - val_loss: 0.2902 - val_acc: 0.9327\n",
      "Epoch 36/100\n",
      "76315/76315 [==============================] - 12s 162us/sample - loss: 0.0862 - acc: 0.9725 - val_loss: 0.2785 - val_acc: 0.9356\n",
      "Epoch 37/100\n",
      "76315/76315 [==============================] - 13s 167us/sample - loss: 0.0807 - acc: 0.9742 - val_loss: 0.2832 - val_acc: 0.9353\n",
      "Epoch 38/100\n",
      "76315/76315 [==============================] - 12s 163us/sample - loss: 0.0797 - acc: 0.9744 - val_loss: 0.2855 - val_acc: 0.9355\n",
      "Epoch 39/100\n",
      "76315/76315 [==============================] - 12s 158us/sample - loss: 0.0789 - acc: 0.9751 - val_loss: 0.2931 - val_acc: 0.9362\n",
      "Epoch 40/100\n",
      "76315/76315 [==============================] - 12s 161us/sample - loss: 0.0738 - acc: 0.9762 - val_loss: 0.2787 - val_acc: 0.9367\n",
      "Epoch 41/100\n",
      "76315/76315 [==============================] - 12s 153us/sample - loss: 0.0778 - acc: 0.9745 - val_loss: 0.2876 - val_acc: 0.9355\n",
      "Epoch 42/100\n",
      "76315/76315 [==============================] - 12s 161us/sample - loss: 0.0745 - acc: 0.9764 - val_loss: 0.3038 - val_acc: 0.9347\n",
      "Epoch 43/100\n",
      "76315/76315 [==============================] - 12s 162us/sample - loss: 0.0686 - acc: 0.9781 - val_loss: 0.2928 - val_acc: 0.9371\n",
      "Epoch 44/100\n",
      "76315/76315 [==============================] - 12s 163us/sample - loss: 0.0706 - acc: 0.9772 - val_loss: 0.2959 - val_acc: 0.9361\n",
      "Epoch 45/100\n",
      "76315/76315 [==============================] - 12s 157us/sample - loss: 0.0709 - acc: 0.9777 - val_loss: 0.2902 - val_acc: 0.9369\n",
      "Epoch 46/100\n",
      "76315/76315 [==============================] - 12s 157us/sample - loss: 0.0678 - acc: 0.9776 - val_loss: 0.2916 - val_acc: 0.9380\n",
      "Epoch 47/100\n",
      "76315/76315 [==============================] - 12s 154us/sample - loss: 0.0638 - acc: 0.9796 - val_loss: 0.3095 - val_acc: 0.9349\n",
      "Epoch 48/100\n",
      "76315/76315 [==============================] - 12s 155us/sample - loss: 0.0604 - acc: 0.9805 - val_loss: 0.3112 - val_acc: 0.9383\n",
      "Epoch 49/100\n",
      "76315/76315 [==============================] - 13s 164us/sample - loss: 0.0628 - acc: 0.9793 - val_loss: 0.3046 - val_acc: 0.9363\n",
      "Epoch 50/100\n",
      "76315/76315 [==============================] - 12s 159us/sample - loss: 0.0598 - acc: 0.9806 - val_loss: 0.3198 - val_acc: 0.9360\n",
      "Epoch 51/100\n",
      "76315/76315 [==============================] - 12s 156us/sample - loss: 0.0608 - acc: 0.9804 - val_loss: 0.3210 - val_acc: 0.9361\n",
      "Epoch 52/100\n",
      "76315/76315 [==============================] - 13s 165us/sample - loss: 0.0598 - acc: 0.9809 - val_loss: 0.3126 - val_acc: 0.9397\n",
      "Epoch 53/100\n",
      "76315/76315 [==============================] - 12s 162us/sample - loss: 0.0571 - acc: 0.9815 - val_loss: 0.3158 - val_acc: 0.9369\n",
      "Epoch 54/100\n",
      "76315/76315 [==============================] - 13s 168us/sample - loss: 0.0588 - acc: 0.9809 - val_loss: 0.3192 - val_acc: 0.9371\n",
      "Epoch 55/100\n",
      "76315/76315 [==============================] - 13s 167us/sample - loss: 0.0551 - acc: 0.9819 - val_loss: 0.3329 - val_acc: 0.9365\n",
      "Epoch 56/100\n",
      "76315/76315 [==============================] - 13s 167us/sample - loss: 0.0545 - acc: 0.9824 - val_loss: 0.3342 - val_acc: 0.9342\n",
      "Epoch 57/100\n",
      "76315/76315 [==============================] - 12s 158us/sample - loss: 0.0545 - acc: 0.9826 - val_loss: 0.3352 - val_acc: 0.9353\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76315/76315 [==============================] - 12s 156us/sample - loss: 0.0490 - acc: 0.9840 - val_loss: 0.3309 - val_acc: 0.9374\n",
      "Epoch 59/100\n",
      "76315/76315 [==============================] - 12s 157us/sample - loss: 0.0510 - acc: 0.9839 - val_loss: 0.3420 - val_acc: 0.9361\n",
      "Epoch 60/100\n",
      "76315/76315 [==============================] - 12s 156us/sample - loss: 0.0534 - acc: 0.9827 - val_loss: 0.3328 - val_acc: 0.9384\n",
      "Epoch 61/100\n",
      "76315/76315 [==============================] - 12s 151us/sample - loss: 0.0556 - acc: 0.9819 - val_loss: 0.3243 - val_acc: 0.9375\n",
      "Epoch 62/100\n",
      "76315/76315 [==============================] - 12s 152us/sample - loss: 0.0490 - acc: 0.9846 - val_loss: 0.3227 - val_acc: 0.9383\n",
      "Epoch 63/100\n",
      "76315/76315 [==============================] - 13s 164us/sample - loss: 0.0477 - acc: 0.9849 - val_loss: 0.3297 - val_acc: 0.9368\n",
      "Epoch 64/100\n",
      "76315/76315 [==============================] - 11s 150us/sample - loss: 0.0454 - acc: 0.9854 - val_loss: 0.3153 - val_acc: 0.9393\n",
      "Epoch 65/100\n",
      "76315/76315 [==============================] - 12s 156us/sample - loss: 0.0408 - acc: 0.9870 - val_loss: 0.3571 - val_acc: 0.9361\n",
      "Epoch 66/100\n",
      "76315/76315 [==============================] - 12s 151us/sample - loss: 0.0470 - acc: 0.9848 - val_loss: 0.3524 - val_acc: 0.9347\n",
      "Epoch 67/100\n",
      "76315/76315 [==============================] - 11s 147us/sample - loss: 0.0485 - acc: 0.9842 - val_loss: 0.3541 - val_acc: 0.9382\n",
      "Epoch 68/100\n",
      "76315/76315 [==============================] - 12s 159us/sample - loss: 0.0450 - acc: 0.9859 - val_loss: 0.3556 - val_acc: 0.9358\n",
      "Epoch 69/100\n",
      "76315/76315 [==============================] - 12s 160us/sample - loss: 0.0447 - acc: 0.9854 - val_loss: 0.3408 - val_acc: 0.9371\n",
      "Epoch 70/100\n",
      "76315/76315 [==============================] - 12s 159us/sample - loss: 0.0436 - acc: 0.9862 - val_loss: 0.3542 - val_acc: 0.9375\n",
      "Epoch 71/100\n",
      "76315/76315 [==============================] - 12s 151us/sample - loss: 0.0455 - acc: 0.9853 - val_loss: 0.3926 - val_acc: 0.9336\n",
      "Epoch 72/100\n",
      "76315/76315 [==============================] - 12s 153us/sample - loss: 0.0442 - acc: 0.9854 - val_loss: 0.3559 - val_acc: 0.9380\n",
      "Epoch 73/100\n",
      "76315/76315 [==============================] - 12s 153us/sample - loss: 0.0437 - acc: 0.9862 - val_loss: 0.3604 - val_acc: 0.9365\n",
      "Epoch 74/100\n",
      "76315/76315 [==============================] - 12s 154us/sample - loss: 0.0413 - acc: 0.9870 - val_loss: 0.3468 - val_acc: 0.9400\n",
      "Epoch 75/100\n",
      "76315/76315 [==============================] - 12s 158us/sample - loss: 0.0402 - acc: 0.9869 - val_loss: 0.3385 - val_acc: 0.9391\n",
      "Epoch 76/100\n",
      "76315/76315 [==============================] - 12s 162us/sample - loss: 0.0379 - acc: 0.9877 - val_loss: 0.3674 - val_acc: 0.9358\n",
      "Epoch 77/100\n",
      "76315/76315 [==============================] - 12s 160us/sample - loss: 0.0390 - acc: 0.9876 - val_loss: 0.3649 - val_acc: 0.9358\n",
      "Epoch 78/100\n",
      "76315/76315 [==============================] - 12s 163us/sample - loss: 0.0423 - acc: 0.9863 - val_loss: 0.3503 - val_acc: 0.9382\n",
      "Epoch 79/100\n",
      "76315/76315 [==============================] - 12s 158us/sample - loss: 0.0383 - acc: 0.9880 - val_loss: 0.3563 - val_acc: 0.9387\n",
      "Epoch 80/100\n",
      "76315/76315 [==============================] - 13s 166us/sample - loss: 0.0374 - acc: 0.9875 - val_loss: 0.3508 - val_acc: 0.9386\n",
      "Epoch 81/100\n",
      "76315/76315 [==============================] - 12s 162us/sample - loss: 0.0332 - acc: 0.9893 - val_loss: 0.3673 - val_acc: 0.9393\n",
      "Epoch 82/100\n",
      "76315/76315 [==============================] - 12s 155us/sample - loss: 0.0372 - acc: 0.9881 - val_loss: 0.3815 - val_acc: 0.9382\n",
      "Epoch 83/100\n",
      "76315/76315 [==============================] - 12s 158us/sample - loss: 0.0342 - acc: 0.9892 - val_loss: 0.3734 - val_acc: 0.9354\n",
      "Epoch 84/100\n",
      "76315/76315 [==============================] - 12s 152us/sample - loss: 0.0380 - acc: 0.9878 - val_loss: 0.3568 - val_acc: 0.9365\n",
      "Epoch 85/100\n",
      "76315/76315 [==============================] - 12s 154us/sample - loss: 0.0349 - acc: 0.9886 - val_loss: 0.3693 - val_acc: 0.9390\n",
      "Epoch 86/100\n",
      "76315/76315 [==============================] - 12s 160us/sample - loss: 0.0362 - acc: 0.9882 - val_loss: 0.3559 - val_acc: 0.9396\n",
      "Epoch 87/100\n",
      "76315/76315 [==============================] - 12s 161us/sample - loss: 0.0338 - acc: 0.9894 - val_loss: 0.3710 - val_acc: 0.9383\n",
      "Epoch 88/100\n",
      "76315/76315 [==============================] - 13s 166us/sample - loss: 0.0348 - acc: 0.9888 - val_loss: 0.3932 - val_acc: 0.9359\n",
      "Epoch 89/100\n",
      "76315/76315 [==============================] - 13s 167us/sample - loss: 0.0339 - acc: 0.9889 - val_loss: 0.3780 - val_acc: 0.9379\n",
      "Epoch 90/100\n",
      "76315/76315 [==============================] - 13s 167us/sample - loss: 0.0345 - acc: 0.9892 - val_loss: 0.3869 - val_acc: 0.9386\n",
      "Epoch 91/100\n",
      "76315/76315 [==============================] - 12s 158us/sample - loss: 0.0384 - acc: 0.9877 - val_loss: 0.3698 - val_acc: 0.9407\n",
      "Epoch 92/100\n",
      "76315/76315 [==============================] - 12s 161us/sample - loss: 0.0329 - acc: 0.9892 - val_loss: 0.3566 - val_acc: 0.9404\n",
      "Epoch 93/100\n",
      "76315/76315 [==============================] - 12s 161us/sample - loss: 0.0309 - acc: 0.9901 - val_loss: 0.4153 - val_acc: 0.9362\n",
      "Epoch 94/100\n",
      "76315/76315 [==============================] - 12s 163us/sample - loss: 0.0336 - acc: 0.9893 - val_loss: 0.3796 - val_acc: 0.9377\n",
      "Epoch 95/100\n",
      "76315/76315 [==============================] - 12s 159us/sample - loss: 0.0413 - acc: 0.9871 - val_loss: 0.3965 - val_acc: 0.9380\n",
      "Epoch 96/100\n",
      "76315/76315 [==============================] - 12s 162us/sample - loss: 0.0315 - acc: 0.9895 - val_loss: 0.3676 - val_acc: 0.9393\n",
      "Epoch 97/100\n",
      "76315/76315 [==============================] - 12s 159us/sample - loss: 0.0280 - acc: 0.9912 - val_loss: 0.3939 - val_acc: 0.9384\n",
      "Epoch 98/100\n",
      "76315/76315 [==============================] - 12s 163us/sample - loss: 0.0308 - acc: 0.9903 - val_loss: 0.3935 - val_acc: 0.9366\n",
      "Epoch 99/100\n",
      "76315/76315 [==============================] - 12s 155us/sample - loss: 0.0279 - acc: 0.9913 - val_loss: 0.3913 - val_acc: 0.9399\n",
      "Epoch 100/100\n",
      "76315/76315 [==============================] - 12s 163us/sample - loss: 0.0297 - acc: 0.9906 - val_loss: 0.3928 - val_acc: 0.9377\n"
     ]
    }
   ],
   "source": [
    "vm.model.train(X_train, Y_train, batch_size=1024, epoch=100, validation_data=(X_test, Y_test), callbacks=[logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3XmcXPV55/vPU9Xd1Xu3Wt2tpbWDEGIziAaM8QJ4CXhhiY2Dd3tic29i4sQ3yQTP4ng8k5vceTnxJGNCzNhOcMYBA3ZsOZeYALbBG1jC7BICoQW1tt6X6qXWZ/74VbdarepFQkctqb7v16te3afqVNVz6lQ9z/n9fmcxd0dERAQgNt8BiIjIyUNFQUREJqgoiIjIBBUFERGZoKIgIiITVBRERGSCioKIiExQURARkQkqCiIiMqFsvgM4Ws3Nzb5q1ar5DkNE5JTy5JNPdrt7y2zznXJFYdWqVWzevHm+wxAROaWY2e65zKfuIxERmaCiICIiEyIrCmb2DTPrNLPnp3nczOxvzGy7mT1rZhuiikVEROYmypbCPwDXzPD4tcDawu0W4I4IYxERkTmIrCi4+2NA7wyzXA9804PHgUYzWxJVPCIiMrv5HFNoA/ZMmu4o3HcEM7vFzDab2eaurq4TEpyISCmaz6JgRe4rehk4d7/T3dvdvb2lZdbdbEVE5BjN53EKHcDySdPLgH3zFIuIyGvm7vSNZEhn8zRWl1NZHp923mwuz66eEbYdGKKjb4SGqnIW1iaoryyjfzRD51CKvuE0VeVxGqrLaagq57y2BtoaqyJdhvksChuBW83sHuAyYMDd989jPCIlpXc4DUBTTUWk7+PuDKdz9A2nyeUdMzCMoVSG3uE0vcNp0tk8MTNiMWisqmB5UzXLFlSRyzvbO5O8dHCIgdEMtYkyaivLGEnn2Lp/kC37BulKpmhrrGLZgioaqio4ODjGvv5RBkYztDVWsWJhNUsaKkmmQgwDoxnK4zEqy2OUx2N0DaXo6B/lwMAo5fEYDVUhAcfMyOTy5PJOJu9ksnkyuTwLqitY3VzDmpYa8g47u5Ps6Bpmb/8o3ckUmdyhDo/qijhLGiq5aMUC2lcuYHFDJU/u7uOJHb0809FPKps/qs/yz248jw9dtvJ4r6LDmHvRHpvX/sJmdwNXAs3AQeBPgXIAd/87MzPgK4Q9lEaAT7j7rIcqt7e3u45ollIyOJaho3eUvDsxM8riRmtdgoaqcsLP6HB9w2l+uaOHrqEUqWyOVCbPaCbHSDrHSDrL3v5Rth1I0p1MAbCmpYZLVjaxfkkddZXl1FaWkc7m2XZgiBcPDHFgcJSaijLqKstJlMXoGU7Rk0wzNJalsbqclroEC2sqMDNyeSebzzMwmqEnmaZvJE3fcIZ07uiS31xUlcdZv6SO1rpK9g+OsbdvhP6RDIvqK1naWElDVTl7+8fY3TPMSDqHGTRWlVNfVU4254xlcqSyeVrqErQ1VrG4oZJc3hkYzTA4msGBeMwoixnl8VBAymJG73CaHd1JupOhqDbXJljTXMOypipa6ypprUuQKI/RP5KhbzjNrp4RntzdS99IBoCYwXltDVyyqon1S+o5e3EdKxdWMzSWpTuZYmA0w4LqClrqEjTVVDCayTEwkmFgNCxbS13imD4vM3vS3dtnnS+qohAVFQWZD+7O4FiW6oo45fHDh+IGxzKMpnPEzIjHwtZlMpVlOJUlmcqSHAt/s3mnLhGSa8ygK5miayhFdzLN4FiGobHwnGzeyeXzjKZzvNo7MpF8pqqpiLNsQTXNdRU01YRuh+f3DfJsRz9Tf9ZlMaO6Ik51RRmL6hOctaiOdYvryOScJ3f3smlXHwOjmcOeE48Za5praFtQxUg6x9BYlnQ2R1NNBc21CWoTZfSNZOhKpugdTmEYMQvPa6yuYEF1BU015TTVJGiqKaexuoLyuJHPh8HD2kS88FgFibIY7pBzp3c4xau9I+zuGSFmxlmLajlrUR0LaxIMp8NnVBaPsaKpmnjs8KLo7kcUSndnKJWlpqLsiPlfi4HRDGZQX1k+67zuzo7uYQ4OjHH+sgbq5vCc401FQWSSdDbP9s4ke/pGaKqpYFFdJQtqyhnLHErgZlAWi5F3Z9uBIZ7e08+zHf3sHxijJ5kmncsTM1jSELoqxjI5dveGrdPXoiIeo74qFIvxolMWMxLlMZYvqGZ1cw3Lm6opj4fYMrk8BwbG2Ns/SkffKD3JFL3DafpGMqxpqeHNa1t481ktrG6uIVEWo6IsdkQhmyqfd/pG0iRTWYbGssTMWNNSM2OfuJxa5loUTrkT4knpGcvk6B/JkHMnn3dG0jn6R0IS7E6m2Nc/yr7+UdK5PGtbwxZwY3U5L+4f4vl9A2zZN8j2ziTZ/NFtAFWVxzm/rYErzmymuTZ0kQyOZejoG6Wjb4T6qnLedf4SljdVU1dZRt5Dco3HjLrKMmoqyqhJlFFXWUZtImyljifdbD5Pa12ClrpK6ivLinYDnUixmLGwNsHC2mPrmpDTh4qCzItc3ukdTtOdTE1s9e4fGGUsk5/YV3n/wBhbDwyyq3uYmfJ5WcxY3FBJWcz44fMHDpu3uTbBuUvruersVtYvqWdlU3XYs2NwjN7hNFUVceoqy6iuKJuIK+/OGS21rG2tpWyWLWyR042KgkRqb/8oj73UxRM7ejhQSMTjt6mJvixmoW8ZcIeWugTrl9TxnguWsqi+kngMYmZUlsdZUF1BY3U5C2sraK2rnOgrHsvk2N6ZpHc4zdmL62itrzzxCy1yClNRkDkZGsvw9J5++kcyDI5lGE5lyeScdDbPcCrLrp4RdnYn2dc/RqI8Rm0ifLU6+kYBWFSfYEVT6B+/eOUCmmsTE7cljZW0NVbRXJt4zQOBleVxzmtreM3LK1KqVBQECFvY2w4MsXX/IOlcfmJXue5kmrt+sYv7Nu9hOJ0r+tyKshirFlaztrWOq9a1ks7lSY5lSefyfPwNq3jLWS2c2Vo77/3mIjI7FYUS9/iOHv7mkZd5fEfPtP325XHjPRcs5cYNbbTWhf2/ayvLKI8b5bEYseO4m5+IzC8VhRKTTGXZ0zvCru5h/vHx3fzilR5a6xL8zpVncH5bA+csaaCiLBaOFt0/CMBN7ctorVPfvEgpUFE4zbiH0wK80jVMR98IHX2j7C3ssrm3f/Swfeqbayv4z+8+hw9dtuKI/dEXN1Ry1dmtJzp8EZlnKgqngVQ2x6adfTy89SAPbTnI3v7RicdqE2W0NVbRtqCKC5c3smxBNcubqli+oJp1i+t0cJKIHEZF4RSUyztb9w/y+I4efra9myd29DKayZEoi/Gmtc383tVncl5bQ+EEYcXPjyMiUoyKwimibzjNgy8c4N+2HGTTzl6GUlkA1jTX8P72ZbxpbQtvOHPhxEFYIiLHQhnkJLZ/YJRHtnbyb1sO8vPt3eTyzvKmKt79uqVctrqJS1c3sTTic6vLa5DLQj4D5VpHAPTuCEcl1i6CRO18RwO5DKSGoLIRYkdx5Lo7DOyBjs0w0gNlCYgnoHkttG04fvG5Q99OqFsK5SduRw8VhZPM/oFRvvfUPn7wzL6JvX9WLqzmljev4V3nL+HcpfXqDposl4X0UPhxQ/gBxaf5Wie7oHsbVC2A2sXhb2oAhrsh2QmD+8KPfbgLlm6As34DKushn4Odj8HWH0BFNbS1Q9vFUN92ZDJxh31PwTN3w3P3h7hWXg5nvg2WXAg45LOAhWRU1Qg1zVA5zQF3+Rx0boXOLVDbCk1rQuydW+DVX8LeJyFeER6raYHMaFieke7w+s1nQfOZMHQQdv003Mqq4Jzr4JwbYNG5MPn7lOyE578DvTthxWWw8o1QtwjSw9C3G4b2hWVKJcPzzroWahYeev7BLeH51QvDe9cvhVcegWe+DQefOzRfeQ0svxTOvRHWvweqmw49lhqCPU/A7l+EOFKDMDYIuRTEysItn4XRPhjtD8m9fgk0LIMFq2HNlbDmLYc+03wO+l8Ny77zsfDaw92QGQmPxxPQtDp8tm0bYOUVYf2nh8O63PdUWO7RPhjpha4XIXmw+Ppqa4fLfxdWXwm9r4R5B/ZCdizcxgbDd6x/Nwz3hOWuaQ7rdNE5sPj88L166cHwOfbthFg5LL0Qll8G598U/o+QzpJ6kvjpy1189dEd/PyVbtxhw4pG3nHuYt62vpUzWiI+8CuVhHh52OKZzD38MHLpQ1tVA3vCLT0ctoxaz4G6JYcnlsnPP9q4e3fCSz8Mt5GekMDKEmCx8OPOZyEzHJLBaB+kk4c/3+LhR9XQFhJT1YIQx54noOflucUQT4QEFK+AlW8IiW64MySyfCZ8HuNiZWF+sxCf58Lj8QSc/c4Qyys/hs4XZn7P5nWw4vUhSY/0wuBe6NsF+54ORW869W1h+YY7C8UGSNSHZDPSGxLquKoFsOqNMDYAu34GnoeaVlh4RkiIyU545UdhGcoqQxKDUFzG+qf5rCpg/XWw9u3w3H2w/WHClXan5JW2i+H894dEnTwYCvD2h0LrIVYWWg/jZ70a2h9isDgsWBWeU1kfPlPPhe9iLB6Wp2pBeP7g3pB8u18On1esDFrWh+9I8sChz6amFVZdET63ykaoqAkJv3dneG73tkPrdfw5ANXNhfdrhKYzYFl7uNW3QTYVbq/8CJ64IyzTEZ9TImztV9RCw3JoXBGKwWhf2AgZ2AvdL4Xlg/B9X/1mWPdOGOiAPb8Kxek9/wMu/OD034cZ6NTZp4g9vSP8t/9/Cw++cJC2xipual/GjRe1sXJhzdxfJJ+H/l3hh1zTEhL8dPP1bIeOTeHW9WL4AicPQqIBLng/bPho+OI/+2145p4w/2wS9VC3OPzgKuvD6w3sPZRIKxsgURe+8Nmx8KNesAqWvA4WnRe2ag88B/ufOfR+LWeHrb7xLSz3wlZiPHTHVDWFH+l4wqioDUluYE/YKhzcF5LiSE9I5G0XhwS/+PywtZY8GB6vagyfWU1z+IHXt0F5NXT8CrZsDEmu5aywhbb2HSFRHXw+bKGP9IRkkEsX4ouFx5vWwDnXh9ceN7A3bDlObOnmQsIe7YeBV8OP/tUnQssFC0myoQ2WXgTLLg1xj/SE9TXQEbbCV14eto4hvP9Yf/gOjHdXuYfl7H4pfFat5x5q2SS74MUfwN5fh9fs3RG+N+e9Fy64GRaeCQeeCcWjd2dhK3xV+JuoD8l0bACe/lZoFY0NhPV/6S1wyW+HddH9Uihsyy4JGxBTucOBZ8PnnDwQ6ojnQ+ti1RVhuY+2mymXCd/t7Q/D/mfDuh1vRay4PHyvZtpQGekNLbA9T4SNiqUbwve0sn5u75/Pw8sPhgLTfBa0rAsFIDaHvfwyY9C1NbTIVr4htP4my6bC53OM3ZEqCie5gdEMX330Fb7+s53EzLj16jP55JtWkygrfHkyY4Ut5Gm+wMlOeOKr4cs7dWuyakH4Aay/DtZdE37wz90Pz383/PggFIFF58LCNSH5dm2DLd8PW8jjVr0Jzrg6JMl4WWErZ1nY0imvDltVnVvDDyB5MMQ01h++zA3LQmLLjIaEMTYQkmFZZfiB9GwPhWC8Cd+4AhadH5LBumtDYi01+XwopNULpy/sJ6P0SCjoSy86oX3fcnRUFE5So+kcd/1yF3f85BUGRjNc97ql3Hbt2WHA2B12/AR++peh/zNWFhJ83WJY9y44/30heT5+Bzz2pZBQl1wQtoKXvC40d4e7w5bk9odDk3pcvCJs6Z71G2ELrPmsI/vDR/tC8Ugn4dzfhAXRXguWfC5sSVYXtvpFJDIqCieZ3T3D/O/Hd3Pv5g4GRjNcta6FP/qNdZy7tCG0Cl78F3j8b0O3RO3iQr+hh0TdvR12/zxMJxpCF8NZ18A7/iwMIhaTz8O+X4cBq8blodUwuTtDREqKrrx2kugeGuVr9/+An798kK2s5h3nLuETV6zmkhWNsP9p+OF9oU92tC9047y7MJA0ddB3cD+88N3QX3rRR+DMt878xrHYocEwEZE5UlE43sYGoXMrfuA59j37CFUdP+M2BqEC8lULiVVeDc/VwHceDHtZxMph/bthw8dg9Vum31+6fglc/ukTuywiUnJUFI6XkV6496NhLICwc12FN/BM5cWcfcX1LGmsIbb9kdDXnx0LA7jr3hn6+Sfv5y0iMo9UFI6HZCd88wbo2U5v+2f5yxdqeHRgER942+X8X28549B1fi94f+jrx+e2i5qIyAkWaVEws2uAvwbiwNfc/S+mPL4S+AbQAvQCH3b3jihjOu4G9sI3r4PBffzqDX/HJx6tprI8zld+ewOXn1GkBXA0h9OLiJxgkRUFM4sDtwNvBzqATWa20d23TJrtS8A33f0uM7sa+HPgI1HFdFxkU/Dj/zccXTjQAQMdeFmC7533FT77UIILl9dxx4c3sKRB57sRkVNPlC2FS4Ht7r4DwMzuAa4HJheFc4DPFv7/MfC9CON57TKj8O0Ph3GBtnZYfD75s67hK72X8le/LOfdFyzhSze9TtcoEJFTVpRFoQ3YM2m6A7hsyjzPAO8ldDHdCNSZ2UJ375k8k5ndAtwCsGLFisgCnlEqCXffHA77v+5/woaPMprO8el/+jU/erGT37nyDP74Het0vWIROaVF2cFdLDtOPVLuj4C3mNlTwFuAvUD2iCe53+nu7e7e3tLScvwjnc3BLfCPN4SzNv7mnbDhowyMZPjw15/gJ9s6+bMbz+NPrjlbBUFETnlRthQ6gOWTppcB+ybP4O77gN8EMLNa4L3uPhBhTEendyf85M/h2XvDCd1u+ns453o6B8f4yNd/xc7uYW7/4AauPX/JfEcqInJcRFkUNgFrzWw1oQVwM3DYOV/NrBnodfc88DnCnkgnh75d8LeXAw5XfAau+AOobqJ3OM1NX/0lXUMpvvHxS3jj2ub5jlRE5LiJrCi4e9bMbgUeJOyS+g13f8HMvghsdveNwJXAn5uZA48BJ88hu8/eC9lRuPXJifMLZXN5bv2nX7N/YIy7P/V6Ll6pk7iJyOkl0uMU3P0B4IEp931+0v/3A/dHGcMxcQ8XDFl5xWEnnPvzf32RX7zSw5duep0KgoiclnQkVTEHngsXCDnvvRN3/fNTHXz9Zzv5+BtW8b6Ll81jcCIi0VFRKOb5+8O1DM65AYC9/aPc9p3nuGx1E//xXevnOTgRkeioKEyVz4crlJ1x9cSJ6v7nIy/jDn/1WxdSHtdHJiKnL2W4qTp+Fa7ze977ANjVPcx9T3bwwctW0NaoU1eIyOlNRWGq5+6Dsio4+50A/PUjL1MeN373qjPmOTARkeipKEyWy8IL3wsXu0/U8dLBIb739F4+9oZVtNbpguQicvpTUZjsib+DkW44//0AfPmhl6ipKOP/frNaCSJSGlQUxu18DB76PKx/D6y7lu2dQ/zr8wf4d29czYKaivmOTkTkhFBRAOjfA/d9HBaeCTfcAWbct7mDspjx0ctXznd0IiInjIpCZgzu/QjkMnDztyBRRzaX57tP7eWqs1tprk3Md4QiIieMrtH80r+Gq6jddBc0rwXgsZe76BpK6chlESk5aikc3AIWg3XXTtx1/5MdLKyp4OqzW+cxMBGRE09FoWsrNK2BstBN1Dec5uEtnVx/YZuOXhaRkqOs17UNWs6emNz4zD7SuTw3tavrSERKT2kXhWwKel45rCjc9+Qezl1az/ol9fMYmIjI/CjtotDzCngOWsOZT18+OMTzewe5SQPMIlKiSrsodG0NfwsthZ9v7wbgbecsmq+IRETmVYkXhW1hz6OF4epqm3b3sbShkmULquc5MBGR+VHaRaGzsOdReSXuzuZdvbSvaprvqERE5k1pF4VJex519I1ycDDFJat07WURKV2lWxSyaeg9tOfRpl29AFyyWi0FESldpVsUel+BfPawolBXWcZZrXXzHJiIyPyJtCiY2TVmts3MtpvZbUUeX2FmPzazp8zsWTN7Z5TxHKazsOdR63hR6KN95QJiMTthIYiInGwiKwpmFgduB64FzgE+YGbnTJntPwH3uvtFwM3A30YVzxG6XizsebSW3uE02zuTGmQWkZIXZUvhUmC7u+9w9zRwD3D9lHkcGD90uAHYF2E8h+t6ERashvJKntzdB8AlKgoiUuKiPHV2G7Bn0nQHcNmUeb4A/JuZ/R5QA7wtwngO1/niYeMJFfEYFyxrOGFvLyJyMoqypVCsc96nTH8A+Ad3Xwa8E/hHMzsiJjO7xcw2m9nmrq6u1x7Z+J5HrYeKwgXLGqgsj7/21xYROYVFWRQ6gOWTppdxZPfQbwP3Arj7L4FKoHnqC7n7ne7e7u7tLS0trz2yiT2P1jOazvH83gGNJ4iIEG1R2ASsNbPVZlZBGEjeOGWeV4G3ApjZekJROA5NgVl0vRj+tqzj2Y5+MjmnfaUOWhMRiawouHsWuBV4ENhK2MvoBTP7opldV5jtD4FPmdkzwN3Ax919ahfT8TccTnxH3RJ294wAsG6xjk8QEYn0Gs3u/gDwwJT7Pj/p/y3AFVHGUFRqKPxN1HJwsB+AlrrECQ9DRORkU5pHNKeTYHEoq+Tg0BgLqss1yCwiQskWhWGoqAUzDgykWFRfOd8RiYicFEqzKKSSkKgFoHNojFYVBRERoFSLQnootBSAAwNjLK7XeIKICJRsURiGihqyuTzdSXUfiYiMK82iUOg+6hlOk3dUFERECkqzKKSTUFHHgYExQEVBRGRcaRaF1BBU1HBwcLwoaExBRARKtSikhwsHroWisFgtBRERoGSLQhIqajk4mCJmsLBWLQURESjFopDLQnYMEnUcHByjpS5BXJfgFBEBSrEopJPhb0UNBwbH1HUkIjJJCReFWjoHUzqaWURkkjkVBTP7jpm9q9hV0U45qUJRSNSqpSAiMsVck/wdwAeBl83sL8zs7AhjilZ6OPyJVTMwmtHuqCIik8ypKLj7w+7+IWADsAt4yMx+YWafMLPyKAM87tLhWgp92QoAdR+JiEwy5+4gM1sIfBz4JPAU8NeEIvFQJJFFpdB91JUORUHdRyIih8zpymtm9l3gbOAfgfe4+/7CQ982s81RBReJQvdRZypcVEenuBAROWSul+P8irv/qNgD7t5+HOOJXqH7aP9oWHS1FEREDplr99F6M2scnzCzBWb2uxHFFK1C99HekTiJshj1VZFeplpE5JQy16LwKXfvH59w9z7gU9GEFLH0MGB0JI1F9ZWY6WhmEZFxcy0KMZuUPc0sDlREE1LECuc9OjCUUteRiMgUcy0KDwL3mtlbzexq4G7gh9GFFaHUECRq6Rwco1XHKIiIHGauReFPgB8BvwN8GngE+PezPcnMrjGzbWa23cxuK/L4l83s6cLtJTPrL/Y6x1U6iRfOkKo9j0REDjenUVZ3zxOOar5jri9c6GK6HXg70AFsMrON7r5l0ut+dtL8vwdcNNfXP2bpYXLl1Yxmcuo+EhGZYq7nPlprZveb2RYz2zF+m+VplwLb3X2Hu6eBe4DrZ5j/A4RuqWilkqRj1QDqPhIRmWKu3Ud/T2glZIGrgG8SDmSbSRuwZ9J0R+G+I5jZSmA1oYsqWukhRq0K0DEKIiJTzbUoVLn7I4C5+253/wJw9SzPKbavp08z783A/e6eK/pCZreY2WYz29zV1TXHkKeRHmaYUAx03iMRkcPNtSiMFU6b/bKZ3WpmNwKtszynA1g+aXoZsG+aeW9mhq4jd7/T3dvdvb2lpWWOIU8jlWTMQvdRTSL+2l5LROQ0M9ei8AdANfAZ4GLgw8DHZnnOJmCtma02swpC4t84dSYzWwcsAH4516Bfk3SSsVjoPkqUqSiIiEw2695Hhb2I3u/ufwwkgU/M5YXdPWtmtxKOcYgD33D3F8zsi8Bmdx8vEB8A7nH36bqWjp98DjIjpGy8KJz61wwSETmeZi0K7p4zs4vNzI42cbv7A8ADU+77/JTpLxzNa74mhTOkjhSKQkVcRUFEZLK5ng3uKeD7ZnYfMDx+p7t/N5KoolK4PvOoVVEeN2IxnfdIRGSyuRaFJqCHw/c4cuAUKwqhng1TpfEEEZEi5npE85zGEU56qXAthRFPUKHxBBGRI8z1ymt/T5FjDNz93x33iKJU6D5KUqVBZhGRIubaffQvk/6vBG5k+mMOTl6F7qOkV6qlICJSxFy7j74zedrM7gYejiSiKBWuupbMJ9RSEBEp4lgz41pgxfEM5IQoXJ95MJ/QQLOISBFzHVMY4vAxhQOEayycWgothUF1H4mIFDXX7qO6qAM5IQpjCoPZChLlKgoiIlPN9XoKN5pZw6TpRjO7IbqwIpJOQnkNqTxqKYiIFDHXzPin7j4wPuHu/cCfRhNShArXZ05l8hpoFhEpYq6Zsdh8c92d9eSRHoaKWtK5PBUaaBYROcJci8JmM/srMzvDzNaY2ZeBJ6MMLBLpJFTUkMrk1FIQESlirpnx94A08G3gXmAU+HRUQUUmlYREHalsXmMKIiJFzHXvo2HgtohjiV46CbWLSGc1piAiUsxc9z56yMwaJ00vMLMHowsrIuPdR9m8Dl4TESlirpvLzYU9jgBw9z5mv0bzySeVxCcGmtVSEBGZaq6ZMW9mE6e1MLNVFDlr6kkvPUyuvAbQpThFRIqZ626l/xH4mZk9Wph+M3BLNCFFxB3SSXJl1YCKgohIMXMdaP6hmbUTCsHTwPcJeyCdOtLDgJMpU0tBRGQ6cz0h3ieB3weWEYrC64FfcvjlOU9uhfMejRcFjSmIiBxprpnx94FLgN3ufhVwEdAVWVRRKFx1LROrAtDeRyIiRcy1KIy5+xiAmSXc/UVgXXRhRaBwfeZUPIwpqKUgInKkuWbGjsJxCt8DHjKz7zOHy3Ga2TVmts3MtptZ0YPfzOz9ZrbFzF4ws3+ae+hHqdBSSMc00CwiMp25DjTfWPj3C2b2Y6AB+OFMzzGzOHA78HagA9hkZhvdfcukedYCnwOucPc+M4vu2IfCmMJYrBoYUfeRiEgRR32mU3d/dPa5ALgU2O7uOwDM7B7gemDLpHk+BdxeOBgOd+882njmrNB9NGZVwIi6j0REiogyM7YBeyZNdxTum+ws4Cwz+7mZPW5m10QWTaH7aNTGB5qEx05AAAAMB0lEQVRVFEREporymghW5L6pR0GXAWuBKwm7u/7UzM6bfEoNADO7hcLBcitWrOCYFLqPxouCWgoiIkeKMjN2AMsnTS/jyMHpDuD77p5x953ANkKROIy73+nu7e7e3tLScmzRtKyDiz7MiCcAtRRERIqJMjNuAtaa2WozqwBuBjZOmed7wFUAZtZM6E7aEUk0Z74Nrr+dVD4ssloKIiJHiiwzunsWuBV4ENgK3OvuL5jZF83susJsDwI9ZrYF+DHwx+7eE1VMAKlsDtDBayIixUR6nWV3fwB4YMp9n5/0vwP/T+F2QqSyeUAtBRGRYkouM44XBY0piIgcqeQyo4qCiMj0Si4zprN5KuIxzIrtMSsiUtpKriiksjm1EkREplFy2TGd1fWZRUSmU3LZMZXNq6UgIjKNksuOaimIiEyv5LJjGFPQgWsiIsWUYFFQS0FEZDollx3TGlMQEZlWyWXHVDZPorzkFltEZE5KLjuOH7wmIiJHKrnsqIFmEZHplVxR0C6pIiLTK7nsqIPXRESmV3LZUS0FEZHplVx2DC0FjSmIiBRTckVBLQURkemVVHbM5510TmMKIiLTKansmM4Vrrqmg9dERIoqqew4filOHbwmIlJcSWXHVDYHQKJcA80iIsWUVFFIF1oKCbUURESKijQ7mtk1ZrbNzLab2W1FHv+4mXWZ2dOF2yejjGe8+0hjCiIixZVF9cJmFgduB94OdACbzGyju2+ZMuu33f3WqOKYLK0xBRGRGUWZHS8Ftrv7DndPA/cA10f4frNSS0FEZGZRZsc2YM+k6Y7CfVO918yeNbP7zWx5sRcys1vMbLOZbe7q6jrmgA61FDTQLCJSTJRFwYrc51OmfwCscvcLgIeBu4q9kLvf6e7t7t7e0tJyzAEd2vtILQURkWKizI4dwOQt/2XAvskzuHuPu6cKk/8LuDjCeEhlCt1HOqJZRKSoKLPjJmCtma02swrgZmDj5BnMbMmkyeuArRHGM3FEs859JCJSXGR7H7l71sxuBR4E4sA33P0FM/sisNndNwKfMbPrgCzQC3w8qnhgUveRzpIqIlJUZEUBwN0fAB6Yct/nJ/3/OeBzUcYw2cRAs1oKIiJFlVR2nNglVUVBRKSoksqOaimIiMyspLKjWgoiIjMrqeyoU2eLiMyspLJjKpujoiyGWbHj6kREpLSKQkaX4hQRmUlJZUhdn1lEZGYllSFDS0EHromITKekikI6l9fuqCIiMyipDJnK5NR9JCIyg5LKkGopiIjMrKQypPY+EhGZWUllyLD3kQaaRUSmU1JFYfzgNRERKa6kMmQ6q+4jEZGZlFSGTGU10CwiMpOSypAaaBYRmVlJZUjtkioiMrOSypDh4DXtfSQiMp2SKgpqKYiIzKxkMmQ+72RyrjEFEZEZlEyGTOfGL8Wp7iMRkemUTFFIZQqX4lRLQURkWpFmSDO7xsy2mdl2M7tthvneZ2ZuZu1RxZLK5QDUfSQiMoPIMqSZxYHbgWuBc4APmNk5RearAz4DPBFVLKCWgojIXESZIS8Ftrv7DndPA/cA1xeZ778C/x0YizAWUtnxMQUVBRGR6USZIduAPZOmOwr3TTCzi4Dl7v4vM72Qmd1iZpvNbHNXV9cxBZNWURARmVWUGdKK3OcTD5rFgC8DfzjbC7n7ne7e7u7tLS0txxRMKjs+pqC9j0REphNlUegAlk+aXgbsmzRdB5wH/MTMdgGvBzZGNdg83lLQmIKIyPSizJCbgLVmttrMKoCbgY3jD7r7gLs3u/sqd18FPA5c5+6bowhGYwoiIrOLLEO6exa4FXgQ2Arc6+4vmNkXzey6qN53OofGFNR9JCIynbIoX9zdHwAemHLf56eZ98ooY0mp+0hEZFYlkyHTOnhNRGRWJZMhdfCaiMjsSiZDaqBZRGR2JZMhtUuqiMjsSiZDrlxYzbXnLdbeRyIiM4h076OTyTvOXcw7zl0832GIiJzUSqalICIis1NREBGRCSoKIiIyQUVBREQmqCiIiMgEFQUREZmgoiAiIhNUFEREZIK5++xznUTMrAvYfYxPbwa6j2M4p4pSXO5SXGYozeUuxWWGo1/ule4+6/WMT7mi8FqY2WZ3j+RynyezUlzuUlxmKM3lLsVlhuiWW91HIiIyQUVBREQmlFpRuHO+A5gnpbjcpbjMUJrLXYrLDBEtd0mNKYiIyMxKraUgIiIzKJmiYGbXmNk2M9tuZrfNdzxRMLPlZvZjM9tqZi+Y2e8X7m8ys4fM7OXC3wXzHevxZmZxM3vKzP6lML3azJ4oLPO3zaxivmM83sys0czuN7MXC+v88hJZ158tfL+fN7O7zazydFvfZvYNM+s0s+cn3Vd03VrwN4Xc9qyZbXgt710SRcHM4sDtwLXAOcAHzOyc+Y0qElngD919PfB64NOF5bwNeMTd1wKPFKZPN78PbJ00/f8BXy4scx/w2/MSVbT+Gvihu58NvI6w/Kf1ujazNuAzQLu7nwfEgZs5/db3PwDXTLlvunV7LbC2cLsFuOO1vHFJFAXgUmC7u+9w9zRwD3D9PMd03Ln7fnf/deH/IUKSaCMs612F2e4CbpifCKNhZsuAdwFfK0wbcDVwf2GW03GZ64E3A18HcPe0u/dzmq/rgjKgyszKgGpgP6fZ+nb3x4DeKXdPt26vB77pweNAo5ktOdb3LpWi0AbsmTTdUbjvtGVmq4CLgCeARe6+H0LhAFrnL7JI/A/g3wP5wvRCoN/ds4Xp03F9rwG6gL8vdJt9zcxqOM3XtbvvBb4EvEooBgPAk5z+6xumX7fHNb+VSlGwIvedtrtdmVkt8B3gD9x9cL7jiZKZvRvodPcnJ99dZNbTbX2XARuAO9z9ImCY06yrqJhCP/r1wGpgKVBD6D6Z6nRb3zM5rt/3UikKHcDySdPLgH3zFEukzKycUBC+5e7fLdx9cLw5WfjbOV/xReAK4Doz20XoFrya0HJoLHQvwOm5vjuADnd/ojB9P6FInM7rGuBtwE5373L3DPBd4A2c/usbpl+3xzW/lUpR2ASsLeyhUEEYmNo4zzEdd4W+9K8DW939ryY9tBH4WOH/jwHfP9GxRcXdP+fuy9x9FWG9/sjdPwT8GHhfYbbTapkB3P0AsMfM1hXueiuwhdN4XRe8CrzezKoL3/fx5T6t13fBdOt2I/DRwl5IrwcGxruZjkXJHLxmZu8kbEHGgW+4+5/Nc0jHnZm9Efgp8ByH+tf/A2Fc4V5gBeFHdZO7Tx3EOuWZ2ZXAH7n7u81sDaHl0AQ8BXzY3VPzGd/xZmYXEgbXK4AdwCcIG3qn9bo2s/8C/BZhb7ungE8S+tBPm/VtZncDVxLOhHoQ+FPgexRZt4Xi+BXC3kojwCfcffMxv3epFAUREZldqXQfiYjIHKgoiIjIBBUFERGZoKIgIiITVBRERGSCioJIxMzsyvGzt4qc7FQURERkgoqCSIGZfdjMfmVmT5vZVwvXaEia2V+a2a/N7BEzaynMe6GZPV44f/0/Tzq3/Zlm9rCZPVN4zhmFl6+ddO2DbxUOOMLM/sLMthRe50vztOgiE1QURAAzW084SvYKd78QyAEfIpxw7dfuvgF4lHBkKcA3gT9x9wsIR5CP3/8t4HZ3fx3hnDzjpxu4CPgDwvU81gBXmFkTcCNwbuF1/lu0SykyOxUFkeCtwMXAJjN7ujC9hnC6kG8X5vnfwBvNrAFodPdHC/ffBbzZzOqANnf/ZwB3H3P3kcI8v3L3DnfPA08Dq4BBYAz4mpn9JuEUBSLzSkVBJDDgLne/sHBb5+5fKDLfTOeFKXYK43GTz8OTA8oK5/+/lHBW2xuAHx5lzCLHnYqCSPAI8D4za4WJ6+GuJPxGxs+++UHgZ+4+APSZ2ZsK938EeLRw7YoOM7uh8BoJM6ue7g0L171ocPcHCF1LF0axYCJHo2z2WUROf+6+xcz+E/BvZhYDMsCnCRevOdfMniRc5eu3Ck/5GPB3haQ/foZSCAXiq2b2xcJr3DTD29YB3zezSkIr47PHebFEjprOkioyAzNLunvtfMchcqKo+0hERCaopSAiIhPUUhARkQkqCiIiMkFFQUREJqgoiIjIBBUFERGZoKIgIiIT/g8WDML3h5WFjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0497263160>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294   2   1 ...   2   0   0]\n",
      " [  1 315   3 ...   0  13   0]\n",
      " [  0  10 271 ...   0   0   0]\n",
      " ...\n",
      " [  1   4   0 ... 709   0   0]\n",
      " [  0   4   0 ...   0 676   2]\n",
      " [  0   0   0 ...   0   0 690]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backward       0.95      0.96      0.96       307\n",
      "         bed       0.86      0.90      0.88       350\n",
      "        bird       0.92      0.88      0.90       307\n",
      "         cat       0.91      0.97      0.94       338\n",
      "         dog       0.95      0.90      0.92       367\n",
      "        down       0.93      0.92      0.93       729\n",
      "      follow       0.87      0.89      0.88       290\n",
      "     forward       0.92      0.81      0.87       281\n",
      "          go       0.87      0.94      0.90       670\n",
      "       happy       0.97      0.92      0.95       362\n",
      "       house       0.98      0.94      0.96       377\n",
      "       learn       0.88      0.91      0.89       281\n",
      "        left       0.95      0.94      0.94       667\n",
      "      marvin       0.93      0.94      0.93       370\n",
      "          no       0.94      0.92      0.93       703\n",
      "         off       0.94      0.90      0.92       710\n",
      "          on       0.89      0.95      0.92       729\n",
      "       right       0.96      0.95      0.95       688\n",
      "      sheila       0.98      0.95      0.96       364\n",
      "        stop       0.97      0.96      0.97       733\n",
      "        tree       0.91      0.85      0.88       273\n",
      "          up       0.91      0.94      0.93       672\n",
      "      visual       0.95      0.96      0.95       295\n",
      "         wow       0.95      0.93      0.94       374\n",
      "         yes       0.98      0.97      0.97       714\n",
      "        zero       0.98      0.95      0.96       743\n",
      "         one       0.94      0.96      0.95       724\n",
      "         two       0.94      0.95      0.94       699\n",
      "       three       0.93      0.93      0.93       727\n",
      "        four       0.91      0.92      0.91       707\n",
      "        five       0.96      0.93      0.95       698\n",
      "         six       0.96      0.98      0.97       686\n",
      "       seven       0.96      0.96      0.96       736\n",
      "       eight       0.92      0.97      0.95       696\n",
      "        nine       0.95      0.97      0.96       712\n",
      "\n",
      "    accuracy                           0.94     19079\n",
      "   macro avg       0.94      0.93      0.93     19079\n",
      "weighted avg       0.94      0.94      0.94     19079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(list(range(0, len(logger.training))), list(map(lambda x:x[1], logger.training)), label=\"training data\")\n",
    "plt.plot(list(range(0, len(logger.testing))), list(map(lambda x:x[1], logger.testing)), label=\"testing data\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "print_metrics(X_test, Y_test, keyword_list, vm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.model.save(\"keyword-cnn.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class\n",
    "class EmotionClassifier(KerasClassifier):\n",
    "    def __init__(self, file_path=None):\n",
    "        super().__init__(file_path)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.expand_dims(np.array([x]), axis=2)\n",
    "        return self._model.predict(x)\n",
    "\n",
    "    def build(self):\n",
    "        # Now we freeze every layer used for extracting features from data\n",
    "        fine_tuned_model = Sequential(vm.model._model.layers[:-3])\n",
    "        fine_tuned_model.add(Dense(128))\n",
    "        fine_tuned_model.add(Dense(6))\n",
    "        fine_tuned_model.add(Activation('softmax'))\n",
    "        fine_tuned_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        # Here I freeze the weoghts for all layer exept the two last one\n",
    "        for layer in fine_tuned_model.layers[:-9]:\n",
    "            print(layer.name)\n",
    "            layer.trainable = False\n",
    "        fine_tuned_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])        \n",
    "        self._model = fine_tuned_model\n",
    "\n",
    "    def train(self, X, Y, batch_size=32, epoch=720, validation_data=None, callbacks=[]):\n",
    "        self._model.fit(X, Y, batch_size=batch_size, epochs=epoch, validation_data=validation_data, callbacks=callbacks)\n",
    "\n",
    "    def transform(self, x, samplerate):\n",
    "        to_process = mfcc(x, samplerate, 13)\n",
    "        to_process = pad_sequences([to_process], maxlen=35, padding='post')[0]\n",
    "        return to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_noise\n",
      "batch_normalization\n",
      "conv1d\n",
      "activation\n",
      "max_pooling1d\n",
      "conv1d_1\n",
      "activation_1\n",
      "max_pooling1d_1\n",
      "conv1d_2\n",
      "activation_2\n",
      "max_pooling1d_2\n"
     ]
    }
   ],
   "source": [
    "# Now we load the new dataset (savee)\n",
    "emotion_list = [\"calm\", \"happy\", \"angry\", \"fearful\", \"surprised\", \"sad\"]\n",
    "emotion_vm = VoiceModule(\"emotion\", emotion_list, EmotionClassifier())\n",
    "# First we change the folder path\n",
    "folder_path = \"../../data/savee\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing calm\n",
      "Doing happy\n",
      "Doing angry\n",
      "Doing fearful\n",
      "Doing surprised\n",
      "Doing sad\n"
     ]
    }
   ],
   "source": [
    "# Now we load the data\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in emotion_list}\n",
    "X_savee, Y_savee = preprare_wav(data, emotion_vm, sample_duration, step)\n",
    "X_savee = X_savee.astype('float32')\n",
    "X_savee_train, X_savee_test, Y_savee_train, Y_savee_test = train_test_split(X_savee, Y_savee, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 975 samples, validate on 244 samples\n",
      "Epoch 1/100\n",
      "975/975 [==============================] - 2s 2ms/sample - loss: 2.2120 - acc: 0.2000 - val_loss: 1.8918 - val_acc: 0.2254\n",
      "Epoch 2/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.8563 - acc: 0.2451 - val_loss: 1.9309 - val_acc: 0.1967\n",
      "Epoch 3/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.8039 - acc: 0.2728 - val_loss: 2.0101 - val_acc: 0.1967\n",
      "Epoch 4/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.7405 - acc: 0.2985 - val_loss: 2.0790 - val_acc: 0.2418\n",
      "Epoch 5/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.6724 - acc: 0.3251 - val_loss: 2.0693 - val_acc: 0.2213\n",
      "Epoch 6/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.6388 - acc: 0.3426 - val_loss: 2.1040 - val_acc: 0.1803\n",
      "Epoch 7/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.5713 - acc: 0.4010 - val_loss: 2.1882 - val_acc: 0.2049\n",
      "Epoch 8/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.6029 - acc: 0.3600 - val_loss: 2.1023 - val_acc: 0.2254\n",
      "Epoch 9/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.5511 - acc: 0.3938 - val_loss: 2.2099 - val_acc: 0.2008\n",
      "Epoch 10/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.4960 - acc: 0.3928 - val_loss: 2.2848 - val_acc: 0.1885\n",
      "Epoch 11/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.4241 - acc: 0.4236 - val_loss: 2.4717 - val_acc: 0.2008\n",
      "Epoch 12/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.4446 - acc: 0.4256 - val_loss: 2.3966 - val_acc: 0.2295\n",
      "Epoch 13/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.3581 - acc: 0.4687 - val_loss: 2.4231 - val_acc: 0.2049\n",
      "Epoch 14/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.3460 - acc: 0.4913 - val_loss: 2.4046 - val_acc: 0.2008\n",
      "Epoch 15/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.3113 - acc: 0.5026 - val_loss: 2.4457 - val_acc: 0.1844\n",
      "Epoch 16/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.2999 - acc: 0.5005 - val_loss: 2.6349 - val_acc: 0.2049\n",
      "Epoch 17/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.2476 - acc: 0.5251 - val_loss: 2.6328 - val_acc: 0.2254\n",
      "Epoch 18/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.2678 - acc: 0.5221 - val_loss: 2.4960 - val_acc: 0.2172\n",
      "Epoch 19/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.2166 - acc: 0.5600 - val_loss: 2.7302 - val_acc: 0.2336\n",
      "Epoch 20/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.2273 - acc: 0.5128 - val_loss: 2.7428 - val_acc: 0.2131\n",
      "Epoch 21/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.2134 - acc: 0.5292 - val_loss: 2.6619 - val_acc: 0.2090\n",
      "Epoch 22/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.1737 - acc: 0.5733 - val_loss: 2.7311 - val_acc: 0.2090\n",
      "Epoch 23/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.0837 - acc: 0.5785 - val_loss: 2.8291 - val_acc: 0.2008\n",
      "Epoch 24/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.0777 - acc: 0.5969 - val_loss: 2.8678 - val_acc: 0.2459\n",
      "Epoch 25/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.0794 - acc: 0.5723 - val_loss: 2.9362 - val_acc: 0.2459\n",
      "Epoch 26/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.1022 - acc: 0.5723 - val_loss: 3.0188 - val_acc: 0.2213\n",
      "Epoch 27/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.1062 - acc: 0.5867 - val_loss: 2.9217 - val_acc: 0.2090\n",
      "Epoch 28/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.0943 - acc: 0.5826 - val_loss: 2.9921 - val_acc: 0.2254\n",
      "Epoch 29/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 1.0103 - acc: 0.6287 - val_loss: 2.9833 - val_acc: 0.1967\n",
      "Epoch 30/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.9902 - acc: 0.6308 - val_loss: 3.0204 - val_acc: 0.2131\n",
      "Epoch 31/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.9954 - acc: 0.6349 - val_loss: 3.2024 - val_acc: 0.2090\n",
      "Epoch 32/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.9946 - acc: 0.6092 - val_loss: 3.2424 - val_acc: 0.2090\n",
      "Epoch 33/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.9381 - acc: 0.6441 - val_loss: 3.2416 - val_acc: 0.2172\n",
      "Epoch 34/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.9664 - acc: 0.6338 - val_loss: 3.2403 - val_acc: 0.2213\n",
      "Epoch 35/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.9847 - acc: 0.6267 - val_loss: 3.3045 - val_acc: 0.1926\n",
      "Epoch 36/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.9405 - acc: 0.6677 - val_loss: 3.3836 - val_acc: 0.2131\n",
      "Epoch 37/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.9362 - acc: 0.6554 - val_loss: 3.3167 - val_acc: 0.2090\n",
      "Epoch 38/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.8721 - acc: 0.6769 - val_loss: 3.4675 - val_acc: 0.2377\n",
      "Epoch 39/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.8834 - acc: 0.6779 - val_loss: 3.4661 - val_acc: 0.2541\n",
      "Epoch 40/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.8812 - acc: 0.6667 - val_loss: 3.3562 - val_acc: 0.2295\n",
      "Epoch 41/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.8516 - acc: 0.6769 - val_loss: 3.7517 - val_acc: 0.2418\n",
      "Epoch 42/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.8983 - acc: 0.6513 - val_loss: 3.5064 - val_acc: 0.2336\n",
      "Epoch 43/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.8944 - acc: 0.6687 - val_loss: 3.5423 - val_acc: 0.2336\n",
      "Epoch 44/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.8129 - acc: 0.7005 - val_loss: 3.6116 - val_acc: 0.2090\n",
      "Epoch 45/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.8714 - acc: 0.6779 - val_loss: 3.6120 - val_acc: 0.2254\n",
      "Epoch 46/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.8290 - acc: 0.6882 - val_loss: 3.7587 - val_acc: 0.2090\n",
      "Epoch 47/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.8411 - acc: 0.6954 - val_loss: 3.8513 - val_acc: 0.2213\n",
      "Epoch 48/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.8222 - acc: 0.6913 - val_loss: 3.8992 - val_acc: 0.2008\n",
      "Epoch 49/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.8317 - acc: 0.6769 - val_loss: 3.7876 - val_acc: 0.1803\n",
      "Epoch 50/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7959 - acc: 0.7067 - val_loss: 3.8120 - val_acc: 0.2008\n",
      "Epoch 51/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.8753 - acc: 0.6749 - val_loss: 3.6314 - val_acc: 0.2049\n",
      "Epoch 52/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7299 - acc: 0.7395 - val_loss: 3.7170 - val_acc: 0.2172\n",
      "Epoch 53/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7840 - acc: 0.7005 - val_loss: 3.8304 - val_acc: 0.2049\n",
      "Epoch 54/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7980 - acc: 0.7015 - val_loss: 3.9337 - val_acc: 0.1967\n",
      "Epoch 55/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7732 - acc: 0.7097 - val_loss: 3.8839 - val_acc: 0.1885\n",
      "Epoch 56/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.8211 - acc: 0.7026 - val_loss: 4.0409 - val_acc: 0.2008\n",
      "Epoch 57/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7553 - acc: 0.7169 - val_loss: 4.1590 - val_acc: 0.1926\n",
      "Epoch 58/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7483 - acc: 0.7159 - val_loss: 4.0355 - val_acc: 0.1967\n",
      "Epoch 59/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7547 - acc: 0.7303 - val_loss: 3.9625 - val_acc: 0.2090\n",
      "Epoch 60/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7649 - acc: 0.7159 - val_loss: 4.0398 - val_acc: 0.2131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7437 - acc: 0.7221 - val_loss: 3.9262 - val_acc: 0.1967\n",
      "Epoch 62/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7396 - acc: 0.7385 - val_loss: 4.1281 - val_acc: 0.2008\n",
      "Epoch 63/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7264 - acc: 0.7262 - val_loss: 4.2920 - val_acc: 0.1885\n",
      "Epoch 64/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6973 - acc: 0.7456 - val_loss: 4.0610 - val_acc: 0.2090\n",
      "Epoch 65/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7048 - acc: 0.7446 - val_loss: 4.3848 - val_acc: 0.2090\n",
      "Epoch 66/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6725 - acc: 0.7467 - val_loss: 4.3964 - val_acc: 0.2377\n",
      "Epoch 67/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6762 - acc: 0.7467 - val_loss: 4.4425 - val_acc: 0.2254\n",
      "Epoch 68/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7731 - acc: 0.7190 - val_loss: 4.2443 - val_acc: 0.2131\n",
      "Epoch 69/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6607 - acc: 0.7590 - val_loss: 4.4747 - val_acc: 0.1967\n",
      "Epoch 70/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6887 - acc: 0.7538 - val_loss: 4.2845 - val_acc: 0.2213\n",
      "Epoch 71/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6735 - acc: 0.7487 - val_loss: 4.5127 - val_acc: 0.2295\n",
      "Epoch 72/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6593 - acc: 0.7733 - val_loss: 4.5411 - val_acc: 0.1926\n",
      "Epoch 73/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6934 - acc: 0.7487 - val_loss: 4.6172 - val_acc: 0.2049\n",
      "Epoch 74/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.5992 - acc: 0.7795 - val_loss: 4.7452 - val_acc: 0.2254\n",
      "Epoch 75/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6261 - acc: 0.7795 - val_loss: 4.8705 - val_acc: 0.2336\n",
      "Epoch 76/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6621 - acc: 0.7631 - val_loss: 4.6604 - val_acc: 0.2336\n",
      "Epoch 77/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6425 - acc: 0.7579 - val_loss: 4.7241 - val_acc: 0.2377\n",
      "Epoch 78/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6868 - acc: 0.7477 - val_loss: 4.7351 - val_acc: 0.2336\n",
      "Epoch 79/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6929 - acc: 0.7497 - val_loss: 4.5021 - val_acc: 0.2131\n",
      "Epoch 80/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6454 - acc: 0.7713 - val_loss: 4.7171 - val_acc: 0.2336\n",
      "Epoch 81/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6679 - acc: 0.7569 - val_loss: 4.6036 - val_acc: 0.2172\n",
      "Epoch 82/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6430 - acc: 0.7682 - val_loss: 4.6552 - val_acc: 0.2213\n",
      "Epoch 83/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6851 - acc: 0.7477 - val_loss: 4.7322 - val_acc: 0.2090\n",
      "Epoch 84/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6578 - acc: 0.7518 - val_loss: 4.6713 - val_acc: 0.2131\n",
      "Epoch 85/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6098 - acc: 0.7795 - val_loss: 4.7304 - val_acc: 0.2049\n",
      "Epoch 86/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6891 - acc: 0.7467 - val_loss: 4.4013 - val_acc: 0.2131\n",
      "Epoch 87/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6949 - acc: 0.7579 - val_loss: 4.5546 - val_acc: 0.2090\n",
      "Epoch 88/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6149 - acc: 0.7795 - val_loss: 4.4662 - val_acc: 0.2131\n",
      "Epoch 89/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.5995 - acc: 0.7856 - val_loss: 4.6266 - val_acc: 0.2254\n",
      "Epoch 90/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6019 - acc: 0.7949 - val_loss: 4.6083 - val_acc: 0.2090\n",
      "Epoch 91/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6278 - acc: 0.7672 - val_loss: 4.7034 - val_acc: 0.2254\n",
      "Epoch 92/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.5740 - acc: 0.7928 - val_loss: 4.6139 - val_acc: 0.2500\n",
      "Epoch 93/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.7654 - acc: 0.7241 - val_loss: 4.2336 - val_acc: 0.2172\n",
      "Epoch 94/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6349 - acc: 0.7785 - val_loss: 4.5912 - val_acc: 0.2254\n",
      "Epoch 95/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6032 - acc: 0.7795 - val_loss: 4.6600 - val_acc: 0.2090\n",
      "Epoch 96/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6436 - acc: 0.7682 - val_loss: 4.5883 - val_acc: 0.2172\n",
      "Epoch 97/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.5645 - acc: 0.7856 - val_loss: 4.5871 - val_acc: 0.2336\n",
      "Epoch 98/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6109 - acc: 0.7836 - val_loss: 4.6739 - val_acc: 0.2213\n",
      "Epoch 99/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.6054 - acc: 0.7774 - val_loss: 4.6520 - val_acc: 0.2131\n",
      "Epoch 100/100\n",
      "975/975 [==============================] - 1s 1ms/sample - loss: 0.5822 - acc: 0.7846 - val_loss: 4.8228 - val_acc: 0.2213\n"
     ]
    }
   ],
   "source": [
    "emotion_vm.model.train(X_savee_train, Y_savee_train, batch_size=10, validation_data=(X_savee_test, Y_savee_test), epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  8  6  3  6  4]\n",
      " [ 8 11 10  5  7  2]\n",
      " [ 7 11 13  2  6  3]\n",
      " [ 5 10  5  1  8  5]\n",
      " [ 6  8  6  4  6  6]\n",
      " [17  8  6  6  2 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.22      0.31      0.26        39\n",
      "       happy       0.20      0.26      0.22        43\n",
      "       angry       0.28      0.31      0.30        42\n",
      "     fearful       0.05      0.03      0.04        34\n",
      "   surprised       0.17      0.17      0.17        36\n",
      "         sad       0.35      0.22      0.27        50\n",
      "\n",
      "    accuracy                           0.22       244\n",
      "   macro avg       0.21      0.21      0.21       244\n",
      "weighted avg       0.22      0.22      0.22       244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_metrics(X_savee_test, Y_savee_test, emotion_list, emotion_vm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
