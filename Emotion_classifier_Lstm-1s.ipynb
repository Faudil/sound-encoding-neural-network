{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import phase if every import is here it is to allow you to run this cell and know if you have any issue and not after a few hours of training\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, Activation, Flatten, MaxPooling1D, BatchNormalization, LSTM, GaussianNoise\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "from src.VoiceModule import VoiceModule\n",
    "from src.classifiers.KerasClassifier import KerasClassifier\n",
    "from prepare_data_utils import load_wav, preprare_wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bdes.zip\n",
      "fearful\n",
      "savee\n",
      "calm\n",
      "happy\n",
      "surprised\n",
      "angry\n",
      "sad\n",
      "keywords\n"
     ]
    }
   ],
   "source": [
    "# print environment\n",
    "folder_path = \"../../data\"\n",
    "for l in os.listdir(folder_path):\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data method\n",
    "\n",
    "def mfcc(buffer, samplerate, dim):\n",
    "    a = librosa.feature.mfcc(y=buffer, sr=samplerate, n_mfcc=dim)\n",
    "    a = np.transpose(a)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback to later draw some graphs\n",
    "\n",
    "class PerformanceLogger(Callback):\n",
    "    def __init__(self):\n",
    "        # List of tuple (loss, accuracy)\n",
    "        self.training = []\n",
    "        self.testing = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.training.append((logs[\"loss\"], logs[\"acc\"]))\n",
    "        self.testing.append((logs[\"val_loss\"], logs[\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prints metrics about a model\n",
    "def print_metrics(X, Y, label_name_list):\n",
    "    Y_pred = vm.model._model.predict(X)\n",
    "    Y_pred = np.argmax(Y_pred, axis=1)\n",
    "    Y_max = np.argmax(Y, axis=1)\n",
    "    print(confusion_matrix(Y_max, Y_pred))\n",
    "    print(classification_report(Y_max, Y_pred, target_names=label_name_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class\n",
    "class EmotionClassifierLstm(KerasClassifier):\n",
    "    def __init__(self, file_path=None):\n",
    "        super().__init__(file_path)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.expand_dims(np.array([x]), axis=2)\n",
    "        return self._model.predict(x)\n",
    "\n",
    "    def build(self):\n",
    "        model = Sequential()\n",
    "        # This first layer add noises to the input data and serve as a data augmentation technique\n",
    "        # Used to prevent overfitting of the LSTM layer and try to extract more significant feature\n",
    "        model.add(GaussianNoise(0.4))\n",
    "        # This layer normalise the data to speed up the training and prevent the gradient of the LSTM to explode\n",
    "        # and reach exponential weight value\n",
    "        model.add(BatchNormalization())\n",
    "        # This is THE feature extraction layer\n",
    "        model.add(LSTM(64, input_shape=(35, 13)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(BatchNormalization())\n",
    "        # This is the second part of the network, this one will be fine tuned later\n",
    "        model.add(GaussianNoise(0.2))\n",
    "\n",
    "        # The two last layers will be fine-tuned at the end of this notebook\n",
    "        model.add(Dense(32))\n",
    "        model.add(Dense(6))\n",
    "        model.add(Activation('softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self._model = model\n",
    "        \n",
    "    def train(self, X, Y, batch_size=32, epoch=720, validation_data=None, callbacks=[]):\n",
    "        self._model.fit(X, Y, batch_size=batch_size, epochs=epoch, validation_data=validation_data, callbacks=callbacks)\n",
    "\n",
    "    def transform(self, x, samplerate):\n",
    "        to_process = mfcc(x, samplerate, 13)\n",
    "        to_process = pad_sequences([to_process], maxlen=35, padding='post')[0]\n",
    "        return to_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciate model\n",
    "emotion_list = [\"calm\", \"happy\", \"angry\", \"fearful\", \"surprised\", \"sad\"]\n",
    "dimension_mfcc = 13\n",
    "samplerate = 16000\n",
    "nb_break=None\n",
    "sample_duration=1\n",
    "step=0.5\n",
    "\n",
    "logger = PerformanceLogger()\n",
    "\n",
    "cls = EmotionClassifierLstm()\n",
    "vm = VoiceModule(\"emotion-1s\", emotion_list, cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing calm\n",
      "Doing happy\n",
      "Doing angry\n",
      "Doing fearful\n",
      "Doing surprised\n",
      "Doing sad\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in emotion_list}\n",
    "X, Y = preprare_wav(data, vm, sample_duration, step)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_file = f\"x_{'_'.join(emotion_list)}-{vm._name}.npy\"\n",
    "Y_file = f\"y_{'_'.join(emotion_list)}-{vm._name}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the prepared input data \n",
    "np.save(X_file, X)\n",
    "np.save(Y_file, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for training\n",
    "X, Y = np.load(X_file), np.load(Y_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5435 1359\n",
      "(35, 13)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "\"\"\"train_size = 80 * len(X) // 100\n",
    "test_size = 20 * len(X) // 100\n",
    "#X = np.expand_dims(X, axis=3)\n",
    "X_train, X_test, = X[:train_size], X[train_size:]\n",
    "Y_train, Y_test = Y[:train_size], Y[train_size:]\"\"\"\n",
    "X = X.astype('float32')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(len(X_train), len(X_test))\n",
    "\n",
    "print(X[0].shape)\n",
    "print( X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5435 samples, validate on 1359 samples\n",
      "WARNING:tensorflow:From /home/arc/fdp5/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "5435/5435 [==============================] - 7s 1ms/sample - loss: 1.7081 - acc: 0.3043 - val_loss: 1.7382 - val_acc: 0.2884\n",
      "Epoch 2/100\n",
      "5435/5435 [==============================] - 5s 840us/sample - loss: 1.5145 - acc: 0.3875 - val_loss: 1.6854 - val_acc: 0.3208\n",
      "Epoch 3/100\n",
      "5435/5435 [==============================] - 6s 1ms/sample - loss: 1.4152 - acc: 0.4243 - val_loss: 1.5930 - val_acc: 0.3517\n",
      "Epoch 4/100\n",
      "5435/5435 [==============================] - 7s 1ms/sample - loss: 1.3549 - acc: 0.4517 - val_loss: 1.4682 - val_acc: 0.4032\n",
      "Epoch 5/100\n",
      "5435/5435 [==============================] - 5s 1ms/sample - loss: 1.2920 - acc: 0.4780 - val_loss: 1.3662 - val_acc: 0.4341\n",
      "Epoch 6/100\n",
      "5435/5435 [==============================] - 5s 950us/sample - loss: 1.2392 - acc: 0.5058 - val_loss: 1.3112 - val_acc: 0.4533\n",
      "Epoch 7/100\n",
      "5435/5435 [==============================] - 5s 855us/sample - loss: 1.1912 - acc: 0.5275 - val_loss: 1.2533 - val_acc: 0.4901\n",
      "Epoch 8/100\n",
      "5435/5435 [==============================] - 5s 875us/sample - loss: 1.1596 - acc: 0.5397 - val_loss: 1.2333 - val_acc: 0.4820\n",
      "Epoch 9/100\n",
      "5435/5435 [==============================] - 6s 1ms/sample - loss: 1.1105 - acc: 0.5597 - val_loss: 1.2273 - val_acc: 0.5063\n",
      "Epoch 10/100\n",
      "5435/5435 [==============================] - 5s 956us/sample - loss: 1.0805 - acc: 0.5822 - val_loss: 1.1869 - val_acc: 0.5239\n",
      "Epoch 11/100\n",
      "5435/5435 [==============================] - 5s 978us/sample - loss: 1.0376 - acc: 0.5978 - val_loss: 1.2310 - val_acc: 0.5151\n",
      "Epoch 12/100\n",
      "5435/5435 [==============================] - 5s 968us/sample - loss: 1.0027 - acc: 0.6083 - val_loss: 1.1812 - val_acc: 0.5438\n",
      "Epoch 13/100\n",
      "5435/5435 [==============================] - 5s 929us/sample - loss: 0.9644 - acc: 0.6267 - val_loss: 1.1655 - val_acc: 0.5460\n",
      "Epoch 14/100\n",
      "5435/5435 [==============================] - 5s 920us/sample - loss: 0.9329 - acc: 0.6396 - val_loss: 1.1177 - val_acc: 0.5622\n",
      "Epoch 15/100\n",
      "5435/5435 [==============================] - 5s 975us/sample - loss: 0.9166 - acc: 0.6500 - val_loss: 1.1369 - val_acc: 0.5556\n",
      "Epoch 16/100\n",
      "5435/5435 [==============================] - 5s 965us/sample - loss: 0.8761 - acc: 0.6657 - val_loss: 1.1248 - val_acc: 0.5710\n",
      "Epoch 17/100\n",
      "5435/5435 [==============================] - 6s 1ms/sample - loss: 0.8269 - acc: 0.6767 - val_loss: 1.1307 - val_acc: 0.5769\n",
      "Epoch 18/100\n",
      "5435/5435 [==============================] - 5s 972us/sample - loss: 0.8305 - acc: 0.6786 - val_loss: 1.1044 - val_acc: 0.5762\n",
      "Epoch 19/100\n",
      "5435/5435 [==============================] - 5s 946us/sample - loss: 0.8027 - acc: 0.6883 - val_loss: 1.1080 - val_acc: 0.5806\n",
      "Epoch 20/100\n",
      "5435/5435 [==============================] - 5s 878us/sample - loss: 0.7910 - acc: 0.7010 - val_loss: 1.1570 - val_acc: 0.5710\n",
      "Epoch 21/100\n",
      "5435/5435 [==============================] - 5s 943us/sample - loss: 0.7459 - acc: 0.7144 - val_loss: 1.0879 - val_acc: 0.6034\n",
      "Epoch 22/100\n",
      "5435/5435 [==============================] - 5s 886us/sample - loss: 0.7078 - acc: 0.7339 - val_loss: 1.0807 - val_acc: 0.5997\n",
      "Epoch 23/100\n",
      "5435/5435 [==============================] - 5s 875us/sample - loss: 0.6885 - acc: 0.7382 - val_loss: 1.0908 - val_acc: 0.6063\n",
      "Epoch 24/100\n",
      "5435/5435 [==============================] - 5s 862us/sample - loss: 0.6779 - acc: 0.7422 - val_loss: 1.1558 - val_acc: 0.6041\n",
      "Epoch 25/100\n",
      "5435/5435 [==============================] - 5s 845us/sample - loss: 0.6678 - acc: 0.7454 - val_loss: 1.1135 - val_acc: 0.6012\n",
      "Epoch 26/100\n",
      "5435/5435 [==============================] - 5s 900us/sample - loss: 0.6586 - acc: 0.7546 - val_loss: 1.1427 - val_acc: 0.6019\n",
      "Epoch 27/100\n",
      "5435/5435 [==============================] - 5s 887us/sample - loss: 0.6311 - acc: 0.7549 - val_loss: 1.1190 - val_acc: 0.6262\n",
      "Epoch 28/100\n",
      "5435/5435 [==============================] - 5s 855us/sample - loss: 0.6039 - acc: 0.7709 - val_loss: 1.1237 - val_acc: 0.6056\n",
      "Epoch 29/100\n",
      "5435/5435 [==============================] - 5s 861us/sample - loss: 0.5990 - acc: 0.7768 - val_loss: 1.1405 - val_acc: 0.6210\n",
      "Epoch 30/100\n",
      "5435/5435 [==============================] - 5s 844us/sample - loss: 0.5791 - acc: 0.7801 - val_loss: 1.1309 - val_acc: 0.6321\n",
      "Epoch 31/100\n",
      "5435/5435 [==============================] - 5s 857us/sample - loss: 0.5388 - acc: 0.8007 - val_loss: 1.1309 - val_acc: 0.6394\n",
      "Epoch 32/100\n",
      "5435/5435 [==============================] - 5s 865us/sample - loss: 0.5525 - acc: 0.7917 - val_loss: 1.2102 - val_acc: 0.6078\n",
      "Epoch 33/100\n",
      "5435/5435 [==============================] - 5s 889us/sample - loss: 0.5464 - acc: 0.7950 - val_loss: 1.1697 - val_acc: 0.6218\n",
      "Epoch 34/100\n",
      "5435/5435 [==============================] - 4s 813us/sample - loss: 0.5322 - acc: 0.7989 - val_loss: 1.1595 - val_acc: 0.6144\n",
      "Epoch 35/100\n",
      "5435/5435 [==============================] - 5s 888us/sample - loss: 0.5049 - acc: 0.8162 - val_loss: 1.1491 - val_acc: 0.6372\n",
      "Epoch 36/100\n",
      "5435/5435 [==============================] - 4s 822us/sample - loss: 0.4998 - acc: 0.8144 - val_loss: 1.1756 - val_acc: 0.6372\n",
      "Epoch 37/100\n",
      "5435/5435 [==============================] - 4s 782us/sample - loss: 0.4776 - acc: 0.8197 - val_loss: 1.1595 - val_acc: 0.6343\n",
      "Epoch 38/100\n",
      "5435/5435 [==============================] - 4s 794us/sample - loss: 0.4734 - acc: 0.8236 - val_loss: 1.2455 - val_acc: 0.6218\n",
      "Epoch 39/100\n",
      "5435/5435 [==============================] - 4s 803us/sample - loss: 0.4601 - acc: 0.8274 - val_loss: 1.2600 - val_acc: 0.6255\n",
      "Epoch 40/100\n",
      "5435/5435 [==============================] - 5s 852us/sample - loss: 0.4637 - acc: 0.8230 - val_loss: 1.2822 - val_acc: 0.6093\n",
      "Epoch 41/100\n",
      "5435/5435 [==============================] - 4s 828us/sample - loss: 0.4490 - acc: 0.8329 - val_loss: 1.3358 - val_acc: 0.6181\n",
      "Epoch 42/100\n",
      "5435/5435 [==============================] - 4s 816us/sample - loss: 0.4281 - acc: 0.8432 - val_loss: 1.2695 - val_acc: 0.6439\n",
      "Epoch 43/100\n",
      "5435/5435 [==============================] - 4s 791us/sample - loss: 0.4315 - acc: 0.8412 - val_loss: 1.2654 - val_acc: 0.6321\n",
      "Epoch 44/100\n",
      "5435/5435 [==============================] - 5s 903us/sample - loss: 0.4132 - acc: 0.8451 - val_loss: 1.2863 - val_acc: 0.6321\n",
      "Epoch 45/100\n",
      "5435/5435 [==============================] - 4s 822us/sample - loss: 0.4053 - acc: 0.8541 - val_loss: 1.3350 - val_acc: 0.6313\n",
      "Epoch 46/100\n",
      "5435/5435 [==============================] - 4s 808us/sample - loss: 0.3945 - acc: 0.8530 - val_loss: 1.3265 - val_acc: 0.6159\n",
      "Epoch 47/100\n",
      "5435/5435 [==============================] - 4s 802us/sample - loss: 0.4083 - acc: 0.8532 - val_loss: 1.3313 - val_acc: 0.6233\n",
      "Epoch 48/100\n",
      "5435/5435 [==============================] - 4s 827us/sample - loss: 0.4116 - acc: 0.8436 - val_loss: 1.3165 - val_acc: 0.6284\n",
      "Epoch 49/100\n",
      "5435/5435 [==============================] - 5s 863us/sample - loss: 0.3906 - acc: 0.8583 - val_loss: 1.2903 - val_acc: 0.6350\n",
      "Epoch 50/100\n",
      "5435/5435 [==============================] - 4s 827us/sample - loss: 0.3767 - acc: 0.8635 - val_loss: 1.3428 - val_acc: 0.6269\n",
      "Epoch 51/100\n",
      "5435/5435 [==============================] - 4s 803us/sample - loss: 0.3465 - acc: 0.8712 - val_loss: 1.3715 - val_acc: 0.6365\n",
      "Epoch 52/100\n",
      "5435/5435 [==============================] - 4s 773us/sample - loss: 0.3563 - acc: 0.8677 - val_loss: 1.3510 - val_acc: 0.6350\n",
      "Epoch 53/100\n",
      "5435/5435 [==============================] - 4s 766us/sample - loss: 0.3522 - acc: 0.8697 - val_loss: 1.3370 - val_acc: 0.6534\n",
      "Epoch 54/100\n",
      "5435/5435 [==============================] - 4s 818us/sample - loss: 0.3583 - acc: 0.8672 - val_loss: 1.3720 - val_acc: 0.6358\n",
      "Epoch 55/100\n",
      "5435/5435 [==============================] - 4s 792us/sample - loss: 0.3493 - acc: 0.8753 - val_loss: 1.3784 - val_acc: 0.6365\n",
      "Epoch 56/100\n",
      "5435/5435 [==============================] - 4s 812us/sample - loss: 0.3588 - acc: 0.8741 - val_loss: 1.3320 - val_acc: 0.6497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "5435/5435 [==============================] - 4s 825us/sample - loss: 0.3390 - acc: 0.8734 - val_loss: 1.3633 - val_acc: 0.6556\n",
      "Epoch 58/100\n",
      "5435/5435 [==============================] - 4s 816us/sample - loss: 0.3346 - acc: 0.8804 - val_loss: 1.4171 - val_acc: 0.6306\n",
      "Epoch 59/100\n",
      "5435/5435 [==============================] - 4s 807us/sample - loss: 0.3431 - acc: 0.8734 - val_loss: 1.3678 - val_acc: 0.6453\n",
      "Epoch 60/100\n",
      "5435/5435 [==============================] - 4s 807us/sample - loss: 0.3150 - acc: 0.8837 - val_loss: 1.4196 - val_acc: 0.6409\n",
      "Epoch 61/100\n",
      "5435/5435 [==============================] - 4s 789us/sample - loss: 0.3084 - acc: 0.8837 - val_loss: 1.4541 - val_acc: 0.6453\n",
      "Epoch 62/100\n",
      "5435/5435 [==============================] - 5s 830us/sample - loss: 0.3419 - acc: 0.8773 - val_loss: 1.4294 - val_acc: 0.6255\n",
      "Epoch 63/100\n",
      "5435/5435 [==============================] - 5s 831us/sample - loss: 0.3180 - acc: 0.8867 - val_loss: 1.4026 - val_acc: 0.6527\n",
      "Epoch 64/100\n",
      "5435/5435 [==============================] - 4s 824us/sample - loss: 0.3190 - acc: 0.8826 - val_loss: 1.4085 - val_acc: 0.6439\n",
      "Epoch 65/100\n",
      "5435/5435 [==============================] - 4s 804us/sample - loss: 0.3079 - acc: 0.8845 - val_loss: 1.4817 - val_acc: 0.6394\n",
      "Epoch 66/100\n",
      "5435/5435 [==============================] - 4s 823us/sample - loss: 0.2949 - acc: 0.8924 - val_loss: 1.4339 - val_acc: 0.6519\n",
      "Epoch 67/100\n",
      "5435/5435 [==============================] - 4s 828us/sample - loss: 0.2817 - acc: 0.8977 - val_loss: 1.5161 - val_acc: 0.6394\n",
      "Epoch 68/100\n",
      "5435/5435 [==============================] - 5s 854us/sample - loss: 0.2823 - acc: 0.8977 - val_loss: 1.5098 - val_acc: 0.6468\n",
      "Epoch 69/100\n",
      "5435/5435 [==============================] - 4s 823us/sample - loss: 0.3046 - acc: 0.8870 - val_loss: 1.4534 - val_acc: 0.6446\n",
      "Epoch 70/100\n",
      "5435/5435 [==============================] - 5s 867us/sample - loss: 0.2758 - acc: 0.9019 - val_loss: 1.4239 - val_acc: 0.6497\n",
      "Epoch 71/100\n",
      "5435/5435 [==============================] - 4s 820us/sample - loss: 0.2599 - acc: 0.9080 - val_loss: 1.5205 - val_acc: 0.6446\n",
      "Epoch 72/100\n",
      "5435/5435 [==============================] - 4s 800us/sample - loss: 0.2766 - acc: 0.8995 - val_loss: 1.5562 - val_acc: 0.6365\n",
      "Epoch 73/100\n",
      "5435/5435 [==============================] - 5s 835us/sample - loss: 0.2740 - acc: 0.9008 - val_loss: 1.4814 - val_acc: 0.6461\n",
      "Epoch 74/100\n",
      "5435/5435 [==============================] - 4s 821us/sample - loss: 0.2568 - acc: 0.9115 - val_loss: 1.5596 - val_acc: 0.6490\n",
      "Epoch 75/100\n",
      "5435/5435 [==============================] - 4s 800us/sample - loss: 0.2582 - acc: 0.9102 - val_loss: 1.5245 - val_acc: 0.6512\n",
      "Epoch 76/100\n",
      "5435/5435 [==============================] - 4s 784us/sample - loss: 0.2756 - acc: 0.9012 - val_loss: 1.5250 - val_acc: 0.6365\n",
      "Epoch 77/100\n",
      "5435/5435 [==============================] - 4s 812us/sample - loss: 0.2607 - acc: 0.9034 - val_loss: 1.6080 - val_acc: 0.6431\n",
      "Epoch 78/100\n",
      "5435/5435 [==============================] - 4s 787us/sample - loss: 0.2414 - acc: 0.9100 - val_loss: 1.5755 - val_acc: 0.6416\n",
      "Epoch 79/100\n",
      "5435/5435 [==============================] - 4s 795us/sample - loss: 0.2497 - acc: 0.9095 - val_loss: 1.4998 - val_acc: 0.6431\n",
      "Epoch 80/100\n",
      "5435/5435 [==============================] - 4s 825us/sample - loss: 0.2535 - acc: 0.9060 - val_loss: 1.5153 - val_acc: 0.6571\n",
      "Epoch 81/100\n",
      "5435/5435 [==============================] - 5s 854us/sample - loss: 0.2422 - acc: 0.9139 - val_loss: 1.4971 - val_acc: 0.6542\n",
      "Epoch 82/100\n",
      "5435/5435 [==============================] - 4s 824us/sample - loss: 0.2388 - acc: 0.9157 - val_loss: 1.5549 - val_acc: 0.6431\n",
      "Epoch 83/100\n",
      "5435/5435 [==============================] - 4s 800us/sample - loss: 0.2470 - acc: 0.9097 - val_loss: 1.5317 - val_acc: 0.6519\n",
      "Epoch 84/100\n",
      "5435/5435 [==============================] - 5s 858us/sample - loss: 0.2325 - acc: 0.9172 - val_loss: 1.5964 - val_acc: 0.6505\n",
      "Epoch 85/100\n",
      "5435/5435 [==============================] - 5s 878us/sample - loss: 0.2130 - acc: 0.9270 - val_loss: 1.7169 - val_acc: 0.6321\n",
      "Epoch 86/100\n",
      "5435/5435 [==============================] - 4s 812us/sample - loss: 0.2318 - acc: 0.9165 - val_loss: 1.5774 - val_acc: 0.6542\n",
      "Epoch 87/100\n",
      "5435/5435 [==============================] - 4s 796us/sample - loss: 0.2159 - acc: 0.9209 - val_loss: 1.6423 - val_acc: 0.6372\n",
      "Epoch 88/100\n",
      "5435/5435 [==============================] - 4s 817us/sample - loss: 0.2323 - acc: 0.9194 - val_loss: 1.6188 - val_acc: 0.6490\n",
      "Epoch 89/100\n",
      "5435/5435 [==============================] - 4s 822us/sample - loss: 0.2238 - acc: 0.9233 - val_loss: 1.6005 - val_acc: 0.6416\n",
      "Epoch 90/100\n",
      "5435/5435 [==============================] - 4s 806us/sample - loss: 0.2026 - acc: 0.9271 - val_loss: 1.5978 - val_acc: 0.6505\n",
      "Epoch 91/100\n",
      "5435/5435 [==============================] - 5s 851us/sample - loss: 0.2450 - acc: 0.9126 - val_loss: 1.6457 - val_acc: 0.6439\n",
      "Epoch 92/100\n",
      "5435/5435 [==============================] - 5s 842us/sample - loss: 0.2251 - acc: 0.9157 - val_loss: 1.5841 - val_acc: 0.6394\n",
      "Epoch 93/100\n",
      "5435/5435 [==============================] - 5s 850us/sample - loss: 0.1910 - acc: 0.9332 - val_loss: 1.6180 - val_acc: 0.6409\n",
      "Epoch 94/100\n",
      "5435/5435 [==============================] - 5s 829us/sample - loss: 0.2066 - acc: 0.9297 - val_loss: 1.6174 - val_acc: 0.6416\n",
      "Epoch 95/100\n",
      "5435/5435 [==============================] - 4s 815us/sample - loss: 0.2206 - acc: 0.9225 - val_loss: 1.6126 - val_acc: 0.6519\n",
      "Epoch 96/100\n",
      "5435/5435 [==============================] - 4s 788us/sample - loss: 0.2068 - acc: 0.9260 - val_loss: 1.6211 - val_acc: 0.6497\n",
      "Epoch 97/100\n",
      "5435/5435 [==============================] - 4s 795us/sample - loss: 0.2124 - acc: 0.9255 - val_loss: 1.6484 - val_acc: 0.6689\n",
      "Epoch 98/100\n",
      "5435/5435 [==============================] - 4s 808us/sample - loss: 0.2154 - acc: 0.9247 - val_loss: 1.6497 - val_acc: 0.6416\n",
      "Epoch 99/100\n",
      "5435/5435 [==============================] - 4s 789us/sample - loss: 0.2300 - acc: 0.9201 - val_loss: 1.6699 - val_acc: 0.6468\n",
      "Epoch 100/100\n",
      "5435/5435 [==============================] - 4s 802us/sample - loss: 0.2075 - acc: 0.9257 - val_loss: 1.5311 - val_acc: 0.6564\n"
     ]
    }
   ],
   "source": [
    "vm.model.train(X_train, Y_train, batch_size=64, epoch=100, validation_data=(X_test, Y_test), callbacks=[logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3a0edcfc50>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[174  11   4   4  11  42]\n",
      " [  7 135  15  17  19  25]\n",
      " [  8  16 175  14  11  12]\n",
      " [  3  13  21 133  30  11]\n",
      " [  6  19  16  22 134  15]\n",
      " [ 28  20   9  22  16 141]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.77      0.71      0.74       246\n",
      "       happy       0.63      0.62      0.62       218\n",
      "       angry       0.73      0.74      0.74       236\n",
      "     fearful       0.63      0.63      0.63       211\n",
      "   surprised       0.61      0.63      0.62       212\n",
      "         sad       0.57      0.60      0.59       236\n",
      "\n",
      "    accuracy                           0.66      1359\n",
      "   macro avg       0.66      0.65      0.66      1359\n",
      "weighted avg       0.66      0.66      0.66      1359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(list(range(0, len(logger.training))), list(map(lambda x:x[1], logger.training)), label=\"training data\")\n",
    "plt.plot(list(range(0, len(logger.testing))), list(map(lambda x:x[1], logger.testing)), label=\"testing data\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "print_metrics(X_test, Y_test, emotion_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this graph we can see that the model largely overfit around the 20st epoch\n",
    "We can also see that the testing data's accuracy continues to grow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we save the model so we don't have to retrain it each time\n",
    "vm.model.save(\"emotion_lstm-1s.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Here we load the model to check if nothing went wrong\n",
    "vm.model.load(\"emotion_lstm-1s.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing calm\n",
      "Doing happy\n",
      "Doing angry\n",
      "Doing fearful\n",
      "Doing surprised\n",
      "Doing sad\n"
     ]
    }
   ],
   "source": [
    "# Now we load the new dataset (savee)\n",
    "\n",
    "# First we change the folder path\n",
    "folder_path += \"/savee\"\n",
    "\n",
    "# Now we load the data\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in emotion_list}\n",
    "X_savee, Y_savee = preprare_wav(data, vm, sample_duration, step)\n",
    "X_savee = X_savee.astype('float32')\n",
    "X_savee_train, X_savee_test, Y_savee_train, Y_savee_test = train_test_split(X_savee, Y_savee, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2582/2582 [==============================] - 1s 345us/sample - loss: 6.7283 - acc: 0.2029\n",
      "[[ 88  67 248   4 248  30]\n",
      " [ 28  95  72  18 128  27]\n",
      " [ 20  52 121   8 146  11]\n",
      " [ 35  37  86  18 144  38]\n",
      " [ 31  59  53  21 179  20]\n",
      " [ 74  63 137   5 148  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.32      0.13      0.18       685\n",
      "       happy       0.25      0.26      0.26       368\n",
      "       angry       0.17      0.34      0.23       358\n",
      "     fearful       0.24      0.05      0.08       358\n",
      "   surprised       0.18      0.49      0.26       363\n",
      "         sad       0.15      0.05      0.08       450\n",
      "\n",
      "    accuracy                           0.20      2582\n",
      "   macro avg       0.22      0.22      0.18      2582\n",
      "weighted avg       0.23      0.20      0.18      2582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vm.model._model.evaluate(X_savee, Y_savee)\n",
    "print_metrics(X_savee, Y_savee, emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_noise_3\n",
      "batch_normalization_4\n",
      "lstm_2\n",
      "activation_4\n",
      "flatten_2\n",
      "batch_normalization_5\n",
      "gaussian_noise_4\n"
     ]
    }
   ],
   "source": [
    "# Now we freeze every layer used for extracting features from data\n",
    "for layer in vm.model._model.layers[:-3]:\n",
    "    print(layer.name)\n",
    "    layer.trainable = False\n",
    "vm.model._model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2065 samples, validate on 517 samples\n",
      "Epoch 1/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 3.2496 - acc: 0.2581 - val_loss: 2.6290 - val_acc: 0.2766\n",
      "Epoch 2/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.8056 - acc: 0.3138 - val_loss: 2.1951 - val_acc: 0.3095\n",
      "Epoch 3/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.6440 - acc: 0.3375 - val_loss: 1.9793 - val_acc: 0.3172\n",
      "Epoch 4/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5992 - acc: 0.3462 - val_loss: 1.9457 - val_acc: 0.3230\n",
      "Epoch 5/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5528 - acc: 0.3724 - val_loss: 1.9410 - val_acc: 0.3037\n",
      "Epoch 6/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5472 - acc: 0.3714 - val_loss: 1.8936 - val_acc: 0.3133\n",
      "Epoch 7/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5481 - acc: 0.3763 - val_loss: 1.9137 - val_acc: 0.3250\n",
      "Epoch 8/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5289 - acc: 0.3777 - val_loss: 1.8769 - val_acc: 0.3327\n",
      "Epoch 9/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5293 - acc: 0.3637 - val_loss: 1.9531 - val_acc: 0.3191\n",
      "Epoch 10/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5386 - acc: 0.3850 - val_loss: 2.0030 - val_acc: 0.3075\n",
      "Epoch 11/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5291 - acc: 0.3782 - val_loss: 1.9430 - val_acc: 0.3308\n",
      "Epoch 12/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5304 - acc: 0.3763 - val_loss: 1.8956 - val_acc: 0.3133\n",
      "Epoch 13/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5237 - acc: 0.3685 - val_loss: 1.8977 - val_acc: 0.3211\n",
      "Epoch 14/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5174 - acc: 0.3893 - val_loss: 1.8376 - val_acc: 0.3153\n",
      "Epoch 15/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5284 - acc: 0.3792 - val_loss: 1.9674 - val_acc: 0.3172\n",
      "Epoch 16/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5264 - acc: 0.3777 - val_loss: 1.9256 - val_acc: 0.3191\n",
      "Epoch 17/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5289 - acc: 0.3705 - val_loss: 1.9210 - val_acc: 0.3172\n",
      "Epoch 18/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5279 - acc: 0.3734 - val_loss: 1.9625 - val_acc: 0.3230\n",
      "Epoch 19/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5288 - acc: 0.3690 - val_loss: 1.8747 - val_acc: 0.3172\n",
      "Epoch 20/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5312 - acc: 0.3738 - val_loss: 1.9060 - val_acc: 0.3250\n",
      "Epoch 21/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5067 - acc: 0.3801 - val_loss: 1.9051 - val_acc: 0.3269\n",
      "Epoch 22/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5311 - acc: 0.3608 - val_loss: 1.8676 - val_acc: 0.3250\n",
      "Epoch 23/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5188 - acc: 0.3801 - val_loss: 1.9145 - val_acc: 0.3191\n",
      "Epoch 24/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5193 - acc: 0.3777 - val_loss: 1.8590 - val_acc: 0.3288\n",
      "Epoch 25/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5376 - acc: 0.3714 - val_loss: 1.8750 - val_acc: 0.3230\n",
      "Epoch 26/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5235 - acc: 0.3763 - val_loss: 1.8592 - val_acc: 0.3366\n",
      "Epoch 27/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5248 - acc: 0.3729 - val_loss: 1.9024 - val_acc: 0.3308\n",
      "Epoch 28/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5261 - acc: 0.3782 - val_loss: 1.8917 - val_acc: 0.3172\n",
      "Epoch 29/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5222 - acc: 0.3763 - val_loss: 1.9462 - val_acc: 0.3153\n",
      "Epoch 30/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5210 - acc: 0.3903 - val_loss: 1.8813 - val_acc: 0.3153\n",
      "Epoch 31/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5290 - acc: 0.3729 - val_loss: 1.9123 - val_acc: 0.3191\n",
      "Epoch 32/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5292 - acc: 0.3748 - val_loss: 1.9195 - val_acc: 0.3172\n",
      "Epoch 33/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5051 - acc: 0.3913 - val_loss: 1.8867 - val_acc: 0.3288\n",
      "Epoch 34/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5252 - acc: 0.3729 - val_loss: 1.8492 - val_acc: 0.3346\n",
      "Epoch 35/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5044 - acc: 0.3787 - val_loss: 1.9858 - val_acc: 0.3211\n",
      "Epoch 36/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5270 - acc: 0.3651 - val_loss: 1.9387 - val_acc: 0.3211\n",
      "Epoch 37/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5311 - acc: 0.3680 - val_loss: 1.9084 - val_acc: 0.3288\n",
      "Epoch 38/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5227 - acc: 0.3923 - val_loss: 1.8820 - val_acc: 0.3288\n",
      "Epoch 39/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5091 - acc: 0.3782 - val_loss: 1.9569 - val_acc: 0.3230\n",
      "Epoch 40/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5111 - acc: 0.3971 - val_loss: 1.9520 - val_acc: 0.3211\n",
      "Epoch 41/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5160 - acc: 0.3782 - val_loss: 1.9611 - val_acc: 0.3075\n",
      "Epoch 42/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5205 - acc: 0.3826 - val_loss: 1.9170 - val_acc: 0.3153\n",
      "Epoch 43/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5264 - acc: 0.3700 - val_loss: 1.8726 - val_acc: 0.3191\n",
      "Epoch 44/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5488 - acc: 0.3642 - val_loss: 1.8601 - val_acc: 0.3308\n",
      "Epoch 45/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5277 - acc: 0.3806 - val_loss: 1.8992 - val_acc: 0.3269\n",
      "Epoch 46/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5062 - acc: 0.3831 - val_loss: 1.8684 - val_acc: 0.3424\n",
      "Epoch 47/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5085 - acc: 0.3816 - val_loss: 1.8675 - val_acc: 0.3385\n",
      "Epoch 48/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5260 - acc: 0.3593 - val_loss: 1.8789 - val_acc: 0.3211\n",
      "Epoch 49/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5085 - acc: 0.3826 - val_loss: 1.8602 - val_acc: 0.3230\n",
      "Epoch 50/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5125 - acc: 0.3864 - val_loss: 1.9300 - val_acc: 0.3250\n",
      "Epoch 51/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5182 - acc: 0.3850 - val_loss: 1.9072 - val_acc: 0.3230\n",
      "Epoch 52/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5279 - acc: 0.3893 - val_loss: 1.8880 - val_acc: 0.3269\n",
      "Epoch 53/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5201 - acc: 0.3927 - val_loss: 1.8852 - val_acc: 0.3172\n",
      "Epoch 54/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5306 - acc: 0.3826 - val_loss: 1.8992 - val_acc: 0.3269\n",
      "Epoch 55/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5264 - acc: 0.3753 - val_loss: 1.8858 - val_acc: 0.3191\n",
      "Epoch 56/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5198 - acc: 0.3903 - val_loss: 1.8588 - val_acc: 0.3250\n",
      "Epoch 57/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5361 - acc: 0.3622 - val_loss: 1.8667 - val_acc: 0.3211\n",
      "Epoch 58/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5152 - acc: 0.3782 - val_loss: 1.8728 - val_acc: 0.3211\n",
      "Epoch 59/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5139 - acc: 0.3874 - val_loss: 1.8700 - val_acc: 0.3366\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5155 - acc: 0.3826 - val_loss: 1.8385 - val_acc: 0.3250\n",
      "Epoch 61/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5199 - acc: 0.3864 - val_loss: 1.8736 - val_acc: 0.3230\n",
      "Epoch 62/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5173 - acc: 0.3869 - val_loss: 1.9177 - val_acc: 0.3230\n",
      "Epoch 63/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5148 - acc: 0.3845 - val_loss: 1.8848 - val_acc: 0.3288\n",
      "Epoch 64/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5096 - acc: 0.3821 - val_loss: 1.8896 - val_acc: 0.3308\n",
      "Epoch 65/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5141 - acc: 0.3797 - val_loss: 1.9048 - val_acc: 0.3211\n",
      "Epoch 66/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5087 - acc: 0.3801 - val_loss: 1.8861 - val_acc: 0.3230\n",
      "Epoch 67/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5104 - acc: 0.3908 - val_loss: 1.8888 - val_acc: 0.3211\n",
      "Epoch 68/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5310 - acc: 0.3763 - val_loss: 1.8748 - val_acc: 0.3269\n",
      "Epoch 69/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5169 - acc: 0.3898 - val_loss: 1.8933 - val_acc: 0.3172\n",
      "Epoch 70/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5160 - acc: 0.3797 - val_loss: 1.8898 - val_acc: 0.3250\n",
      "Epoch 71/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5239 - acc: 0.3792 - val_loss: 1.8715 - val_acc: 0.3288\n",
      "Epoch 72/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5048 - acc: 0.3772 - val_loss: 1.9019 - val_acc: 0.3172\n",
      "Epoch 73/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5144 - acc: 0.3816 - val_loss: 1.8487 - val_acc: 0.3308\n",
      "Epoch 74/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5182 - acc: 0.3661 - val_loss: 1.8531 - val_acc: 0.3191\n",
      "Epoch 75/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5231 - acc: 0.3700 - val_loss: 1.8639 - val_acc: 0.3269\n",
      "Epoch 76/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5065 - acc: 0.3961 - val_loss: 1.8502 - val_acc: 0.3288\n",
      "Epoch 77/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5195 - acc: 0.3952 - val_loss: 1.8806 - val_acc: 0.3172\n",
      "Epoch 78/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5267 - acc: 0.3729 - val_loss: 1.8684 - val_acc: 0.3250\n",
      "Epoch 79/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5177 - acc: 0.3874 - val_loss: 1.8771 - val_acc: 0.3250\n",
      "Epoch 80/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5024 - acc: 0.3850 - val_loss: 1.9333 - val_acc: 0.3288\n",
      "Epoch 81/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5192 - acc: 0.3826 - val_loss: 1.8480 - val_acc: 0.3308\n",
      "Epoch 82/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5189 - acc: 0.3821 - val_loss: 1.8787 - val_acc: 0.3250\n",
      "Epoch 83/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5237 - acc: 0.3787 - val_loss: 1.8610 - val_acc: 0.3308\n",
      "Epoch 84/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5190 - acc: 0.3831 - val_loss: 1.8980 - val_acc: 0.3230\n",
      "Epoch 85/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5281 - acc: 0.3898 - val_loss: 1.8975 - val_acc: 0.3250\n",
      "Epoch 86/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5235 - acc: 0.3777 - val_loss: 1.9203 - val_acc: 0.3250\n",
      "Epoch 87/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5238 - acc: 0.3743 - val_loss: 1.8720 - val_acc: 0.3211\n",
      "Epoch 88/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5056 - acc: 0.3981 - val_loss: 1.8513 - val_acc: 0.3211\n",
      "Epoch 89/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.4896 - acc: 0.4024 - val_loss: 1.8845 - val_acc: 0.3269\n",
      "Epoch 90/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5265 - acc: 0.3666 - val_loss: 1.9240 - val_acc: 0.3230\n",
      "Epoch 91/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.4994 - acc: 0.3821 - val_loss: 1.9466 - val_acc: 0.3211\n",
      "Epoch 92/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5282 - acc: 0.3671 - val_loss: 1.8924 - val_acc: 0.3288\n",
      "Epoch 93/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5110 - acc: 0.3826 - val_loss: 1.8940 - val_acc: 0.3250\n",
      "Epoch 94/100\n",
      "2065/2065 [==============================] - 3s 2ms/sample - loss: 1.5216 - acc: 0.3666 - val_loss: 1.9229 - val_acc: 0.3250\n",
      "Epoch 95/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5026 - acc: 0.3850 - val_loss: 1.9441 - val_acc: 0.3230\n",
      "Epoch 96/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5139 - acc: 0.3758 - val_loss: 1.9402 - val_acc: 0.3250\n",
      "Epoch 97/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5248 - acc: 0.3753 - val_loss: 1.9220 - val_acc: 0.3327\n",
      "Epoch 98/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5221 - acc: 0.3840 - val_loss: 1.9848 - val_acc: 0.3250\n",
      "Epoch 99/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5224 - acc: 0.3656 - val_loss: 1.9173 - val_acc: 0.3211\n",
      "Epoch 100/100\n",
      "2065/2065 [==============================] - 4s 2ms/sample - loss: 1.5144 - acc: 0.3714 - val_loss: 1.9473 - val_acc: 0.3211\n"
     ]
    }
   ],
   "source": [
    "# And we train the two last layers\n",
    "# This is classic fine tuning\n",
    "vm.model.train(X_savee_train, Y_savee_train, batch_size=10, validation_data=(X_savee_test, Y_savee_test), epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[631   8  14   1  14  17]\n",
      " [255  36  34   1  15  27]\n",
      " [240  17  66   1  20  14]\n",
      " [225  15  22   5  53  38]\n",
      " [234  18  28   2  62  19]\n",
      " [379   2  19   2  14  34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.32      0.92      0.48       685\n",
      "       happy       0.38      0.10      0.16       368\n",
      "       angry       0.36      0.18      0.24       358\n",
      "     fearful       0.42      0.01      0.03       358\n",
      "   surprised       0.35      0.17      0.23       363\n",
      "         sad       0.23      0.08      0.11       450\n",
      "\n",
      "    accuracy                           0.32      2582\n",
      "   macro avg       0.34      0.24      0.21      2582\n",
      "weighted avg       0.34      0.32      0.24      2582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_metrics(X_savee, Y_savee, emotion_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
