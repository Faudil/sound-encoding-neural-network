{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import phase if every import is here it is to allow you to run this cell and know if you have any issue and not after a few hours of training\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, Activation, Flatten, MaxPooling1D, BatchNormalization, LSTM, GaussianNoise\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "from src.VoiceModule import VoiceModule\n",
    "from src.classifiers.KerasClassifier import KerasClassifier\n",
    "from prepare_data_utils import load_wav, preprare_wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bdes.zip\n",
      "fearful\n",
      "savee\n",
      "calm\n",
      "happy\n",
      "surprised\n",
      "angry\n",
      "sad\n",
      "keywords\n"
     ]
    }
   ],
   "source": [
    "# print environment\n",
    "folder_path = \"../../data\"\n",
    "for l in os.listdir(folder_path):\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data method\n",
    "\n",
    "def mfcc(buffer, samplerate, dim):\n",
    "    a = librosa.feature.mfcc(y=buffer, sr=samplerate, n_mfcc=dim)\n",
    "    a = np.transpose(a)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback to later draw some graphs\n",
    "\n",
    "class PerformanceLogger(Callback):\n",
    "    def __init__(self):\n",
    "        # List of tuple (loss, accuracy)\n",
    "        self.training = []\n",
    "        self.testing = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.training.append((logs[\"loss\"], logs[\"acc\"]))\n",
    "        self.testing.append((logs[\"val_loss\"], logs[\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prints metrics about a model\n",
    "def print_metrics(X, Y, label_name_list):\n",
    "    Y_pred = vm.model._model.predict(X)\n",
    "    Y_pred = np.argmax(Y_pred, axis=1)\n",
    "    Y_max = np.argmax(Y, axis=1)\n",
    "    print(confusion_matrix(Y_max, Y_pred))\n",
    "    print(classification_report(Y_max, Y_pred, target_names=label_name_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class\n",
    "class EmotionClassifierLstm(KerasClassifier):\n",
    "    def __init__(self, file_path=None):\n",
    "        super().__init__(file_path)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.expand_dims(np.array([x]), axis=2)\n",
    "        return self._model.predict(x)\n",
    "\n",
    "    def build(self):\n",
    "        model = Sequential()\n",
    "        # This first layer add noises to the input data and serve as a data augmentation technique\n",
    "        # Used to prevent overfitting of the LSTM layer and try to extract more significant feature\n",
    "        model.add(GaussianNoise(0.4))\n",
    "        # This layer normalise the data to speed up the training and prevent the gradient of the LSTM to explode\n",
    "        # and reach exponential weight value\n",
    "        model.add(BatchNormalization())\n",
    "        # This is THE feature extraction layer\n",
    "        model.add(LSTM(128, input_shape=(70, 13)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(BatchNormalization())\n",
    "        # This is the second part of the network, this one will be fine tuned later\n",
    "        model.add(GaussianNoise(0.2))\n",
    "\n",
    "        # The two last layers will be fine-tuned at the end of this notebook\n",
    "        model.add(Dense(64))\n",
    "        model.add(Dense(6))\n",
    "        model.add(Activation('softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self._model = model\n",
    "        \n",
    "    def train(self, X, Y, batch_size=32, epoch=720, validation_data=None, callbacks=[]):\n",
    "        self._model.fit(X, Y, batch_size=batch_size, epochs=epoch, validation_data=validation_data, callbacks=callbacks)\n",
    "\n",
    "    def transform(self, x, samplerate):\n",
    "        to_process = mfcc(x, samplerate, 13)\n",
    "        to_process = pad_sequences([to_process], maxlen=70, padding='post')[0]\n",
    "        return to_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/arc/fdp5/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#Instanciate model\n",
    "emotion_list = [\"calm\", \"happy\", \"angry\", \"fearful\", \"surprised\", \"sad\"]\n",
    "dimension_mfcc = 13\n",
    "samplerate = 16000\n",
    "nb_break=None\n",
    "sample_duration=2\n",
    "step=2\n",
    "\n",
    "logger = PerformanceLogger()\n",
    "\n",
    "cls = EmotionClassifierLstm()\n",
    "vm = VoiceModule(\"emotion\", emotion_list, cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing calm\n",
      "Doing happy\n",
      "Doing angry\n",
      "Doing fearful\n",
      "Doing surprised\n",
      "Doing sad\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in emotion_list}\n",
    "X, Y = preprare_wav(data, vm, sample_duration, step)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_file = f\"x_{'_'.join(emotion_list)}-{vm._name}.npy\"\n",
    "Y_file = f\"y_{'_'.join(emotion_list)}-{vm._name}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the prepared input data \n",
    "np.save(X_file, X)\n",
    "np.save(Y_file, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for training\n",
    "X, Y = np.load(X_file), np.load(Y_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063 266\n",
      "(70, 13)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "\"\"\"train_size = 80 * len(X) // 100\n",
    "test_size = 20 * len(X) // 100\n",
    "#X = np.expand_dims(X, axis=3)\n",
    "X_train, X_test, = X[:train_size], X[train_size:]\n",
    "Y_train, Y_test = Y[:train_size], Y[train_size:]\"\"\"\n",
    "X = X.astype('float32')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(len(X_train), len(X_test))\n",
    "\n",
    "print(X[0].shape)\n",
    "print( X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1063 samples, validate on 266 samples\n",
      "WARNING:tensorflow:From /home/arc/fdp5/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "1063/1063 [==============================] - 5s 4ms/sample - loss: 1.6570 - acc: 0.3387 - val_loss: 1.7559 - val_acc: 0.2669\n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 1.3611 - acc: 0.4779 - val_loss: 1.7439 - val_acc: 0.2632\n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 1.2665 - acc: 0.5005 - val_loss: 1.7323 - val_acc: 0.2218\n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 1.1640 - acc: 0.5484 - val_loss: 1.7173 - val_acc: 0.2632\n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 1.1013 - acc: 0.5682 - val_loss: 1.7107 - val_acc: 0.2293\n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 1.0214 - acc: 0.6030 - val_loss: 1.6812 - val_acc: 0.2744\n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.9795 - acc: 0.6256 - val_loss: 1.6385 - val_acc: 0.3045\n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.8818 - acc: 0.6548 - val_loss: 1.5765 - val_acc: 0.3534\n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.8503 - acc: 0.6689 - val_loss: 1.5252 - val_acc: 0.4098\n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.7868 - acc: 0.7027 - val_loss: 1.4878 - val_acc: 0.3947\n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.7019 - acc: 0.7319 - val_loss: 1.4503 - val_acc: 0.4398\n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.6566 - acc: 0.7592 - val_loss: 1.3924 - val_acc: 0.4436\n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.5570 - acc: 0.7996 - val_loss: 1.3148 - val_acc: 0.5226\n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.4988 - acc: 0.8166 - val_loss: 1.2650 - val_acc: 0.5865\n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.4328 - acc: 0.8410 - val_loss: 1.2551 - val_acc: 0.5338\n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.4366 - acc: 0.8401 - val_loss: 1.1595 - val_acc: 0.5977\n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.3794 - acc: 0.8749 - val_loss: 1.1280 - val_acc: 0.5902\n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.3455 - acc: 0.8739 - val_loss: 1.0720 - val_acc: 0.6090\n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.3060 - acc: 0.8871 - val_loss: 1.1061 - val_acc: 0.6053\n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 3s 2ms/sample - loss: 0.2698 - acc: 0.9078 - val_loss: 1.0788 - val_acc: 0.6090\n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.2513 - acc: 0.9106 - val_loss: 1.1812 - val_acc: 0.6165\n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.2505 - acc: 0.9163 - val_loss: 1.1145 - val_acc: 0.6090\n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.2150 - acc: 0.9341 - val_loss: 1.1682 - val_acc: 0.6203\n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1969 - acc: 0.9379 - val_loss: 1.2533 - val_acc: 0.6429\n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1326 - acc: 0.9558 - val_loss: 1.2019 - val_acc: 0.6579\n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1243 - acc: 0.9614 - val_loss: 1.2842 - val_acc: 0.6278\n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1453 - acc: 0.9398 - val_loss: 1.1847 - val_acc: 0.6654\n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1294 - acc: 0.9614 - val_loss: 1.2931 - val_acc: 0.6617\n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1358 - acc: 0.9492 - val_loss: 1.6453 - val_acc: 0.6203\n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1234 - acc: 0.9577 - val_loss: 1.4246 - val_acc: 0.6617\n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1284 - acc: 0.9605 - val_loss: 1.6274 - val_acc: 0.6203\n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0906 - acc: 0.9737 - val_loss: 1.5094 - val_acc: 0.6429\n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1090 - acc: 0.9699 - val_loss: 1.5263 - val_acc: 0.6729\n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0598 - acc: 0.9821 - val_loss: 1.6074 - val_acc: 0.6466\n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0777 - acc: 0.9784 - val_loss: 1.6075 - val_acc: 0.6729\n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 3s 2ms/sample - loss: 0.0393 - acc: 0.9897 - val_loss: 1.5002 - val_acc: 0.6955\n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0527 - acc: 0.9821 - val_loss: 1.5812 - val_acc: 0.6917\n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0870 - acc: 0.9718 - val_loss: 2.0913 - val_acc: 0.6316\n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1769 - acc: 0.9426 - val_loss: 1.6522 - val_acc: 0.6090\n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1026 - acc: 0.9671 - val_loss: 1.7702 - val_acc: 0.6429\n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0783 - acc: 0.9746 - val_loss: 1.5414 - val_acc: 0.6842\n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0646 - acc: 0.9831 - val_loss: 1.6455 - val_acc: 0.6805\n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0348 - acc: 0.9906 - val_loss: 1.6344 - val_acc: 0.6805\n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0284 - acc: 0.9925 - val_loss: 1.8585 - val_acc: 0.6504\n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0651 - acc: 0.9840 - val_loss: 1.7753 - val_acc: 0.6729\n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0427 - acc: 0.9887 - val_loss: 1.8126 - val_acc: 0.6504\n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0415 - acc: 0.9859 - val_loss: 2.0431 - val_acc: 0.6391\n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0542 - acc: 0.9831 - val_loss: 1.8783 - val_acc: 0.6729\n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0348 - acc: 0.9878 - val_loss: 2.4055 - val_acc: 0.5977\n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0620 - acc: 0.9793 - val_loss: 2.0042 - val_acc: 0.6466\n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0738 - acc: 0.9793 - val_loss: 1.9830 - val_acc: 0.6391\n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0493 - acc: 0.9802 - val_loss: 1.7907 - val_acc: 0.6617\n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0618 - acc: 0.9849 - val_loss: 2.1597 - val_acc: 0.6429\n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0825 - acc: 0.9755 - val_loss: 2.0182 - val_acc: 0.6541\n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0787 - acc: 0.9737 - val_loss: 1.9667 - val_acc: 0.6729\n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0739 - acc: 0.9765 - val_loss: 1.8407 - val_acc: 0.6880\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0741 - acc: 0.9727 - val_loss: 1.8747 - val_acc: 0.6805\n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1070 - acc: 0.9680 - val_loss: 1.8751 - val_acc: 0.6617\n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0440 - acc: 0.9821 - val_loss: 1.8202 - val_acc: 0.6541\n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0399 - acc: 0.9887 - val_loss: 1.8925 - val_acc: 0.6353\n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0281 - acc: 0.9925 - val_loss: 2.1341 - val_acc: 0.6654\n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0287 - acc: 0.9915 - val_loss: 1.8962 - val_acc: 0.6429\n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0201 - acc: 0.9915 - val_loss: 1.9698 - val_acc: 0.6541\n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0108 - acc: 0.9991 - val_loss: 2.0707 - val_acc: 0.6692\n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0087 - acc: 0.9991 - val_loss: 2.0478 - val_acc: 0.6917\n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0057 - acc: 0.9981 - val_loss: 2.0708 - val_acc: 0.6541\n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 2.0882 - val_acc: 0.6541\n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 2.0466 - val_acc: 0.6729\n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 2.0350 - val_acc: 0.6767\n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 3s 2ms/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 1.9422 - val_acc: 0.6842\n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 1.9729 - val_acc: 0.6805\n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0027 - acc: 0.9991 - val_loss: 1.9871 - val_acc: 0.6767\n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 2.0431 - val_acc: 0.6617\n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 2.0399 - val_acc: 0.6617\n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 2.0237 - val_acc: 0.6541\n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 9.9010e-04 - acc: 1.0000 - val_loss: 2.0158 - val_acc: 0.6541\n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 3s 2ms/sample - loss: 0.0043 - acc: 0.9991 - val_loss: 2.0076 - val_acc: 0.6729\n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 3s 2ms/sample - loss: 0.0104 - acc: 0.9972 - val_loss: 2.2124 - val_acc: 0.6504\n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 3s 2ms/sample - loss: 0.0172 - acc: 0.9944 - val_loss: 1.9529 - val_acc: 0.6805\n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0102 - acc: 0.9962 - val_loss: 2.0051 - val_acc: 0.6917\n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0124 - acc: 0.9972 - val_loss: 2.2627 - val_acc: 0.6729\n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 3s 2ms/sample - loss: 0.0118 - acc: 0.9981 - val_loss: 2.3324 - val_acc: 0.6692\n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0090 - acc: 0.9991 - val_loss: 2.3271 - val_acc: 0.6654\n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0123 - acc: 0.9944 - val_loss: 2.4991 - val_acc: 0.6579\n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0230 - acc: 0.9934 - val_loss: 2.2760 - val_acc: 0.6617\n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0208 - acc: 0.9944 - val_loss: 2.3771 - val_acc: 0.6391\n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0274 - acc: 0.9925 - val_loss: 2.5542 - val_acc: 0.6504\n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0804 - acc: 0.9784 - val_loss: 2.2908 - val_acc: 0.6429\n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1325 - acc: 0.9595 - val_loss: 2.6980 - val_acc: 0.5977\n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1237 - acc: 0.9577 - val_loss: 2.6217 - val_acc: 0.6165\n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1332 - acc: 0.9558 - val_loss: 2.4076 - val_acc: 0.6053\n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 3s 2ms/sample - loss: 0.0835 - acc: 0.9727 - val_loss: 2.1522 - val_acc: 0.6729\n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 3s 2ms/sample - loss: 0.1010 - acc: 0.9624 - val_loss: 2.1822 - val_acc: 0.6429\n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.1556 - acc: 0.9586 - val_loss: 2.0301 - val_acc: 0.6842\n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0965 - acc: 0.9661 - val_loss: 1.9569 - val_acc: 0.6767\n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0521 - acc: 0.9831 - val_loss: 1.7844 - val_acc: 0.6767\n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0438 - acc: 0.9831 - val_loss: 1.8669 - val_acc: 0.6729\n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 3s 2ms/sample - loss: 0.0234 - acc: 0.9906 - val_loss: 1.9335 - val_acc: 0.6767\n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0172 - acc: 0.9962 - val_loss: 1.9709 - val_acc: 0.6617\n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 3s 3ms/sample - loss: 0.0137 - acc: 0.9953 - val_loss: 1.9968 - val_acc: 0.6767\n"
     ]
    }
   ],
   "source": [
    "vm.model.train(X_train, Y_train, batch_size=64, epoch=100, validation_data=(X_test, Y_test), callbacks=[logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f19f471d1d0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36  3  0  0  0  7]\n",
      " [ 1 27  2  7  6  1]\n",
      " [ 0  5 44  2  0  2]\n",
      " [ 2  6  1 27  4  6]\n",
      " [ 1  3  5  2 22  1]\n",
      " [ 5  6  1  2  5 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.80      0.78      0.79        46\n",
      "       happy       0.54      0.61      0.57        44\n",
      "       angry       0.83      0.83      0.83        53\n",
      "     fearful       0.68      0.59      0.63        46\n",
      "   surprised       0.59      0.65      0.62        34\n",
      "         sad       0.59      0.56      0.57        43\n",
      "\n",
      "    accuracy                           0.68       266\n",
      "   macro avg       0.67      0.67      0.67       266\n",
      "weighted avg       0.68      0.68      0.68       266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(list(range(0, len(logger.training))), list(map(lambda x:x[1], logger.training)), label=\"training data\")\n",
    "plt.plot(list(range(0, len(logger.testing))), list(map(lambda x:x[1], logger.testing)), label=\"testing data\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "print_metrics(X_test, Y_test, emotion_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this graph we can see that the model largely overfit around the 20st epoch\n",
    "We can also see that the testing data's accuracy continues to grow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we save the model so we don't have to retrain it each time\n",
    "vm.model.save(\"emotion_lstm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Here we load the model to check if nothing went wrong\n",
    "vm.model.load(\"emotion_lstm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing calm\n",
      "Doing happy\n",
      "Doing angry\n",
      "Doing fearful\n",
      "Doing surprised\n",
      "Doing sad\n"
     ]
    }
   ],
   "source": [
    "# Now we load the new dataset (savee)\n",
    "\n",
    "# First we change the folder path\n",
    "folder_path += \"/savee\"\n",
    "\n",
    "# Now we load the data\n",
    "data = {f: load_wav(f\"{folder_path}/{f}\", nb_break) for f in emotion_list}\n",
    "X_savee, Y_savee = preprare_wav(data, vm, sample_duration, step)\n",
    "X_savee = X_savee.astype('float32')\n",
    "X_savee_train, X_savee_test, Y_savee_train, Y_savee_test = train_test_split(X_savee, Y_savee, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580/580 [==============================] - 0s 809us/sample - loss: 8.4240 - acc: 0.2207\n",
      "[[15 15  2  5 69 44]\n",
      " [ 3 19  1  6 37 16]\n",
      " [ 4 11  1  6 44 15]\n",
      " [ 4  6  3  5 42 20]\n",
      " [ 2  9  0  7 54  9]\n",
      " [17 11  0  5 39 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.33      0.10      0.15       150\n",
      "       happy       0.27      0.23      0.25        82\n",
      "       angry       0.14      0.01      0.02        81\n",
      "     fearful       0.15      0.06      0.09        80\n",
      "   surprised       0.19      0.67      0.30        81\n",
      "         sad       0.25      0.32      0.28       106\n",
      "\n",
      "    accuracy                           0.22       580\n",
      "   macro avg       0.22      0.23      0.18       580\n",
      "weighted avg       0.24      0.22      0.18       580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vm.model._model.evaluate(X_savee, Y_savee)\n",
    "print_metrics(X_savee, Y_savee, emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_noise\n",
      "batch_normalization\n",
      "lstm\n",
      "activation\n",
      "flatten\n",
      "batch_normalization_1\n",
      "gaussian_noise_1\n"
     ]
    }
   ],
   "source": [
    "# Now we freeze every layer used for extracting features from data\n",
    "for layer in vm.model._model.layers[:-3]:\n",
    "    print(layer.name)\n",
    "    layer.trainable = False\n",
    "vm.model._model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 464 samples, validate on 116 samples\n",
      "Epoch 1/100\n",
      "464/464 [==============================] - 2s 4ms/sample - loss: 5.0117 - acc: 0.2091 - val_loss: 5.2628 - val_acc: 0.2328\n",
      "Epoch 2/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 2.4653 - acc: 0.2931 - val_loss: 3.4826 - val_acc: 0.2241\n",
      "Epoch 3/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.8851 - acc: 0.2953 - val_loss: 2.8134 - val_acc: 0.2241\n",
      "Epoch 4/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.6437 - acc: 0.3384 - val_loss: 2.5926 - val_acc: 0.2328\n",
      "Epoch 5/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.6355 - acc: 0.3772 - val_loss: 2.3865 - val_acc: 0.2241\n",
      "Epoch 6/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.5163 - acc: 0.4009 - val_loss: 2.4888 - val_acc: 0.2414\n",
      "Epoch 7/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.5414 - acc: 0.3707 - val_loss: 2.2258 - val_acc: 0.2500\n",
      "Epoch 8/100\n",
      "464/464 [==============================] - 2s 3ms/sample - loss: 1.4705 - acc: 0.3944 - val_loss: 2.2518 - val_acc: 0.2586\n",
      "Epoch 9/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.4513 - acc: 0.4289 - val_loss: 2.2180 - val_acc: 0.2500\n",
      "Epoch 10/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.4433 - acc: 0.4116 - val_loss: 2.2047 - val_acc: 0.2672\n",
      "Epoch 11/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.4203 - acc: 0.4397 - val_loss: 2.2527 - val_acc: 0.2414\n",
      "Epoch 12/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.4062 - acc: 0.4310 - val_loss: 2.2572 - val_acc: 0.2414\n",
      "Epoch 13/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3936 - acc: 0.4246 - val_loss: 2.2111 - val_acc: 0.2672\n",
      "Epoch 14/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3807 - acc: 0.4526 - val_loss: 2.2510 - val_acc: 0.2672\n",
      "Epoch 15/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3469 - acc: 0.4526 - val_loss: 2.3298 - val_acc: 0.2672\n",
      "Epoch 16/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3765 - acc: 0.4741 - val_loss: 2.4782 - val_acc: 0.2586\n",
      "Epoch 17/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3816 - acc: 0.4569 - val_loss: 2.4695 - val_acc: 0.2759\n",
      "Epoch 18/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3761 - acc: 0.4547 - val_loss: 2.4745 - val_acc: 0.2586\n",
      "Epoch 19/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3858 - acc: 0.4569 - val_loss: 2.3989 - val_acc: 0.2414\n",
      "Epoch 20/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3546 - acc: 0.4569 - val_loss: 2.5711 - val_acc: 0.2759\n",
      "Epoch 21/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3761 - acc: 0.4655 - val_loss: 2.5027 - val_acc: 0.2759\n",
      "Epoch 22/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3051 - acc: 0.4720 - val_loss: 2.6363 - val_acc: 0.2845\n",
      "Epoch 23/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3767 - acc: 0.4332 - val_loss: 2.5909 - val_acc: 0.2845\n",
      "Epoch 24/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3334 - acc: 0.4828 - val_loss: 2.5916 - val_acc: 0.2759\n",
      "Epoch 25/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3339 - acc: 0.4397 - val_loss: 2.6327 - val_acc: 0.3017\n",
      "Epoch 26/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2943 - acc: 0.5000 - val_loss: 2.5768 - val_acc: 0.2845\n",
      "Epoch 27/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3497 - acc: 0.4634 - val_loss: 2.5694 - val_acc: 0.2931\n",
      "Epoch 28/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3535 - acc: 0.4849 - val_loss: 2.5422 - val_acc: 0.2672\n",
      "Epoch 29/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3428 - acc: 0.4461 - val_loss: 2.6563 - val_acc: 0.2759\n",
      "Epoch 30/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3138 - acc: 0.4763 - val_loss: 2.6712 - val_acc: 0.2845\n",
      "Epoch 31/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3042 - acc: 0.4677 - val_loss: 2.6805 - val_acc: 0.2759\n",
      "Epoch 32/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3507 - acc: 0.4978 - val_loss: 2.6120 - val_acc: 0.2586\n",
      "Epoch 33/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3217 - acc: 0.4612 - val_loss: 2.7463 - val_acc: 0.2845\n",
      "Epoch 34/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3718 - acc: 0.4526 - val_loss: 2.7081 - val_acc: 0.2672\n",
      "Epoch 35/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3181 - acc: 0.4741 - val_loss: 2.8061 - val_acc: 0.2759\n",
      "Epoch 36/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3120 - acc: 0.4741 - val_loss: 2.6492 - val_acc: 0.2845\n",
      "Epoch 37/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3550 - acc: 0.4526 - val_loss: 2.6014 - val_acc: 0.3103\n",
      "Epoch 38/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3374 - acc: 0.4569 - val_loss: 2.6838 - val_acc: 0.2931\n",
      "Epoch 39/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3688 - acc: 0.4741 - val_loss: 2.5889 - val_acc: 0.2931\n",
      "Epoch 40/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3026 - acc: 0.4871 - val_loss: 2.6016 - val_acc: 0.3103\n",
      "Epoch 41/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3719 - acc: 0.4612 - val_loss: 2.5161 - val_acc: 0.2931\n",
      "Epoch 42/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3871 - acc: 0.4418 - val_loss: 2.5158 - val_acc: 0.3017\n",
      "Epoch 43/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3192 - acc: 0.4741 - val_loss: 2.5494 - val_acc: 0.3017\n",
      "Epoch 44/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2883 - acc: 0.5000 - val_loss: 2.5559 - val_acc: 0.3190\n",
      "Epoch 45/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3567 - acc: 0.4634 - val_loss: 2.6198 - val_acc: 0.3017\n",
      "Epoch 46/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3503 - acc: 0.4634 - val_loss: 2.6571 - val_acc: 0.2845\n",
      "Epoch 47/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3284 - acc: 0.4741 - val_loss: 2.5906 - val_acc: 0.2845\n",
      "Epoch 48/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3118 - acc: 0.4849 - val_loss: 2.5776 - val_acc: 0.2759\n",
      "Epoch 49/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3411 - acc: 0.4763 - val_loss: 2.5482 - val_acc: 0.2931\n",
      "Epoch 50/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3952 - acc: 0.4677 - val_loss: 2.6528 - val_acc: 0.2845\n",
      "Epoch 51/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2643 - acc: 0.4591 - val_loss: 2.5892 - val_acc: 0.2759\n",
      "Epoch 52/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3430 - acc: 0.4892 - val_loss: 2.6716 - val_acc: 0.3017\n",
      "Epoch 53/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3489 - acc: 0.4418 - val_loss: 2.6220 - val_acc: 0.2586\n",
      "Epoch 54/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3576 - acc: 0.4698 - val_loss: 2.5002 - val_acc: 0.3017\n",
      "Epoch 55/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2435 - acc: 0.4935 - val_loss: 2.5995 - val_acc: 0.2672\n",
      "Epoch 56/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3651 - acc: 0.4526 - val_loss: 2.6347 - val_acc: 0.2845\n",
      "Epoch 57/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2648 - acc: 0.5022 - val_loss: 2.5960 - val_acc: 0.2672\n",
      "Epoch 58/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3112 - acc: 0.4698 - val_loss: 2.6724 - val_acc: 0.2845\n",
      "Epoch 59/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2628 - acc: 0.4784 - val_loss: 2.7566 - val_acc: 0.2759\n",
      "Epoch 60/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2769 - acc: 0.5000 - val_loss: 2.7424 - val_acc: 0.2672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2592 - acc: 0.5172 - val_loss: 2.6979 - val_acc: 0.2500\n",
      "Epoch 62/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3141 - acc: 0.4612 - val_loss: 2.8554 - val_acc: 0.2586\n",
      "Epoch 63/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3407 - acc: 0.4483 - val_loss: 2.7043 - val_acc: 0.2931\n",
      "Epoch 64/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3141 - acc: 0.5022 - val_loss: 2.8204 - val_acc: 0.2931\n",
      "Epoch 65/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2747 - acc: 0.4741 - val_loss: 2.8279 - val_acc: 0.2759\n",
      "Epoch 66/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3528 - acc: 0.4483 - val_loss: 2.7714 - val_acc: 0.2672\n",
      "Epoch 67/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2508 - acc: 0.5000 - val_loss: 2.7938 - val_acc: 0.2500\n",
      "Epoch 68/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3346 - acc: 0.4526 - val_loss: 2.7228 - val_acc: 0.2672\n",
      "Epoch 69/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2712 - acc: 0.4806 - val_loss: 2.6713 - val_acc: 0.2672\n",
      "Epoch 70/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2672 - acc: 0.5043 - val_loss: 2.6707 - val_acc: 0.3190\n",
      "Epoch 71/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2971 - acc: 0.4763 - val_loss: 2.7605 - val_acc: 0.2845\n",
      "Epoch 72/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2659 - acc: 0.4784 - val_loss: 2.6955 - val_acc: 0.2759\n",
      "Epoch 73/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2747 - acc: 0.4741 - val_loss: 2.7438 - val_acc: 0.3103\n",
      "Epoch 74/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2900 - acc: 0.4784 - val_loss: 2.6300 - val_acc: 0.2672\n",
      "Epoch 75/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3335 - acc: 0.4483 - val_loss: 2.6236 - val_acc: 0.2672\n",
      "Epoch 76/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3179 - acc: 0.5043 - val_loss: 2.5364 - val_acc: 0.2845\n",
      "Epoch 77/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2293 - acc: 0.4978 - val_loss: 2.6707 - val_acc: 0.2759\n",
      "Epoch 78/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3183 - acc: 0.4806 - val_loss: 2.6896 - val_acc: 0.2672\n",
      "Epoch 79/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2797 - acc: 0.4677 - val_loss: 2.6472 - val_acc: 0.2845\n",
      "Epoch 80/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2691 - acc: 0.5237 - val_loss: 2.7825 - val_acc: 0.2500\n",
      "Epoch 81/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3221 - acc: 0.4655 - val_loss: 2.6826 - val_acc: 0.2672\n",
      "Epoch 82/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3030 - acc: 0.4892 - val_loss: 2.7950 - val_acc: 0.2845\n",
      "Epoch 83/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2882 - acc: 0.4806 - val_loss: 2.6519 - val_acc: 0.2586\n",
      "Epoch 84/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2602 - acc: 0.4784 - val_loss: 2.6810 - val_acc: 0.2759\n",
      "Epoch 85/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3002 - acc: 0.4763 - val_loss: 2.7800 - val_acc: 0.2845\n",
      "Epoch 86/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3259 - acc: 0.4698 - val_loss: 2.7277 - val_acc: 0.2672\n",
      "Epoch 87/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2918 - acc: 0.4677 - val_loss: 2.7738 - val_acc: 0.3017\n",
      "Epoch 88/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3281 - acc: 0.4591 - val_loss: 2.8096 - val_acc: 0.2586\n",
      "Epoch 89/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3335 - acc: 0.4547 - val_loss: 2.8443 - val_acc: 0.2759\n",
      "Epoch 90/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2987 - acc: 0.4634 - val_loss: 2.8487 - val_acc: 0.2759\n",
      "Epoch 91/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3077 - acc: 0.4871 - val_loss: 2.8528 - val_acc: 0.2672\n",
      "Epoch 92/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2662 - acc: 0.4957 - val_loss: 2.8187 - val_acc: 0.2759\n",
      "Epoch 93/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3311 - acc: 0.4784 - val_loss: 2.6973 - val_acc: 0.2586\n",
      "Epoch 94/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2674 - acc: 0.4978 - val_loss: 2.7653 - val_acc: 0.2672\n",
      "Epoch 95/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3411 - acc: 0.4483 - val_loss: 2.8420 - val_acc: 0.2759\n",
      "Epoch 96/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2365 - acc: 0.5043 - val_loss: 2.6653 - val_acc: 0.2845\n",
      "Epoch 97/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3293 - acc: 0.4784 - val_loss: 2.6696 - val_acc: 0.2845\n",
      "Epoch 98/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3401 - acc: 0.4634 - val_loss: 2.6952 - val_acc: 0.2759\n",
      "Epoch 99/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.3052 - acc: 0.4741 - val_loss: 2.6708 - val_acc: 0.2414\n",
      "Epoch 100/100\n",
      "464/464 [==============================] - 1s 3ms/sample - loss: 1.2878 - acc: 0.5194 - val_loss: 2.6949 - val_acc: 0.2759\n"
     ]
    }
   ],
   "source": [
    "# And we train the two last layers\n",
    "# This is classic fine tuning\n",
    "vm.model.train(X_savee_train, Y_savee_train, batch_size=10, validation_data=(X_savee_test, Y_savee_test), epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111   0   2  10  10  17]\n",
      " [ 29   7  16  11  13   6]\n",
      " [ 25   0  28   2  20   6]\n",
      " [ 33   1   1  18  23   4]\n",
      " [ 18   2   9  15  27  10]\n",
      " [ 66   2   4   6  12  16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.39      0.74      0.51       150\n",
      "       happy       0.58      0.09      0.15        82\n",
      "       angry       0.47      0.35      0.40        81\n",
      "     fearful       0.29      0.23      0.25        80\n",
      "   surprised       0.26      0.33      0.29        81\n",
      "         sad       0.27      0.15      0.19       106\n",
      "\n",
      "    accuracy                           0.36       580\n",
      "   macro avg       0.38      0.31      0.30       580\n",
      "weighted avg       0.37      0.36      0.32       580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_metrics(X_savee, Y_savee, emotion_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
